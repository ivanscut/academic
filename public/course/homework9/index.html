<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 2.4.0">
  <meta name="generator" content="Hugo 0.48" />
  <meta name="author" content="Zhijian He">

  
  
  
  
    
  
  <meta name="description" content="Consider the linear model\[y_i=\beta_0&#43;\beta_1x_i&#43;\epsilon_i,\ \epsilon_i\stackrel{iid}{\sim} N(0,\sigma^2), i=1,\dots,n.\]
Derive the maximum likelihood estimators (MLE) for \(\beta_0,\beta_1\). Are they consistent with the least square estimators (LSE)?
Derive the MLE for \(\sigma^2\) and look at its unbiasedness.
A very slippery point is whether to treat the \(x_i\) as fixed numbers or as random variables. In the class, we treated the predictors \(x_i\) as fixed numbers for sake of convenience. Now suppose that the predictors \(x_i\) are iid random variables (independent of \(\epsilon_i\)) with density \(f_X(x;\theta)\) for some parameter \(\theta\).">

  
  <link rel="alternate" hreflang="en-us" href="/course/homework9/">

  


  

  
  
  
  <meta name="theme-color" content="#0095eb">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Dr. Zhijian He">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Dr. Zhijian He">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/course/homework9/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Dr. Zhijian He">
  <meta property="og:url" content="/course/homework9/">
  <meta property="og:title" content="第九次作业 | Dr. Zhijian He">
  <meta property="og:description" content="Consider the linear model\[y_i=\beta_0&#43;\beta_1x_i&#43;\epsilon_i,\ \epsilon_i\stackrel{iid}{\sim} N(0,\sigma^2), i=1,\dots,n.\]
Derive the maximum likelihood estimators (MLE) for \(\beta_0,\beta_1\). Are they consistent with the least square estimators (LSE)?
Derive the MLE for \(\sigma^2\) and look at its unbiasedness.
A very slippery point is whether to treat the \(x_i\) as fixed numbers or as random variables. In the class, we treated the predictors \(x_i\) as fixed numbers for sake of convenience. Now suppose that the predictors \(x_i\) are iid random variables (independent of \(\epsilon_i\)) with density \(f_X(x;\theta)\) for some parameter \(\theta\).">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-12-18T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2018-12-18T00:00:00&#43;00:00">
  

  

  

  <title>第九次作业 | Dr. Zhijian He</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Dr. Zhijian He</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/talk">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/course/">
            
            <span>Courses</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>



<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      





<form class="docs-search d-flex align-items-center">
  <input name="q" type="search" class="form-control" id="search-query" placeholder="Search..." autocomplete="off">
</form>


<nav class="docs-links" id="docs-nav">
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/course/">Overview</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/course/bchap01/">Bayesian Statistics</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/course/bchap01/">Chapter 1</a>
      </li>
      
      <li >
        <a href="/course/bchap02/">Chapter 2</a>
      </li>
      
      <li >
        <a href="/course/bchap03/">Chapter 3</a>
      </li>
      
      <li >
        <a href="/course/bchap04/">Chapter 4</a>
      </li>
      
      <li >
        <a href="/course/bchap05/">Chapter 5</a>
      </li>
      
      <li >
        <a href="/course/bchap10/">Chapter 10</a>
      </li>
      
      <li >
        <a href="/course/abc/">ABC-Review</a>
      </li>
      
      <li >
        <a href="/course/qmc-abc/">QMC-ABC</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/course/chap00/">数理统计</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/course/chap00/">课程简介</a>
      </li>
      
      <li >
        <a href="/course/chap01/">第一章</a>
      </li>
      
      <li >
        <a href="/course/chap02/">第二章</a>
      </li>
      
      <li >
        <a href="/course/chap03/">第三章</a>
      </li>
      
      <li >
        <a href="/course/chap04/">第四章</a>
      </li>
      
      <li >
        <a href="/course/ex2/">R密度估计</a>
      </li>
      
      <li >
        <a href="/course/ex1/">R画图技巧</a>
      </li>
      
      <li >
        <a href="/course/homework1/">第一次作业</a>
      </li>
      
      <li >
        <a href="/course/homework2/">第二次作业</a>
      </li>
      
      <li >
        <a href="/course/homework3/">第三次作业</a>
      </li>
      
      <li >
        <a href="/course/homework4/">第四次作业</a>
      </li>
      
      <li >
        <a href="/course/homework5/">第五次作业</a>
      </li>
      
      <li >
        <a href="/course/homework6/">第六次作业</a>
      </li>
      
      <li >
        <a href="/course/homework7/">第七次作业</a>
      </li>
      
      <li >
        <a href="/course/homework8/">第八次作业</a>
      </li>
      
      <li class="active">
        <a href="/course/homework9/">第九次作业</a>
      </li>
      
      <li >
        <a href="/course/homework10/">第十次作业</a>
      </li>
      
      <li >
        <a href="/course/homework11/">第十一次作业</a>
      </li>
      
      <li >
        <a href="/course/testa/">期末试卷</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">
      <div id="search-hits">
        
      </div>
      <article class="article" itemscope itemtype="http://schema.org/Article">

        


        <div class="docs-article-container">
          <h1 itemprop="name">第九次作业</h1>

          <div class="article-style" itemprop="articleBody">
            <p>Consider the linear model
<span class="math display">\[y_i=\beta_0+\beta_1x_i+\epsilon_i,\ \epsilon_i\stackrel{iid}{\sim} N(0,\sigma^2), i=1,\dots,n.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Derive the maximum likelihood estimators (MLE) for <span class="math inline">\(\beta_0,\beta_1\)</span>. Are they consistent with the least square estimators (LSE)?</p></li>
<li><p>Derive the MLE for <span class="math inline">\(\sigma^2\)</span> and look at its unbiasedness.</p></li>
<li><p>A very slippery point is whether to treat the <span class="math inline">\(x_i\)</span> as fixed numbers or as random variables. In the class, we treated the predictors <span class="math inline">\(x_i\)</span> as fixed numbers for sake of convenience. Now suppose that the predictors <span class="math inline">\(x_i\)</span> are iid random variables (independent of <span class="math inline">\(\epsilon_i\)</span>) with density <span class="math inline">\(f_X(x;\theta)\)</span> for some parameter <span class="math inline">\(\theta\)</span>. Write down the likelihood function for all of our data <span class="math inline">\((x_i,y_i),i=1,\dots,n\)</span>. Derive the MLE for <span class="math inline">\(\beta_0,\beta_1\)</span> and see whether the MLE changes if we work with the setting of random predictors?</p></li>
</ol>
<!-- 
`Solution`: Note that $y_i\sim N(\beta_0+\beta_1 x_i,\sigma^2)$ independently. The likelihood function is

$$L(\beta_0,\beta_1,\sigma^2) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(y_i-\beta_0-\beta_1x_i)^2}{2\sigma^2}}=(2\pi\sigma^2)^{-n/2}e^{-\frac{Q(\beta_0,\beta_1)}{2\sigma^2}},$$
where $Q(\beta_0,\beta_1) = \sum_{i=1}^n (y_i-\beta_0-\beta_1x_i)^2$.
For given $\sigma^2$, to maximize $L(\beta_0,\beta_1,\sigma^2)$, it suffices to minimize $Q(\beta_0,\beta_1)$. So the MLEs for $\beta_0,\beta_1$ are consistent with the LSEs, i.e.,

$$\hat\beta_1 = \frac{\ell_{xy}}{\ell_{xx}}=\frac{\sum_{i=1}^n (y_i-\bar y)(x_i-\bar x)}{\sum_{i=1}^n(x_i-\bar x)^2},\ \hat\beta_0 = \bar y -\hat\beta_1\bar x.$$

We then choose $\sigma^2$ to maximize $L(\hat\beta_0,\hat\beta_1,\sigma^2) = (2\pi\sigma^2)^{-n/2}e^{-\frac{Q(\hat\beta_0,\hat\beta_1)}{2\sigma^2}}$.
It is easy to see that the maximizer is 
$$\hat\sigma^2_{MLE} = \frac{Q(\hat\beta_0,\hat\beta_1)}{n}=\frac{S_e^2}{n}.$$

We have proved that $E[S_e^2] = (n-2)\sigma^2$. So $E[\hat\sigma^2_{MLE}] = \frac{n-2}{n}\sigma^2$, which is NOT an unbiased estimate of $\sigma^2$.

If $x_i$ are random variables with density $f_X(x;\theta)$. The likelihood function for $(x_i,y_i)$ is 

$$L(\beta_0,\beta_1,\sigma^2,\theta) =\prod_{i=1}^nf_X(x_i;\theta) f(y_i|x_i) = \prod_{i=1}^nf_X(x_i;\theta) e^{-\frac{(y_i-\beta_0-\beta_1x_i)^2}{2\sigma^2}} =(2\pi\sigma^2)^{-n/2}e^{-\frac{Q(\beta_0,\beta_1)}{2\sigma^2}}\prod_{i=1}^n f_X(x_i;\theta).$$

For fixed $\theta,\sigma^2$, to maximize $L(\beta_0,\beta_1,\sigma^2,\theta)$, it suffices to minimize $Q(\beta_0,\beta_1)$. So the MLE does not changes if we work with the setting of random predictors. 

You can imagine that $(x_i,y_i)$ pairs are generated somewhere and on one day you're given $x_1,\dots,x_n$ independent draws from $f_X$. At that point the data have not told you anything about $\beta_0$ or $\beta_1$. The next
day $y_i|x_i$ are revealed to you. That is informative about $\beta_0$ and $\beta_1$ using $f_{Y|X}(y_i|x_i;\beta_0,\beta_1,\sigma^2)$.
The easier analysis is with $x_i$ fixed, so that is the one we'll do.

-->
<hr />
<p>Consider the linear model without intercept</p>
<p><span class="math display">\[y_i  = \beta x_i+\epsilon_i,\ i=1,\dots,n,\]</span></p>
<p>where <span class="math inline">\(\epsilon_i\)</span> are independent with <span class="math inline">\(E[\epsilon_i]=0\)</span> and <span class="math inline">\(Var[\epsilon_i]=\sigma^2\)</span>.</p>
<ul>
<li><p>Write down the least square estimator <span class="math inline">\(\hat \beta\)</span> for <span class="math inline">\(\beta\)</span>, and derive an unbiased estiamtor for <span class="math inline">\(\sigma^2\)</span>.</p></li>
<li><p>For fixed <span class="math inline">\(x_0\)</span>, let <span class="math inline">\(\hat{y}_0=\hat\beta x_0\)</span>. Work out <span class="math inline">\(Var[\hat{y}_0]\)</span>.</p></li>
</ul>
<!-- 
`Solution`: Let $Q(\beta)= \sum_{i=1}^n (y_i-\beta x_i)^2$. Then we have

$$Q'(\beta) = -\sum_{i=1}^n 2x_i(y_i-\beta x_i).$$

Letting $Q'(\beta) = 0$, we work out the LSE for $\beta$, i.e.,

$$\hat\beta = \frac{\sum_{i=1}^n x_iy_i}{\sum_{i=1}^n x_i^2}.$$

Note that

$$\begin{align}
E[Q(\hat\beta)]&= E[\sum_{i=1}^n y_i^2+\hat\beta^2\sum_{i=1}^n x_i^2-2\hat\beta\sum_{i=1}^n x_iy_i]\\
&= \sum_{i=1}^n \lbrace Var[y_i]+(E[y_i])^2\rbrace-E[\hat\beta\sum_{i=1}^n x_iy_i]\\
&=\sum_{i=1}^n (\sigma^2+\beta^2 x_i^2)-\frac{E[(\sum_{i=1}^n x_iy_i)^2]}{\sum_{i=1}^n x_i^2}\\
&= n\sigma^2+\beta^2\sum_{i=1}^n x_i^2-\frac{Var[\sum_{i=1}^n x_iy_i]+\lbrace E[\sum_{i=1}^n x_iy_i]\rbrace^2}{\sum_{i=1}^n x_i^2}\\
&=(n-1)\sigma^2.
\end{align}
$$

So $\hat\sigma^2 = Q(\hat\beta)/(n-1)$ is an unbiased estimate of $\sigma^2$.

$$
\begin{align}
Var[\hat y_0] &= Var[x_0\hat\beta] = x_0^2Var[\hat\beta]\\
&=x_0^2Var\left[\frac{\sum_{i=1}^n x_iy_i}{\sum_{i=1}^n x_i^2}\right]\\&=\frac{x_0^2}{(\sum_{i=1}^n x_i^2)^2}\sum_{i=1}^n Var[x_i y_i]\\
&=\frac{x_0^2}{(\sum_{i=1}^n x_i^2)^2}\sum_{i=1}^n x_i^2\sigma^2\\
&=\frac{x_0^2\sigma^2}{\sum_{i=1}^n x_i^2}
\end{align}
$$

-->
<hr />
<p><code>Case study</code>: Genetic variability is thought to be a key factor in the survival of a species, the idea
being that “diverse” populations should have a better chance of coping with changing
environments. Table below summarizes the results of a study designed to test
that hypothesis experimentally. Two populations of fruit flies (Drosophila serrata)-one that was cross-bred (Strain A) and the other,
in-bred (Strain B)-were put into sealed containers where food and space were kept
to a minimum. Recorded every hundred days were the numbers of Drosophila alive
in each population.</p>
<table>
<thead>
<tr class="header">
<th>Date</th>
<th>Day number</th>
<th>Strain A</th>
<th>Strain B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Feb 2</td>
<td>0</td>
<td>100</td>
<td>100</td>
</tr>
<tr class="even">
<td>May 13</td>
<td>100</td>
<td>250</td>
<td>203</td>
</tr>
<tr class="odd">
<td>Aug 21</td>
<td>200</td>
<td>304</td>
<td>214</td>
</tr>
<tr class="even">
<td>Nov 29</td>
<td>300</td>
<td>403</td>
<td>295</td>
</tr>
<tr class="odd">
<td>Mar 8</td>
<td>400</td>
<td>446</td>
<td>330</td>
</tr>
<tr class="even">
<td>Jun 16</td>
<td>500</td>
<td>482</td>
<td>324</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Plot day numbers versus population sizes for Strain A and Strain B, respectively. Does the plot look linear? If so, please use least squares to figure out the coefficients and
their standard errors, and plot the two regression lines.</p></li>
<li><p>Let <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_1^*\)</span> be the true slopes (i.e., growth rates) for Strain A and Strain B, respectively. Assume the population sizes for the two strains are independent. Under the same assumptions of <span class="math inline">\(\epsilon_i\stackrel{iid}{\sim} N(0,\sigma^2)\)</span> for both strains, do we have enough evidence here
to reject the null hypothesis that <span class="math inline">\(\beta_1\le \beta_1^*\)</span> (significance level <span class="math inline">\(\alpha=0.05\)</span>)? Or equivalently, do these data support the theory that genetically mixed populations have a
better chance of survival in hostile environments.</p></li>
</ul>
<!-- 
`Solution`: 


```r
day = seq(0,500,by=100)
A = c(100,250,304,403,446,482)
B = c(100,203,214,295,330,324)
matplot(day,cbind(A,B),pch=1:2,ylab="population size",ylim = c(100,550))
legend(0,550,c("Strain A", "Strain B"),pch = 1:2,col=c("black","red"))
lm.A = lm(A~day)
lm.B = lm(B~day)
abline(coef(lm.A),lty=2)
abline(coef(lm.B),lty=2,col="red")
text(120,300,expression(hat(y)[A] == 145.3 + 0.742 * x))
text(300,200,expression(hat(y)[B] == 131.3 + 0.452 * x),col="red")
```

<img src="/course/homework9_files/figure-html/unnamed-chunk-1-1.png" width="672" />

```r
output = rbind(summary(lm.A)$coef,summary(lm.B)$coef)
row.names(output) = c("A-Intercept","A-Slope","B-Intercept","B-Slope")
knitr::kable(output,"html",caption = "The coefficients and their standard errors")
```

<table>
<caption>(\#tab:unnamed-chunk-1)The coefficients and their standard errors</caption>
 <thead>
  <tr>
   <th style="text-align:left;">   </th>
   <th style="text-align:right;"> Estimate </th>
   <th style="text-align:right;"> Std. Error </th>
   <th style="text-align:right;"> t value </th>
   <th style="text-align:right;"> Pr(&gt;|t|) </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> A-Intercept </td>
   <td style="text-align:right;"> 145.3333 </td>
   <td style="text-align:right;"> 26.8668380 </td>
   <td style="text-align:right;"> 5.409395 </td>
   <td style="text-align:right;"> 0.0056567 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> A-Slope </td>
   <td style="text-align:right;"> 0.7420 </td>
   <td style="text-align:right;"> 0.0887382 </td>
   <td style="text-align:right;"> 8.361671 </td>
   <td style="text-align:right;"> 0.0011186 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B-Intercept </td>
   <td style="text-align:right;"> 131.3333 </td>
   <td style="text-align:right;"> 22.7725468 </td>
   <td style="text-align:right;"> 5.767178 </td>
   <td style="text-align:right;"> 0.0044864 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B-Slope </td>
   <td style="text-align:right;"> 0.4520 </td>
   <td style="text-align:right;"> 0.0752152 </td>
   <td style="text-align:right;"> 6.009420 </td>
   <td style="text-align:right;"> 0.0038603 </td>
  </tr>
</tbody>
</table>


We now test 

$$H_0:\beta_1\le \beta_1^*,\ H_1:\beta_1>\beta_1^*.$$

Note that $\hat\beta_1 \sim N(\beta_1,\sigma^2/\ell_{xx})$ and $S_{e}^2/\sigma^2\sim \chi^2(n-2)$, where $S_2^2$ is the sum of squared errors for Strain A. Similarly, $\hat\beta_1^* \sim N(\beta_1^*,\sigma^2/\ell_{xx})$ and $\tilde{S}_{e}^2/\sigma^2\sim \chi^2(n-2)$, where $\tilde{S}_{e}^2$ is the sum of squared errors for Strain B. By independence of A and B, we have

$$\hat\beta_1-\hat\beta_1^*\sim N(\beta_1-\beta_1^*,2\sigma^2/\ell_{xx}),$$

$$\frac{S_{e}^2+\tilde{S}_{e}^2}{\sigma^2}\sim \chi^2(2n-4).$$

As a result,

$$\frac{\hat\beta_1-\hat\beta_1^*-(\beta_1-\beta_1^*)}{\sqrt{ \frac{S_{e}^2+\tilde{S}_{e}^2}{(n-2)\ell_{xx}} }}\sim t(2n-4).$$

We thus choose the test statistic

$$T = \frac{\hat\beta_1-\hat\beta_1^*}{\sqrt{ \frac{S_{e}^2+\tilde{S}_{e}^2}{(n-2)\ell_{xx}} }}.$$

If $\beta_1=\beta_1^*$, we have $T\sim t(2n-4)$. The rejection region is $W = \{T>C\}$, where $C$ is satisfied 

$$\sup_{\beta_1\le\beta_1^*}P(T>C|\beta_1,\beta_1^*)=P(T>C|\beta_1=\beta_1^*)=\alpha.$$
We used the fact that the maximum is attainable at the boundary $\beta_1=\beta_1^*$ (WHY?), under which $T\sim t(2n-4)$. So the critical value $C=t_{1-\alpha}(2n-4)$. The observed test statistic is  
$$t = \frac{0.742   -0.452  }{\sqrt{ \frac{5512.14+3960.14}{(6-2)\times 175000} }}=2.50>t_{0.95}(8)=1.8595.$$

We therefore reject the null. These data, then, **do** support the theory that genetically mixed populations have a
better chance of survival in hostile environments.

-->

          </div>

          

        </div>

        <div class="body-footer">
          Last updated on Dec 18, 2018
        </div>

      </article>

      <footer class="site-footer">
  
  <p class="powered-by">
    <a href="/privacy/">Privacy Policy</a>
  </p>
  

  <p class="powered-by">
    Zhijian He &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>

    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "Search Results",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    <script src="/js/search.js"></script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

  </body>
</html>


