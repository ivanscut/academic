<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dr. Zhijian He on Dr. Zhijian He</title>
    <link>/</link>
    <description>Recent content in Dr. Zhijian He on Dr. Zhijian He</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>第六次作业</title>
      <link>/post/homework6/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/homework6/</guid>
      <description>&lt;p&gt;True or false, and state why:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The significance level of a statistical test is equal to the probability that the
null hypothesis is true.&lt;/li&gt;
&lt;li&gt;If the significance level of a test is decreased, the power of the test would be expected to
increase.&lt;/li&gt;
&lt;li&gt;The probability that the null hypothesis is falsely rejected is equal to the power
of the test.&lt;/li&gt;
&lt;li&gt;A type I error occurs when the test statistic falls in the rejection region of the
test.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;p&gt;A coin is thrown independently 10 times to test the hypothesis that the probability of heads is &lt;span class=&#34;math inline&#34;&gt;\(1/2\)&lt;/span&gt; versus the alternative that the probability is not &lt;span class=&#34;math inline&#34;&gt;\(1/2\)&lt;/span&gt;. The test rejects
if either 0 or 10 heads are observed.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;What is the significance level of the test?&lt;/li&gt;
&lt;li&gt;If in fact the probability of heads is &lt;span class=&#34;math inline&#34;&gt;\(0.1\)&lt;/span&gt;, what is the power of the test?&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;p&gt;Suppose that &lt;span class=&#34;math inline&#34;&gt;\(X_1,X_2,X_3\)&lt;/span&gt; are samples of Bernoulli &lt;span class=&#34;math inline&#34;&gt;\(B(1,p)\)&lt;/span&gt; population. For testing the hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0:p=1/2\ vs.\ H_1:p=3/4\)&lt;/span&gt;, we use a rejection region:
&lt;span class=&#34;math display&#34;&gt;\[W=\{(x_1,x_2,x_3):x_1+x_2+x_3\ge 2\}.\]&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;What are the probabilities of the two types of errors for &lt;span class=&#34;math inline&#34;&gt;\(W\)&lt;/span&gt;?&lt;/li&gt;
&lt;li&gt;What is the power of the test? Graph the power as a function of &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 10: Bayesian computation</title>
      <link>/post/bayes_chap10/</link>
      <pubDate>Mon, 22 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/bayes_chap10/</guid>
      <description>&lt;div id=&#34;introduction-to-bayesian-computation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction to Bayesian computation&lt;/h2&gt;
&lt;p&gt;The goals are to estimate&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the posterior distribution &lt;span class=&#34;math inline&#34;&gt;\(p(\theta|y)\propto p(\theta)p(y|\theta)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the posterior predictive distribution
&lt;span class=&#34;math display&#34;&gt;\[p(\tilde y|y) = \int p(\tilde y|\theta)p(\theta|y)d \theta =E[p(\tilde y|\theta)|y]\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are therefore insterested in estimating the posterior expectation
&lt;span class=&#34;math display&#34;&gt;\[\mu=E[h(\theta)|y]=\int h(\theta)p(\theta|y)d \theta\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;moments: &lt;span class=&#34;math inline&#34;&gt;\(h(\theta)=\theta^k\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;probability: &lt;span class=&#34;math inline&#34;&gt;\(h(\theta)=1_A(\theta)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(A\subseteq \Theta\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;predictive density: &lt;span class=&#34;math inline&#34;&gt;\(h(\theta)=p(\tilde y|\theta)\)&lt;/span&gt; for fixed &lt;span class=&#34;math inline&#34;&gt;\(\tilde y\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;monte-carlo-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Monte Carlo methods&lt;/h2&gt;
&lt;p&gt;Suppose we can simulate &lt;span class=&#34;math inline&#34;&gt;\(\theta^{(i)},\dots,\theta^{(N)}\sim p(\theta|y)\)&lt;/span&gt; independently. Monte Carlo (MC) esimate is then the sample average:
&lt;span class=&#34;math display&#34;&gt;\[\hat{\mu}_N = \frac1N\sum_{i=1}^N h(\theta^{(i)})\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLN: &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu_N\to \mu\)&lt;/span&gt; w.p.1 as &lt;span class=&#34;math inline&#34;&gt;\(N\to \infty\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;CLT: &lt;span class=&#34;math inline&#34;&gt;\(\hat\mu_N-\mu=O_p(N^{-1/2})\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Traditional quadrature rules’ have error rate &lt;span class=&#34;math inline&#34;&gt;\(O(N^{-r/d})\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(r\ge 1\)&lt;/span&gt; depends on the smoothness of the functions, and &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the dimension of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. This suffers &lt;strong&gt;the curse of dimensionality&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;MC has an error rate &lt;span class=&#34;math inline&#34;&gt;\(O(N^{-1/2})\)&lt;/span&gt; independently of the smoothness and the dimension of the functions. The task is to simulate iid samples &lt;span class=&#34;math inline&#34;&gt;\(\theta^{(i)}\sim p(\theta|y)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;random-number-generators&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Random number generators&lt;/h2&gt;
&lt;p&gt;We start with a pseudo-random number generator:
&lt;span class=&#34;math display&#34;&gt;\[u_1,\dots,u_n,\dots\stackrel{iid}\sim U(0,1)\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mersenne Twister&lt;/strong&gt; by Matsumoto &amp;amp; Nishimura (1998), whose period is &lt;span class=&#34;math inline&#34;&gt;\(2^{19937}-1&amp;gt;10^{6000}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RngStreams&lt;/strong&gt; by L’Ecuyer, Simard, Chen, Kelton (2002)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They aren’t really uniform random, but good ones are close enough.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;non-uniform-random-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Non-uniform random variables&lt;/h2&gt;
&lt;p&gt;Some common distributions (such as Normal, exponential, binomial, Poisson etc.) are already in some scientific softwares (R, Python, Matlab, Julia, Mathematica, etc.)&lt;/p&gt;
&lt;p&gt;We are now concerned with a general distribution. Principled approaches are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;inversion&lt;/li&gt;
&lt;li&gt;acceptance-rejection&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;inversion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Inversion&lt;/h2&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(F(x)\)&lt;/span&gt; be the CDF of the distribution of interest. We can simulate the distribution via iid uniforms &lt;span class=&#34;math inline&#34;&gt;\(U_1,\dots,U_N\stackrel{iid}\sim U(0,1)\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X_i=F^{-1}(U_i),i=1,\dots,N\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(F^{-1}\)&lt;/span&gt; is the inverse of the CDF &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;, definited by
&lt;span class=&#34;math display&#34;&gt;\[F^{-1}(u)=\inf\{x\in\mathbb{R}|F(x)\ge u\}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;it is easy to see that &lt;span class=&#34;math inline&#34;&gt;\(X_i\stackrel{iid}\sim F\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;inversion-examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Inversion: examples&lt;/h2&gt;
&lt;div id=&#34;gaussian&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Gaussian&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Z=\Phi^{-1}(U)\sim N(0,1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X=\mu+\sigma\Phi^{-1}(U) \sim N(\mu,\sigma^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exponential&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exponential&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X= -\frac 1\lambda \log (1-U)\sim Exp(\lambda)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bernoulli&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bernoulli&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X=1\{U\le p\}\sim Bin(1,p)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;multivariate-inverse-transformation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multivariate inverse transformation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;let &lt;span class=&#34;math inline&#34;&gt;\(F(x_1,\dots,x_d)\)&lt;/span&gt; be the PDF of &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_d\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;let &lt;span class=&#34;math inline&#34;&gt;\(F_i(x_i)\)&lt;/span&gt; be the marginal distribution of &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;for &lt;span class=&#34;math inline&#34;&gt;\(i=2,\dots,d\)&lt;/span&gt;, let &lt;span class=&#34;math inline&#34;&gt;\(F_i(x_i|x_1,\dots,x_{i-1})\)&lt;/span&gt; be the conditional CDF&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The multivariate inverse transformation is proposed by Rosenblatt (1952), which simulates the components &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; recursively, i.e.,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X_1=F_1^{-1}(U_1)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[X_i=F_i^{-1}(U_i|X_1,\dots,X_{i-1}),\ i=2,\dots,d\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the output has the destribution &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the order of simulating the components can be arbitrary&lt;/li&gt;
&lt;li&gt;the critical issue is to know the conditional CDFs in advance&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;acceptance-rejection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Acceptance-rejection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;suppose the target distrubtion is &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; with the support &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{X}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;we can sample &lt;span class=&#34;math inline&#34;&gt;\(Y\sim g\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; is another density satisfying: there exists &lt;span class=&#34;math inline&#34;&gt;\(M&amp;gt;0\)&lt;/span&gt; such that
&lt;span class=&#34;math display&#34;&gt;\[\frac{f(x)}{g(x)}\le M\ \forall x\in \mathcal{X}\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;we can compute &lt;span class=&#34;math inline&#34;&gt;\(f(x)/g(x)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The algorithm goes below&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Step 1: simulate &lt;span class=&#34;math inline&#34;&gt;\(Y\sim g\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Step 2: accept &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; as a draw from &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; with probability &lt;span class=&#34;math inline&#34;&gt;\(f(Y)/(Mg(Y))\)&lt;/span&gt;. If the draw is rejected, return to Step 1.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Step 2’: simulate &lt;span class=&#34;math inline&#34;&gt;\(U\sim U(0,1)\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
\begin{cases}
\text{accept } Y &amp;amp; U\le f(Y)/(Mg(Y))\\
\text{go to Step 1 }&amp;amp; else
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;acceptance-rejection-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Acceptance-rejection&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;AR.png&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the acceptance probability: &lt;span class=&#34;math display&#34;&gt;\[E[f(Y)/(Mg(Y))]=\frac 1 M\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;we may choose the smallest &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; such that &lt;span class=&#34;math inline&#34;&gt;\(f(x)\le Mg(x)\)&lt;/span&gt; for all &lt;span class=&#34;math inline&#34;&gt;\(x\in\mathcal{X}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;acceptance-rejection-for-bayesian-computation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Acceptance-rejection for Bayesian computation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the target density
&lt;span class=&#34;math display&#34;&gt;\[p(\theta|y)=\frac{p(\theta)p(y|\theta)}{p(y)}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the constant &lt;span class=&#34;math inline&#34;&gt;\(p(y)\)&lt;/span&gt; is unknown&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the AR algorithm works well if taking &lt;span class=&#34;math inline&#34;&gt;\(f(\theta)=p(\theta)p(y|\theta)\)&lt;/span&gt;
and using proposal density &lt;span class=&#34;math inline&#34;&gt;\(\propto g(\theta)\)&lt;/span&gt; with
&lt;span class=&#34;math display&#34;&gt;\[\frac{p(\theta)p(y|\theta)}{g(\theta)}\le M\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-gamma-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example: Gamma distribution&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Gamma(\alpha,\lambda)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha&amp;gt;0\)&lt;/span&gt; is the shape, &lt;span class=&#34;math inline&#34;&gt;\(\lambda&amp;gt;0\)&lt;/span&gt; is the rate&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;density&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x) = \frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}1\{x&amp;gt; 0\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Gamma(\alpha,\lambda)\stackrel{d}{=}\frac 1 \lambda Gamma(\alpha,1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Gamma(\alpha,1)\stackrel{d}{=}U(0,1)^{1/\alpha}Gamma(\alpha+1,1)\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;so our target is &lt;span class=&#34;math inline&#34;&gt;\(Gamma(\alpha,1)\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(\alpha&amp;gt;1\)&lt;/span&gt;. For this case, the density is bounded.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the proposal
&lt;span class=&#34;math display&#34;&gt;\[g(x)=?\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;gamma-density&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gamma density&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayes_chap10_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Ahrens and Dieter (1974) took proposals from a density that combines a
Gaussian density in the center and an exponential density in the right tail.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Marsaglia and Tsang (2000) present an AR algorithm from a truncated
&lt;span class=&#34;math inline&#34;&gt;\(N(0,1)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-beta-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example: Beta distribution&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Beta(\alpha,\beta)\)&lt;/span&gt; density
&lt;span class=&#34;math display&#34;&gt;\[f(x)=\frac{\Gamma(\alpha,\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}1\{0&amp;lt;x&amp;lt;1\}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;generate a Beta from two independent Gammas
&lt;span class=&#34;math display&#34;&gt;\[Beta(\alpha,\beta)\stackrel{d}{=}\frac{Gamma(\alpha,\lambda)}{Gamma(\alpha,\lambda)+Gamma(\beta,\lambda)}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(\alpha&amp;gt;1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta&amp;gt;1\)&lt;/span&gt;, the beta density is unimodal and achieves its maximum at &lt;span class=&#34;math inline&#34;&gt;\(x^*=(\alpha-1)/(\alpha+\beta-2)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;beta-density&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Beta density&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayes_chap10_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Proposal distribution: &lt;span class=&#34;math inline&#34;&gt;\(U(0,1)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(M=f(x^*)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;accept &lt;span class=&#34;math inline&#34;&gt;\(U\sim U(0,1)\)&lt;/span&gt; with probability &lt;span class=&#34;math inline&#34;&gt;\(f(U)/M\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;beta-generator-r-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Beta generator: R code&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;myBeta &amp;lt;- function(n,alpha,beta){
  if(alpha&amp;lt;=1 | beta&amp;lt;=1)
    stop(&amp;quot;alpha, beta cannot be &amp;lt;= 1&amp;quot;)
  M = dbeta((alpha-1)/(alpha+beta-2),alpha,beta)
  x = rep(0,n)
  for(i in 1:n){
    while (TRUE){
      U = runif(1)
      if(dbeta(U,alpha,beta)&amp;gt;= M*runif(1)){
        x[i] = U
        break
      }
    }
  }
  return(x)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulation results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayes_chap10_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-5&#34;&gt;Table 1: &lt;/span&gt;&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sd&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;myBeta&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4001780&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1968478&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;dbeta&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3996059&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2000705&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;true values&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;importance-sampling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Importance Sampling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;the target is to estimate &lt;span class=&#34;math inline&#34;&gt;\(\mu=E_f[h(X)]\)&lt;/span&gt; w.r.t. the density &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the proposal density &lt;span class=&#34;math inline&#34;&gt;\(q(x)\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(q(x)&amp;gt;0\)&lt;/span&gt; whenever &lt;span class=&#34;math inline&#34;&gt;\(h(x)f(x)&amp;gt;0\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\mu=\int h(x)f(x)dx=\int h(x)\frac{f(x)}{g(x)}g(x)dx=E_g[h(X)f(X)/g(X)]\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(f(x)/g(x)\)&lt;/span&gt; called the &lt;strong&gt;likelihood ratio (LR)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The IS algorithm goes below&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: simulate &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; samples &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt; from &lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Step 2: compute the sample average:
&lt;span class=&#34;math display&#34;&gt;\[\hat{\mu}_{IS}=\frac 1N\sum_{i=1}^N \frac{h(X_i)f(X_i)}{g(X_i)}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;choosing-the-proposal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Choosing the proposal&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var[\hat{\mu}_{IS}] = \frac{\sigma^2_g}{N}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma^2_g = \int \left(\frac{h(x)f(x)}{g(x)}-\mu\right)^2g(x)d x=\int\frac{(h(x)f(x)-\mu g(x))^2}{g(x)}dx\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if &lt;span class=&#34;math inline&#34;&gt;\(g(x)=h(x)f(x)/\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(h\ge 0\)&lt;/span&gt;, then we have &lt;strong&gt;the optimal case&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_g=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;but unattainable: &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is unknown constant&lt;/li&gt;
&lt;li&gt;we may find &lt;span class=&#34;math inline&#34;&gt;\(g(x)\approx h(x)f(x)/\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;the-weight-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The weight function&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;let &lt;span class=&#34;math inline&#34;&gt;\(w(x)=f(x)/g(x)\)&lt;/span&gt; be the LR
&lt;span class=&#34;math display&#34;&gt;\[\sigma^2_g =\int \frac{(hf)^2}{g}dx -\mu^2\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\int \frac{(hf)^2}{g}dx=E_f[w(X)h(X)^2]=E_g[w(X)^2h(X)^2]\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if &lt;span class=&#34;math inline&#34;&gt;\(w(x)\)&lt;/span&gt; is bounded, then &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_g\)&lt;/span&gt; is bounded&lt;/li&gt;
&lt;li&gt;if &lt;span class=&#34;math inline&#34;&gt;\(w(x)\)&lt;/span&gt; is unbounded, then &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_g\)&lt;/span&gt; may be unbounded (&lt;strong&gt;the worst case!&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;self-normalized-is-snis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Self-normalized IS (SNIS)&lt;/h2&gt;
&lt;p&gt;What if we cannot compute &lt;span class=&#34;math inline&#34;&gt;\(f/g\)&lt;/span&gt;? Suppose that
&lt;span class=&#34;math display&#34;&gt;\[f(x)=c_f\tilde{f}(x),\ g(x)=c_g\tilde{g}(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and we can compute &lt;span class=&#34;math inline&#34;&gt;\(\tilde f,\tilde g\)&lt;/span&gt; but not the constants &lt;span class=&#34;math inline&#34;&gt;\(c_f,c_g\)&lt;/span&gt;. Then we use&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\mu}_{SNIS}= \frac{\frac 1 N\sum_{i=1}^nh(X_i)\tilde{f}(X_i)/\tilde{g}(X_i)}{\frac 1 N\sum_{i=1}^n\tilde{f}(X_i)/\tilde{g}(X_i)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or, equivalently,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\mu}_{SNIS}= \frac{\frac 1 N\sum_{i=1}^Nh(X_i){f}(X_i)/{g}(X_i)}{\frac 1 N\sum_{i=1}^N{f}(X_i)/{g}(X_i)}=\frac{\frac 1 N\sum_{i=1}^Nh(X_i)w(X_i)}{\frac 1 N\sum_{i=1}^Nw(X_i)}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variance-of-snis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Variance of SNIS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Taylor expansions
&lt;span class=&#34;math display&#34;&gt;\[f(\bar X,\bar Y)\approx f(\mu_1,\mu_2)+f_x(\mu_1,\mu_2)(\bar X-\mu_1)+f_y(\mu_1,\mu_2)(\bar Y-\mu_2)\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E[f(\bar X,\bar Y)]\approx f(\mu_1,\mu_2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var[f(\bar X,\bar Y)]\approx f_x^2Var[\bar X]+f_y^2Var[\bar Y]+2f_xf_yCov(\bar X,\bar Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(f(x,y)=x/y\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(f_x=1/y,f_y=-x/y^2\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[Var[f(\bar X,\bar Y)]\approx \frac{\sigma_X^2}{N\mu_2^2}+\frac{\mu_1^2\sigma_Y^2}{N\mu_2^4}-\frac{2\mu_1}{N\mu_2^3}Cov(X,Y)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var[\hat{\mu}_{SNIS}]\approx \frac{1}{N}E_g[w(X)^2(h(X)-\mu)^2]\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Var[\hat{\mu}_{IS}]= \frac{1}{N}E_g[(h(X)w(X)-\mu)^2]\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;optimal-snis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Optimal SNIS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;SNIS: &lt;span class=&#34;math inline&#34;&gt;\(g_{opt}(x)\propto f(x)|h(x)-\mu|\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;IS: &lt;span class=&#34;math inline&#34;&gt;\(g_{opt}(x)\propto f(x)|h(x)|\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;effective-sample-size&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Effective sample size&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Unequal weighting raises variance, see, Kong (1992), Evans and Swartz (1995)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;for iid &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt; with variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; and fixed &lt;span class=&#34;math inline&#34;&gt;\(w_i\ge 0\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[Var\left(\frac{\sum_{i}w_iY_i}{\sum_iw_i}\right)=\frac{\sum_iw_i^2\sigma^2}{(\sum_iw_i)^2}=\frac{\sigma^2}{N_{eff}}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where the effective sample size &lt;span class=&#34;math inline&#34;&gt;\(N_{eff}\)&lt;/span&gt; is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[N_{eff} = \frac{(\sum_{i=1}^Nw_i)^2}{\sum_{i=1}^Nw_i^2}\in [1,N]\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(N_{eff}\)&lt;/span&gt; is small if there are few extremely high weights which would unduly influence the distribution&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;for equal weights, we have &lt;span class=&#34;math inline&#34;&gt;\(N_{eff}=N\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1&lt;/h2&gt;
&lt;p&gt;Suppose the posterior distribution is &lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;, the proposal distribution is &lt;span class=&#34;math inline&#34;&gt;\(t_3(\mu,\sigma^2)\)&lt;/span&gt;. Consider &lt;span class=&#34;math inline&#34;&gt;\(\mu=\sigma=2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayes_chap10_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-1-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Effective sample size is  9178 / 10000&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayes_chap10_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-7&#34;&gt;Table 2: &lt;/span&gt;&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n=100&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n=1000&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n=10000&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;exact_value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Mean&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.214328&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.011347&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.945335&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Variance&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.069694&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.688183&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.052519&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 2&lt;/h2&gt;
&lt;p&gt;Suppose the posterior distribution is &lt;span class=&#34;math inline&#34;&gt;\(t_3(\mu,\sigma^2)\)&lt;/span&gt;, the proposal distribution is &lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Effective sample size is  6180 / 10000&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayes_chap10_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-8&#34;&gt;Table 3: &lt;/span&gt;&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n=100&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n=1000&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n=10000&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;exact_value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Mean&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.802681&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.784954&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.019707&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Variance&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.630305&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.931088&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.875331&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;is-vs-acceptance-rejection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;IS vs acceptance rejection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Acceptance-rejection requires bounded LR &lt;span class=&#34;math inline&#34;&gt;\(f/g\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We also have to know a bound&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;IS and SNIS require us to keep track of weights&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Plain IS requires normalized &lt;span class=&#34;math inline&#34;&gt;\(f/g\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Acceptance-rejection samples cost more (due to rejections)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;is-for-rare-events&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;IS for rare events&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;rare events:
&lt;span class=&#34;math display&#34;&gt;\[h(x)=1_A(x), \mu = E_f[h(x)]=\int_A f(x) dx=\epsilon\approx 0\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;coefficient of variation of &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[cv:=\frac{\sigma/\sqrt{N}}{\mu}=\frac{\sqrt{\epsilon(1-\epsilon)}}{\sqrt{n}\epsilon}\approx \frac{1}{\sqrt{n\epsilon}}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;to get &lt;span class=&#34;math inline&#34;&gt;\(cv=0.1\)&lt;/span&gt; takes &lt;span class=&#34;math inline&#34;&gt;\(N\ge 100/\epsilon\)&lt;/span&gt;, e.g., &lt;span class=&#34;math inline&#34;&gt;\(\epsilon = 10^{-5}\)&lt;/span&gt;, then &lt;span class=&#34;math inline&#34;&gt;\(N\ge 10^7\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Taking &lt;span class=&#34;math inline&#34;&gt;\(X\sim f\)&lt;/span&gt; does not get enough data from the important region &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Get more data from &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; (from a proper proposal &lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt;), and then correct the bias (the LR function)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;changing-a-parameter&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Changing a parameter&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;norminal distribution &lt;span class=&#34;math inline&#34;&gt;\(p(x;\theta_0)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\theta_0\in\Theta\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;proposal distribution &lt;span class=&#34;math inline&#34;&gt;\(p(x;\theta)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\theta\in\Theta\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;estimator
&lt;span class=&#34;math display&#34;&gt;\[\hat\mu_\theta=\frac{1}{N}\sum_{i=1}^N h(X_i) \frac{p(X_i;\theta_0)}{p(X_i;\theta)}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The importance ratio often simplifies, e.g., in exponential families.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exponential-tilting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exponential tilting&lt;/h2&gt;
&lt;p&gt;Many important distributions can be written in the form
&lt;span class=&#34;math display&#34;&gt;\[p(x;\theta) = a(\theta)\exp[\eta(\theta)^\top T(x)]b(x), \theta\in \Theta\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\mu_\theta=\frac{a(\theta_0)}{a(\theta)}\frac{1}{N}\sum_{i=1}^N h(X_i) \exp[(\eta(\theta_0)-\eta(\theta))^\top T(X_i)]\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\eta(\theta)\)&lt;/span&gt; is the natrual parameter&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This is called the ‘exponential twisting’.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The goal is to choose &lt;span class=&#34;math inline&#34;&gt;\(\theta\in\Theta\)&lt;/span&gt; such that &lt;span class=&#34;math inline&#34;&gt;\(Var[\hat\mu_\theta]\)&lt;/span&gt; is minimized.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;a-simple-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A simple example&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;norminal distribution &lt;span class=&#34;math inline&#34;&gt;\(p(x;\theta_0)=N(x;0,1)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;proposal distribution &lt;span class=&#34;math inline&#34;&gt;\(p(x;\theta)=N(x;\theta,1)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\theta\in\mathbb{R}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;target function &lt;span class=&#34;math inline&#34;&gt;\(h(x) = 1\{x&amp;gt;c\}\)&lt;/span&gt;, for large &lt;span class=&#34;math inline&#34;&gt;\(c&amp;gt;0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\mu=E[h(X)]=1-\Phi(c)\approx 0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;IS estimator
&lt;span class=&#34;math display&#34;&gt;\[\hat\mu_\theta=\frac{1}{N}\sum_{i=1}^N h(X_i) \frac{N(X_i;0,1)}{N(X_i;\theta,1)}=\frac{1}{N}\sum_{i=1}^N h(X_i) e^{-\frac{2\theta X_i-\theta^2}{2}}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;IS variance &lt;span class=&#34;math inline&#34;&gt;\(Var[\hat\mu_\theta]=\sigma^2_\theta/N\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\sigma^2_\theta=\frac{e^{\theta^2}}{\sqrt{2\pi}}\int_c^\infty e^{-\frac{(x+\theta)^2}{2}}dx-\mu^2=\frac{e^{\theta^2}[1-\Phi(c+\theta)]}{\sqrt{2\pi}}-\mu^2\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the optimal parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta^*=\arg \min_{\theta\in \mathbb{R}} e^{\theta^2}[1-\Phi(c+\theta)]\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;the-effect-of-different-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The effect of different parameters&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayes_chap10_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;the threshold c = 3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;the true value is 0.0013498980316301&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;the optimal theta is 3.155&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;variance reduction factor is 404&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;applications-in-computational-finance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Applications in Computational Finance&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;P. Glasserman, P. Heidelberger, and P. Shahabuddin. Asymptotically optimal importance
sampling and stratification for pricing path-dependent options. &lt;em&gt;Mathematical Finance&lt;/em&gt;, 9
(2):117–152, 1999.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;P. Glasserman, P. Heidelberger, and P. Shahabuddin. Variance reduction techniques for
estimating value-at-risk. &lt;em&gt;Management Science&lt;/em&gt;, 46(10):1349–1364, 2000.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;P. Glasserman, J. Li. Importance Sampling for Portfolio Credit Risk. &lt;em&gt;Management Science&lt;/em&gt;, 51(11):1643–1656, 2005.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Xie, Fei, &lt;strong&gt;Zhijian He&lt;/strong&gt;, and Xiaoqun Wang. An Importance Sampling-Based Smoothing Approach for Quasi-Monte Carlo Simulation of Discrete Barrier Options. &lt;em&gt;European Journal of Operational Research&lt;/em&gt;, October 17, 2018.
&lt;a href=&#34;https://doi.org/10.1016/j.ejor.2018.10.030&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.ejor.2018.10.030&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;importance-sampling-for-portfolio-credit-risk&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Importance Sampling for Portfolio Credit Risk&lt;/h2&gt;
&lt;p&gt;Our interest centers on the distribution of losses
from default over a fixed horizon.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;: number of obligors&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_k\)&lt;/span&gt;: default indicator for &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;th obligor, &lt;span class=&#34;math inline&#34;&gt;\(Y_k=1\)&lt;/span&gt; denotes the default; &lt;span class=&#34;math inline&#34;&gt;\(Y_k=0\)&lt;/span&gt; otherwise&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(p_k\)&lt;/span&gt;: marginal probability that &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;th obligor defaults&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(c_k\)&lt;/span&gt;: loss resulting from default of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;th obligor&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(L=c_1Y_1+\dots+c_mY_m\)&lt;/span&gt;: total loss from defaults&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our goal is to estimate tail probabilities &lt;span class=&#34;math inline&#34;&gt;\(P(L&amp;gt;x)\)&lt;/span&gt;, especially at large values of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;normal-copula-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normal copula model&lt;/h2&gt;
&lt;p&gt;In the normal copula model, dependence
is introduced through a multivariate normal vector &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_m\)&lt;/span&gt; of latent variables. Each default indicator is represented as
&lt;span class=&#34;math display&#34;&gt;\[Y_k = 1\{X_k&amp;gt; x_k\},\ k=1,\dots,m.\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[X_k = a_{k1}Z_1+\dots+a_{kd}Z_d+b_k\epsilon_k\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(x_k\)&lt;/span&gt; are chosen to match &lt;span class=&#34;math inline&#34;&gt;\(P(X_k&amp;gt;x_k)=p_k\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Z_1,\dots,Z_d\stackrel{iid}{\sim} N(0,1)\)&lt;/span&gt; are systematic risk factors&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_k\stackrel{iid}{\sim} N(0,1)\)&lt;/span&gt; is an idiosyncratic risk&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(a_{k1},\dots,a_{kd}\)&lt;/span&gt; are the loading factors satisfying &lt;span class=&#34;math inline&#34;&gt;\(\sum_{j=1}^d a_{kj}^2\le 1\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(b_k=\sqrt{1-\sum_{j=1}^d a_{kj}^2}\)&lt;/span&gt; so that &lt;span class=&#34;math inline&#34;&gt;\(X_k\sim N(0,1)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;is-for-independent-obligors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;IS for independent obligors&lt;/h2&gt;
&lt;p&gt;Consider the simple case of independent obligors: &lt;span class=&#34;math inline&#34;&gt;\(a_{ij}=0,\ b_k=1\)&lt;/span&gt;, i.e., &lt;span class=&#34;math inline&#34;&gt;\(Y_k\sim Bin(1,p_k)\)&lt;/span&gt; independently. The idea is to replace each default probability &lt;span class=&#34;math inline&#34;&gt;\(p_k\)&lt;/span&gt; by some other default probability &lt;span class=&#34;math inline&#34;&gt;\(q_k\)&lt;/span&gt;, the basic IS identity is
&lt;span class=&#34;math display&#34;&gt;\[P(L&amp;gt;x)= \tilde{E}\left[1\{L&amp;gt;x\}\prod_{k=1}^m\frac{p_k^{Y_k}(1-p_k)^{1-Y_k}}{q_k^{Y_k}(1-q_k)^{1-Y_k}}\right]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exponential Twisting&lt;/strong&gt;: Glasserman and Li (2005) chooses
&lt;span class=&#34;math display&#34;&gt;\[q_{k,\theta} = \frac{p_ke^{\theta c_k}}{1+p_k(e^{\theta c_k}-1)}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The original probabilities correspond to &lt;span class=&#34;math inline&#34;&gt;\(\theta=0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;if &lt;span class=&#34;math inline&#34;&gt;\(\theta&amp;gt;0\)&lt;/span&gt;, this does indeed increase the default
probabilities; a larger exposure &lt;span class=&#34;math inline&#34;&gt;\(c_k\)&lt;/span&gt; results in a greater
increase in the default probability.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;choosing-the-optimal-parameter&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Choosing the optimal parameter&lt;/h2&gt;
&lt;p&gt;The LR is reduced to
&lt;span class=&#34;math display&#34;&gt;\[\prod_{k=1}^m\frac{p_k^{Y_k}(1-p_k)^{1-Y_k}}{q_k^{Y_k}(1-q_k)^{1-Y_k}}=\exp(-\theta L+\psi(\theta))\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where
&lt;span class=&#34;math display&#34;&gt;\[\psi(\theta)=\log E[e^{\theta L}]=\sum_{k=1}^m \log(1+p_k(e^{\theta c_k}-1))\]&lt;/span&gt;
is the cumulant generating function (CGF) of L.&lt;/p&gt;
&lt;p&gt;The optimal parameter is
&lt;span class=&#34;math display&#34;&gt;\[\theta^* = \arg \min_{\theta\ge 0} \{M_2(\theta)=E_\theta[1\{L&amp;gt;x\}e^{-2\theta L+2\psi(\theta)}]\}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;choosing-the-sub-optimal-parameter&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Choosing the sub-optimal parameter&lt;/h2&gt;
&lt;p&gt;Observe that for &lt;span class=&#34;math inline&#34;&gt;\(\theta\ge 0\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[M_2(\theta)\le e^{-2\theta x+2\psi(\theta)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Minimizing &lt;span class=&#34;math inline&#34;&gt;\(M_2(\theta)\)&lt;/span&gt; is difficult, but minimizing
the upper bound is easy:
&lt;span class=&#34;math display&#34;&gt;\[\theta_x = \arg \min_{\theta\ge 0}e^{-2\theta x+2\psi(\theta)}=\arg \max_{\theta\ge 0} \{\theta x-\psi(\theta)\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The function &lt;span class=&#34;math inline&#34;&gt;\(\psi(\theta)\)&lt;/span&gt; is strictly convex and passes through the origin, so the maximum
is attained at
&lt;span class=&#34;math display&#34;&gt;\[\theta_x = 
\begin{cases}
\text{unique solution to }\psi&amp;#39;(\theta)=x,\ &amp;amp;x&amp;gt;\psi&amp;#39;(0)\\
0,\ &amp;amp;x\le \psi&amp;#39;(0).
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;for the first case, &lt;span class=&#34;math inline&#34;&gt;\(E_{\theta_x}[L]=\psi&amp;#39;(\theta_x)=x\)&lt;/span&gt;, thus, we have shifted the distribution of L so that x is now its mean.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;for the second case, the event &lt;span class=&#34;math inline&#34;&gt;\(\{L&amp;gt;x\}\)&lt;/span&gt; is not rare, so we do not change the probabilities.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;dependent-obligors-conditional-importance-sampling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dependent Obligors: Conditional Importance Sampling&lt;/h2&gt;
&lt;p&gt;For general factor models, &lt;span class=&#34;math inline&#34;&gt;\(Y_k\)&lt;/span&gt; are dependent; but they are independent conditinal on the systematic risk factors &lt;span class=&#34;math inline&#34;&gt;\(Z_1,\dots,Z_d\)&lt;/span&gt;. So we can apply the so-called conditional IS.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Step 1: simulate &lt;span class=&#34;math inline&#34;&gt;\(Z_1,\dots,Z_d\sim N(0,1)\)&lt;/span&gt; and compute the default probability
&lt;span class=&#34;math inline&#34;&gt;\(p_k=p_k(Z_1,\dots,Z_d)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Step 2: for simulated &lt;span class=&#34;math inline&#34;&gt;\(p_k\)&lt;/span&gt;, obtain the twisting parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta_x=\theta_x(Z_1,\dots,Z_d)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Step 3: compute the LR for the &lt;span class=&#34;math inline&#34;&gt;\(\theta_x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Step 4: repeat Steps 1–4 &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; times and then obtain the final IS estimate&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;numerical-results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Numerical results&lt;/h2&gt;
&lt;p&gt;The numerical results were reported in Glasserman and Li (2005).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(21\)&lt;/span&gt;-factor model with &lt;span class=&#34;math inline&#34;&gt;\(m=1000\)&lt;/span&gt; obligors&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(p_k = 0.01(1+\sin(16\pi k/m))\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(c_k=(\lceil5k/m\rceil)^2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;VRF = “Variance Reduction Factor”&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(L&amp;gt;x)\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;VRF&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;10,000&lt;/td&gt;
&lt;td&gt;0.0114&lt;/td&gt;
&lt;td&gt;33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;14,000&lt;/td&gt;
&lt;td&gt;0.0065&lt;/td&gt;
&lt;td&gt;53&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;18,000&lt;/td&gt;
&lt;td&gt;0.0037&lt;/td&gt;
&lt;td&gt;83&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;22,000&lt;/td&gt;
&lt;td&gt;0.0021&lt;/td&gt;
&lt;td&gt;125&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;30,000&lt;/td&gt;
&lt;td&gt;0.0006&lt;/td&gt;
&lt;td&gt;278&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;40,000&lt;/td&gt;
&lt;td&gt;0.0001&lt;/td&gt;
&lt;td&gt;977&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;extensions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extensions&lt;/h2&gt;
&lt;p&gt;The defual indicators&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_k=1\{X_k&amp;gt;x_k\}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X_k\)&lt;/span&gt; follow t copula model&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Joshua C.C. Chan, Dirk P. Kroese. Efficient estimation of large portfolio loss probabilities in t-copula models. &lt;em&gt;European Journal of Operational Research&lt;/em&gt;, 205:361–367, 2010.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X_k\)&lt;/span&gt; follow another advanced models, e.g., self-exciting model, Giesecke et al. (2010)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Random default exposures: &lt;span class=&#34;math inline&#34;&gt;\(c_k=e_k\ell_k\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\ell_k\in[0,1]\)&lt;/span&gt; denotes a random
percentage loss, and &lt;span class=&#34;math inline&#34;&gt;\(e_k&amp;gt;0\)&lt;/span&gt; are constants.
&lt;span class=&#34;math display&#34;&gt;\[L = \sum_{k=1}^m e_k\ell_k1\{X_k&amp;gt;x_k\}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\ell_k\)&lt;/span&gt; are iid truncated normals or betas&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;cross-entropy&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cross-entropy&lt;/h2&gt;
&lt;p&gt;The optimal proposal
density is obtained by locating the member &lt;span class=&#34;math inline&#34;&gt;\(p(x;\theta),\theta\in\Theta\)&lt;/span&gt; that minimizes
its cross-entropy distance to the zero-variance proposal
density &lt;span class=&#34;math inline&#34;&gt;\(q^*(x)\propto h(x)p(x;\theta_0)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The minimization of the cross-entropy is equivalent to solving
the following maximization problem
&lt;span class=&#34;math display&#34;&gt;\[\max_{\theta\in\Theta} \int h(x)p(x;\theta_0)\log p(x;\theta)d x=\max_{\theta\in\Theta}  E_{\theta_0}[h(X)\log p(X;\theta)]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since most often an analytical solution to the above maximization
problem is not available, we consider instead its stochastic
counterpart
&lt;span class=&#34;math display&#34;&gt;\[\theta^*=\arg \max_{\theta\in\Theta}\frac 1{N_0}\sum_{i=1}^{N_0}h(X_i)\log p(X_i;\theta),\ X_i\stackrel{iid}{\sim} p(x;\theta_0)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;More detials see Rubinstein (1997), Rubinstein &amp;amp; Kroese (2004).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>第五次作业</title>
      <link>/post/homework5/</link>
      <pubDate>Mon, 22 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/homework5/</guid>
      <description>&lt;p&gt;课本P61第23题：设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(U(0,\theta)\)&lt;/span&gt;的样本，求&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的置信水平为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间。设得到了&lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;个样本值&lt;span class=&#34;math inline&#34;&gt;\(0.08,0.28,0.53,0.91,0.89\)&lt;/span&gt;, 求&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的置信水平为&lt;span class=&#34;math inline&#34;&gt;\(0.95\)&lt;/span&gt;的置信区间。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;：因为&lt;span class=&#34;math inline&#34;&gt;\(X_i\stackrel{iid}{\sim} U(0,\theta)\)&lt;/span&gt;, 所以&lt;span class=&#34;math inline&#34;&gt;\(Y_i:=X_i/\theta\stackrel{iid}{\sim} U(0,1)\)&lt;/span&gt;. 由此可以构造很多种枢轴量。由于&lt;span class=&#34;math inline&#34;&gt;\(X_{(n)}\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的最大似然估计，所以很自然想到通过&lt;span class=&#34;math inline&#34;&gt;\(X_{(n)}\)&lt;/span&gt;来构造枢轴量。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[G_1= \frac{X_{(n)}}{\theta}=Y_{(n)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因为&lt;span class=&#34;math inline&#34;&gt;\(Y_i\stackrel{iid}{\sim} U(0,1)\)&lt;/span&gt;, 不难计算&lt;span class=&#34;math inline&#34;&gt;\(Y_{(n)}\)&lt;/span&gt;(也就是&lt;span class=&#34;math inline&#34;&gt;\(G_1\)&lt;/span&gt;)的分布函数为：
&lt;span class=&#34;math display&#34;&gt;\[F_1(x) = P(Y_{(n)}\le x ) = \prod_{i=1}^n P(Y_i\le x) = x^n,x\in (0,1) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;假设存在&lt;span class=&#34;math inline&#34;&gt;\(0\le a&amp;lt;b\le 1\)&lt;/span&gt;满足&lt;span class=&#34;math inline&#34;&gt;\(P(a\le G_1\le b)=b^n-a^n=1-\alpha\)&lt;/span&gt;, 则有可以得到一个
置信水平为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间
&lt;span class=&#34;math display&#34;&gt;\[\left[\frac{X_{(n)}}{b},\frac{X_{(n)}}{a}\right].\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;显然满足方程&lt;span class=&#34;math inline&#34;&gt;\(b^n-a^n=1-\alpha\)&lt;/span&gt;的解有无穷多种，最好的选择方案是使得&lt;span class=&#34;math inline&#34;&gt;\(1/a-1/b\)&lt;/span&gt;最短，即
&lt;span class=&#34;math display&#34;&gt;\[a_{opt} = \arg \min_{a\in[0,\alpha^{1/n}]} \left[\frac{1}{a}-\frac{1}{(1-\alpha+a^n)^{1/n}}\right]= \arg \min_{a\in[0,\alpha^{1/n}]}g(a)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(g(a) = \frac{1}{a}-\frac{1}{(1-\alpha+a^n)^{1/n}},a\in[0,\alpha^{1/n}]\)&lt;/span&gt;。因为
&lt;span class=&#34;math display&#34;&gt;\[g&amp;#39;(a) = -\frac 1{a^2}+\frac{a^{n-1}}{(1-\alpha+a^n)^{1+1/n}}&amp;lt; -\frac{1}{a^2}+\frac{a^{n-1}}{(a^n)^{1+1/n}}=0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以&lt;span class=&#34;math inline&#34;&gt;\(g(a)\)&lt;/span&gt;为单调递减函数，于是&lt;span class=&#34;math inline&#34;&gt;\(a_{opt}=\alpha^{1/n},b_{opt}=1\)&lt;/span&gt;. 所以最优的置信区间为&lt;span class=&#34;math inline&#34;&gt;\(\left[X_{(n)},\frac{X_{(n)}}{\alpha^{1/n}}\right]\)&lt;/span&gt;，把具体数据代进去可得置信区间为&lt;span class=&#34;math inline&#34;&gt;\([0.91,1.66]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;当然你可以用平分法得到&lt;span class=&#34;math inline&#34;&gt;\(a=(\alpha/2)^{1/n},b=(1-\alpha/2)^{1/n}\)&lt;/span&gt;, 把具体数据代进去可得置信区间为&lt;span class=&#34;math inline&#34;&gt;\([0.9146,1.9031]\)&lt;/span&gt;, 显然这样的区间长度比最优的情况长些。&lt;/p&gt;
&lt;p&gt;此外，我们还可以构造其他的枢轴量，比如
&lt;span class=&#34;math display&#34;&gt;\[G_2 = -2\sum_{i=1}^n\log Y_i = -2\sum_{i=1}^n\log X_i+2n\log \theta\sim\chi^2(2n)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;为什么是卡方分布？请查看&lt;a href=&#34;https://hezhijian.netlify.com/post/homework1/&#34;&gt;第一次作业第五题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;假设存在&lt;span class=&#34;math inline&#34;&gt;\(0\le c&amp;lt;d\)&lt;/span&gt;满足&lt;span class=&#34;math inline&#34;&gt;\(P(c\le G_2\le d)=1-\alpha\)&lt;/span&gt;, 则有可以得到另一个
置信水平为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间
&lt;span class=&#34;math display&#34;&gt;\[\left[e^{(c+2\sum_{i=1}^n\log X_i)/2n},e^{(d+2\sum_{i=1}^n\log X_i)/2n}\right].\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;利用平分法，不妨取&lt;span class=&#34;math inline&#34;&gt;\(c=\chi^2_{\alpha/2}(2n),d=\chi^2_{1-\alpha/2}(2n)\)&lt;/span&gt;. 代入数据得到置信区间为&lt;span class=&#34;math inline&#34;&gt;\([0.5465,3.0631]\)&lt;/span&gt;，这种做法需要用到所有的数据，而且置信区间长度更长。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;总结：从这例子看出，置信区间的选择有很多种，选取不同的枢轴量，所得的区间往往差别很大。如何选择恰当的枢轴量？一个很好的启发就是与点估计量联系起来。比如这道题第一种方式用到了最大值统计量，这个是未知参数的极大似然估计量，所以“好的”置信区间可能与它存在某种联系，比如包含它。然而，遗憾的是，对区间估计问题没有一个准则来得到所谓“好的”置信区间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;有部分同学使用中心极限定理来得到近似置信区间，这种做法对&lt;span class=&#34;math inline&#34;&gt;\(n=5\)&lt;/span&gt;的小样本问题不合适。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;下面通过R语言来求解具体的区间估计问题，最方便的方法是用函数来实现。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## 单个总体期望的区间估计
# x为数据
# 1-alpha为置信水平
# sigma为总体标准差，默认sigma=NA为未知标准差的情形
# k为输出结果的有效数字，如果k=0意味着不输出结果，默认输出k=6位有效数字的结果
meanCI &amp;lt;- function(x,alpha,sigma=NA,k=6){
  n = length(x)
  mu = mean(x)
  if(is.na(sigma)){
    #方差未知, 用t分布
    len = qt(1-alpha/2,df=n-1)*sd(x)/sqrt(n)
    CI = c(mu-len,mu+len)
  }else{
    #方差已知, 用正态分布
    len = qnorm(1-alpha/2)*sigma/sqrt(n)
    CI = c(mu-len,mu+len)
  }
  if(k&amp;gt;0){#输出结果，保留k位有效数字
    print(paste0(&amp;quot;期望的&amp;quot;,(1-alpha)*100,&amp;quot;%置信区间为[&amp;quot;,signif(CI[1],k),&amp;quot;, &amp;quot;,signif(CI[2],k),&amp;quot;]&amp;quot;))
  }
  return(CI)
}

## 单个总体方差的区间估计
# x为数据
# 1-alpha为置信水平
# mu为总体期望，默认mu=NA为未知期望的情形
# k为输出结果的有效数字，如果k=0意味着不输出结果，默认输出k=6位有效数字的结果
varCI &amp;lt;- function(x,alpha,mu=NA,k=6){
  n = length(x)
  if(is.na(mu)){
    #期望未知, 用chisq(n-1)分布
    CI = (n-1)*var(x)*c(1/qchisq(1-alpha/2,df=n-1),1/qchisq(alpha/2,df=n-1))
  }else{
    #期望已知, 用chisq(n)分布
    CI = sum((x-mu)^2)*c(1/qchisq(1-alpha/2,df=n),1/qchisq(alpha/2,df=n))
  }
  if(k&amp;gt;0){#输出结果，保留k位有效数字
    print(paste0(&amp;quot;方差的&amp;quot;,(1-alpha)*100,&amp;quot;%置信区间为[&amp;quot;,signif(CI[1],k),&amp;quot;, &amp;quot;,signif(CI[2],k),&amp;quot;]&amp;quot;))
  }
  return(CI)
}&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;为了解决课本P62第27题，只需要调用&lt;code&gt;varCI&lt;/code&gt;函数就可以，操作如下&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 第27题数据导入
data1 = c(249,254,243,268,253,269,287,241,273,
          306,303,280,260,256,278,344,304,283,310)
alpha = 0.05
CI1 = varCI(data1,alpha)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;方差的95%置信区间为[418.754, 1603.96]&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(paste0(&amp;quot;标准差的&amp;quot;,(1-alpha)*100,&amp;quot;%置信区间为[&amp;quot;,signif(sqrt(CI1[1]),6),&amp;quot;, &amp;quot;,signif(sqrt(CI1[2]),6),&amp;quot;]&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;标准差的95%置信区间为[20.4635, 40.0495]&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;为解决课本P62第28题，只需要调用&lt;code&gt;meanCI&lt;/code&gt;函数就可以，操作如下&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 第28题数据导入
data2 = c(40,45,23,40,31,33,49,33,34,43,26,39)
alpha = 0.05
CI2 = meanCI(data2,alpha)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;期望的95%置信区间为[31.4317, 41.235]&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;分析R软件的&lt;code&gt;dslabs&lt;/code&gt;包中的身高数据heights, 利用R软件完成以下问题。相关的R语言操作见 &lt;a href=&#34;https://hezhijian.netlify.com/post/ex2/&#34; class=&#34;uri&#34;&gt;https://hezhijian.netlify.com/post/ex2/&lt;/a&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;假设整个总体服从正态分布，求期望和方差的95%置信区间。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;为了判断“正态总体”的假设的合理性，画图比较核估计密度与正态分布密度的差异？&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;假设男生总体与女生总体均服从正态分布（方差相同）且独立，求这两个总体平均水平的差的95%置信区间。可否认为男生总体的平均身高大于女生总体的平均身高？你的理由是什么？&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;为了考察第3问中“男女总体的方差相同”的假设是否合理，不妨求这两个总体的方差比的95%置信区间。并观察该置信区间是否包含1？&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;：第一问只需调用前面的两个函数求解即可。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;dslabs&amp;quot;) #事先需要安装该package
attach(heights) #这样可以直接使用height和sex
alpha = 0.05
CI3 = meanCI(height,alpha)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;期望的95%置信区间为[68.076, 68.57]&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;CI4 = varCI(height,alpha)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;方差的95%置信区间为[15.2985, 18.1559]&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面解决第二问，可以看出是核估计与正态估计接近。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(lwd = 2,mar=c(4,4,4,2))
plot(density(height,from = 50,to=85),type=&amp;quot;l&amp;quot;,col=&amp;quot;blue&amp;quot;,xlab=&amp;quot;x&amp;quot;,main=&amp;quot;Kernel vs. Normal&amp;quot;)
x = seq(50,85,by=0.001)
y = dnorm(x,mean(height),sd(height))
lines(x,y,col=&amp;quot;red&amp;quot;)
legend(x=50,y=.1,legend=c(&amp;quot;Kernel&amp;quot;,&amp;quot;Normal&amp;quot;),lty=c(1,1),col=c(&amp;quot;blue&amp;quot;,&amp;quot;red&amp;quot;),lwd=c(2,2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/homework5_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;下面解决两个正态总体均值差（方差相同）的区间估计，同样用函数来解决。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## 两个总体期望差的区间估计（已知方差相同）
# x,y为两个样本数据
# 1-alpha为置信水平
# k为输出结果的有效数字，如果k=0意味着不输出结果，默认输出k=6位有效数字的结果
meandiffCI &amp;lt;- function(x,y,alpha,k=6){
  n = length(x)
  m = length(y)
  mu1 = mean(x)
  mu2 = mean(y)
  sw = sqrt(((n-1)*var(x)+(m-1)*var(y))/(n+m-2))
  CI = mu1-mu2+qt(1-alpha/2,m+n-2)*sw*sqrt(1/n+1/m)*c(-1,1)
  if(k&amp;gt;0){#输出结果，保留k位有效数字
    print(paste0(&amp;quot;期望差的&amp;quot;,(1-alpha)*100,&amp;quot;%置信区间为[&amp;quot;,signif(CI[1],k),&amp;quot;, &amp;quot;,signif(CI[2],k),&amp;quot;]&amp;quot;))
  }
  return(CI)
}

M_height = height[sex==&amp;quot;Male&amp;quot;] #男生数据
F_height = height[sex==&amp;quot;Female&amp;quot;] #女生数据
alpha = 0.05
CI5 = meandiffCI(M_height,F_height,alpha)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;期望差的95%置信区间为[3.84807, 4.90259]&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面解决两个正态总体方差比的区间估计，同样用函数来解决。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## 两个总体方差比的区间估计（期望未知）
# x,y为两个样本数据
# 1-alpha为置信水平
# k为输出结果的有效数字，如果k=0意味着不输出结果，默认输出k=6位有效数字的结果
vardiffCI &amp;lt;- function(x,y,alpha,k=6){
  n = length(x)
  m = length(y)
  CI = var(x)/var(y)*c(1/qf(1-alpha/2,n-1,m-1),1/qf(alpha/2,n-1,m-1))
  if(k&amp;gt;0){#输出结果，保留k位有效数字
    print(paste0(&amp;quot;方差比的&amp;quot;,(1-alpha)*100,&amp;quot;%置信区间为[&amp;quot;,signif(CI[1],k),&amp;quot;, &amp;quot;,signif(CI[2],k),&amp;quot;]&amp;quot;))
  }
  return(CI)
}

CI6 = vardiffCI(M_height,F_height,alpha)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;方差比的95%置信区间为[0.746698, 1.12527]&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从中可以看出，方差比的置信区间包含1，可以认为男女两个总体的方差相同。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>密度估计：直方图与核估计</title>
      <link>/post/ex2/</link>
      <pubDate>Fri, 19 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/ex2/</guid>
      <description>&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;案例：身高数据&lt;/h2&gt;
&lt;p&gt;数据来源于R的包&lt;code&gt;dslabs&lt;/code&gt;，第一次使用时需要安装该包，命令为&lt;code&gt;install.packages(&amp;quot;dslabs&amp;quot;)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;参考资料： &lt;a href=&#34;https://simplystatistics.org/2018/01/22/the-dslabs-package-provides-datasets-for-teaching-data-science/&#34;&gt;Some datasets for teaching data science&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;直方图&lt;/h3&gt;
&lt;p&gt;直方图的R命令为：&lt;code&gt;hist(...)&lt;/code&gt;, 查看帮助&lt;code&gt;?hist&lt;/code&gt;看具体参数含义&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;核估计&lt;/h3&gt;
&lt;p&gt;核估计的R命令为：&lt;code&gt;density(...)&lt;/code&gt;, 查看帮助&lt;code&gt;?density&lt;/code&gt;看具体参数含义。注意该命令只是给出估计值的数据，不能直接画图，如果要画图则需要调用画图函数，如&lt;code&gt;plot(...)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;以下代码展示所有身高数据的直方图与和核估计。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(!require(dslabs))
  install.packages(&amp;quot;dslabs&amp;quot;)
attach(heights) #此命令用于使用该包里面的身高数据heights
par(mar=c(2,2,1,1)) #调整图形边距
#直方图
hist(height,breaks=10,ylim=c(0,.115),col = &amp;quot;lightblue&amp;quot;, border = &amp;quot;pink&amp;quot;,freq=FALSE,main=&amp;quot;Histogram vs. Kernel density&amp;quot;)
#添加核估计数据
lines(density(height,from = 50,to=85),col=&amp;quot;red&amp;quot;,lwd=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ex2_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;下面代码比较男生和女生数据的核估计&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;female_height = height[sex==&amp;quot;Female&amp;quot;]#提取女生数据
male_height = height[sex==&amp;quot;Male&amp;quot;]#提取男生数据
par(mar=c(2,2,1,1))
#画男生数据
plot(density(male_height,from = 50,to=85),col=&amp;quot;red&amp;quot;,lwd=2,ylim=c(0,.14),main=&amp;quot;Male vs. Female&amp;quot;)
#添加女生数据
lines(density(female_height,from = 50,to=85),col=&amp;quot;blue&amp;quot;,lwd=2)
#画出图例说明
legend(74,0.12,legend = c(&amp;quot;Male&amp;quot;,&amp;quot;Female&amp;quot;),lty = c(1,1),col=c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;),lwd=c(2,2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ex2_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;结论：身高数据可以近似看成正态分布，而且男生、女生两个总体的均值有差异，男生身高平均水平大于女生身高的平均水平。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>第四次作业</title>
      <link>/post/homework4/</link>
      <pubDate>Fri, 12 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/homework4/</guid>
      <description>&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为来自参数为&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的Poisson分布的样本. 在下列选项中选出用于估计参数&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的无偏估计量。&lt;strong&gt;答案：ABCE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A. &lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;B. &lt;span class=&#34;math inline&#34;&gt;\(S_n^{*2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar X)^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;C. &lt;span class=&#34;math inline&#34;&gt;\(\frac 1 {n-1}\sum_{i=1}^{n-1}X_i\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;D. &lt;span class=&#34;math inline&#34;&gt;\(S_n^2=\frac{1}{n}\sum_{i=1}^n(X_i-\bar X)^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;E. &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}2 \bar X + \frac 12 S_n^{*2}\)&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为来自参数为&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的Poisson分布的样本, 已知&lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;是未知参数&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的完全统计量。在下列选项中选出用于估计参数&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的最有效的估计量。&lt;strong&gt;答案：A&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A. &lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;B. &lt;span class=&#34;math inline&#34;&gt;\(S_n^{*2}=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar X)^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;C. &lt;span class=&#34;math inline&#34;&gt;\(\frac 1 {n-1}\sum_{i=1}^{n-1}X_i\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;D. &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}2 \bar X + \frac 12 S_n^{*2}\)&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X,\dots,X_n\)&lt;/span&gt;为来自参数为&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的Poisson分布的样本，求&lt;span class=&#34;math inline&#34;&gt;\(\lambda^2\)&lt;/span&gt;的无偏估计。已知&lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;是参数&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的完全统计量，能否找到&lt;span class=&#34;math inline&#34;&gt;\(\lambda^2\)&lt;/span&gt;的最小方差无偏估计量？&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;: 1. &lt;span class=&#34;math inline&#34;&gt;\(\lambda^2\)&lt;/span&gt;的无偏估计有很多种答案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;因为&lt;span class=&#34;math inline&#34;&gt;\(E[X]=Var[\lambda]=\lambda\)&lt;/span&gt;, 所以&lt;span class=&#34;math inline&#34;&gt;\(E[X^2]=\lambda+\lambda^2=E[X]+\lambda^2\)&lt;/span&gt;，由矩法得到一种无偏估计量：
&lt;span class=&#34;math display&#34;&gt;\[\hat{\lambda^2}_1 = \frac{1}{n}\sum_{i=1}^n(X_i^2-X_i)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;因为&lt;span class=&#34;math inline&#34;&gt;\(E[\bar X]=\lambda\)&lt;/span&gt;, &lt;span class=&#34;math display&#34;&gt;\[E(\bar X^2) = Var(\bar X)+(E[\bar X])^2=\lambda/n+\lambda^2=E[\bar X]/n+\lambda^2,\]&lt;/span&gt;
于是可以得到一种无偏估计量：
&lt;span class=&#34;math display&#34;&gt;\[\hat{\lambda^2}_2 = (\bar X)^2-\bar X/n\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;当然还可以构造无穷多种无偏估计量：
&lt;span class=&#34;math display&#34;&gt;\[\hat{\lambda^2}_3 = \alpha \hat{\lambda^2}_1+(1-\alpha)\hat{\lambda^2}_2,\forall \alpha\in [0,1].\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;虽然无偏统计量有很多，但是最小方差无偏估计量是唯一的（在概率意义下）。由于&lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;是充分完全统计量，所以由B-L-S定理知，&lt;span class=&#34;math inline&#34;&gt;\(\hat{\lambda^2}_2\)&lt;/span&gt;是最小方差无偏的。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;有一部分同学想通过&lt;span class=&#34;math inline&#34;&gt;\(\psi(\bar X)=E[\hat{\lambda^2}_1|\bar X]\)&lt;/span&gt;的得到最小无偏估计量，思路是对的，但是如何计算&lt;span class=&#34;math inline&#34;&gt;\(\psi(\bar X)\)&lt;/span&gt;就没那么容易了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了解决这个问题，我们需要计算在给定&lt;span class=&#34;math inline&#34;&gt;\(\bar X= t\)&lt;/span&gt;下，样本&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;的条件分布。容易计算样本的联合分布为
&lt;span class=&#34;math display&#34;&gt;\[P(X_1=x_1,\dots,X_n=x_n)=\prod_{i=1}^nP(X_i=x_i) = \prod_{i=1}^n \frac{e^{-\lambda}\lambda^{x_i}}{x_i!}=\frac{e^{-n\lambda}\lambda^{n\bar x}}{\prod_{i=1}^nx_i!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由于Possion分布的可加性，有&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^n X_i\sim Possion(n\lambda)\)&lt;/span&gt;, 所以
&lt;span class=&#34;math display&#34;&gt;\[P(\bar X=t)=P(\sum_{i=1}^n X_i=nt)=\frac{e^{-n\lambda}(n\lambda)^{nt}}{(nt)!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;于是，给定&lt;span class=&#34;math inline&#34;&gt;\(\bar X= t\)&lt;/span&gt;下，样本&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;的条件分布为：当&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^nx_i=nt\)&lt;/span&gt;时，
&lt;span class=&#34;math display&#34;&gt;\[P(X_1=x_1,\dots,X_n=x_n|\bar X=t)=\frac{\frac{e^{-n\lambda}\lambda^{nt}}{\prod_{i=1}^nx_i!}}{\frac{e^{-n\lambda}(n\lambda)^{nt}}{(nt)!}}=\frac{(nt)!}{n^{nt}\prod_{i=1}^nx_i!}, \]&lt;/span&gt;
其他情况下，该条件概率为0. 我们发现
&lt;span class=&#34;math display&#34;&gt;\[\psi(t)=E[\hat{\lambda^2}_1|\bar X=t]=E[\frac{1}{n}\sum_{i=1}^nX_i^2-\bar X|\bar X=t]=E[n(\bar X)^2-\frac{1}{n}\sum_{i\neq j}X_iX_j-\bar X|\bar X=t]=nt^2-t-\frac{1}{n}E[\sum_{i\neq j}X_iX_j|\bar X=t].\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由于对称性，&lt;span class=&#34;math inline&#34;&gt;\(E[\sum_{i\neq j}X_iX_j|\bar X=t]=n(n-1)E[X_1X_2|\bar X=t]\)&lt;/span&gt;, 所以只需计算&lt;span class=&#34;math inline&#34;&gt;\(E[X_1X_2|\bar X=t]\)&lt;/span&gt;即可：
&lt;span class=&#34;math display&#34;&gt;\[E[X_1X_2|\bar X=t]=\sum_{\vec x:\sum_{i=1}^nx_i=nt}\frac{x_1x_2(nt)!}{n^{nt}\prod_{i=1}^nx_i!}=\frac{(nt)!}{n^{nt}}\sum_{\vec x:\sum_{i=1}^nx_i=nt}\frac{x_1x_2}{\prod_{i=1}^nx_i!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由于
&lt;span class=&#34;math display&#34;&gt;\[\sum_{\vec x:\sum_{i=1}^nx_i=nt}\frac{x_1x_2}{\prod_{i=1}^nx_i!}=\sum_{\vec x:\sum_{i=1}^nx_i=nt,x_1\ge 1,x_2\ge 1}\frac{1}{(x_1-1)!(x_2-1)!\prod_{i=3}^nx_i!}=\sum_{\vec x:\sum_{i=1}^nx_i=nt-2}\frac{1}{\prod_{i=1}^nx_i!}=\frac{n^{nt-2}}{(nt-2)!}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，
&lt;span class=&#34;math display&#34;&gt;\[\psi(t)=nt^2-t-(n-1)E[X_1X_2|\bar X=t]=nt^2-t-(n-1)\frac{(nt)!}{n^{nt}}\frac{n^{nt-2}}{(nt-2)!}=t^2-\frac{t}{n}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这表明，&lt;span class=&#34;math inline&#34;&gt;\(\psi(\bar X)=(\bar X)^2-\bar X/n\)&lt;/span&gt;, 也就是&lt;span class=&#34;math inline&#34;&gt;\(\hat{\lambda^2}_2\)&lt;/span&gt;. 两种方式得到的最小方差无偏估计量是一致的。这也印证了最小方差无偏估计量是唯一的。显然第一种方式比较简单，第二种方式需要求条件期望，这个比较复杂，一般情况下不容易求解。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;分布的样本，参数&lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma^2\)&lt;/span&gt;未知。证明样本方差&lt;span class=&#34;math inline&#34;&gt;\(S_n^2\)&lt;/span&gt;与修正样本方差&lt;span class=&#34;math inline&#34;&gt;\(S_n^{*2}\)&lt;/span&gt;均为&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的弱相合估计量。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;： 由抽样分布定理知，&lt;span class=&#34;math inline&#34;&gt;\(\frac{\sum_{i=1}^n (X_i-\bar X)^2}{\sigma^2}\sim \chi^2(n-1)\)&lt;/span&gt;, 所以
&lt;span class=&#34;math display&#34;&gt;\[Var[\sum_{i=1}^n (X_i-\bar X)^2]=2(n-1)\sigma^4\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;于是，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var[S_n^2]=Var[\sum_{i=1}^n (X_i-\bar X)^2]/n^2=\frac{2(n-1)\sigma^4}{n^2}\to 0\text{ as }n\to \infty\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var[S_n^{*2}]=Var[\sum_{i=1}^n (X_i-\bar X)^2]/(n-1)^2=\frac{2\sigma^4}{n-1}\to 0\text{ as }n\to \infty\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由于&lt;span class=&#34;math inline&#34;&gt;\(E[S_n^{*2}]=\sigma^2,\lim_{n\to\infty}E[S_n^2]=\sigma^2\)&lt;/span&gt;, 由弱相合性判别条件知，它们都是弱相合的。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;分布的样本，参数&lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma^2\)&lt;/span&gt;未知。样本方差&lt;span class=&#34;math inline&#34;&gt;\(S_n^2\)&lt;/span&gt;与修正样本方差&lt;span class=&#34;math inline&#34;&gt;\(S_n^{*2}\)&lt;/span&gt;作为&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的两种估计量，哪个更有效？由B-L-S定理知，&lt;span class=&#34;math inline&#34;&gt;\(S_n^{*2}\)&lt;/span&gt;是最小方差无偏估计量，这是否与你所得的结论矛盾？由此你能得到什么启发？&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;: 由于&lt;span class=&#34;math inline&#34;&gt;\(S_n^{*2}\)&lt;/span&gt;是无偏的，所以均方误差
&lt;span class=&#34;math display&#34;&gt;\[M(S_n^{*2}) = Var[S_n^{*2}]=\frac{2\sigma^4}{n-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对&lt;span class=&#34;math inline&#34;&gt;\(S_n^{2}\)&lt;/span&gt;, 其均方误差为
&lt;span class=&#34;math display&#34;&gt;\[M(S_n^{*2}) = Var[S_n^{2}]+(E[S_n^2]-\sigma^2)^2=\frac{2(n-1)\sigma^4}{n^2}+(\frac{(n-1)\sigma^2}{n}-\sigma^2)^2=\frac{(2n-1)\sigma^4}{n^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;又
&lt;span class=&#34;math display&#34;&gt;\[\frac{M(S_n^{*2})}{M(S_n^{2})}=\frac{2n^2}{(n-1)(2n-1)}&amp;gt;1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，&lt;span class=&#34;math inline&#34;&gt;\(S_n^{2}\)&lt;/span&gt;比&lt;span class=&#34;math inline&#34;&gt;\(S_n^{*2}\)&lt;/span&gt;有效。这与“&lt;span class=&#34;math inline&#34;&gt;\(S_n^{*2}\)&lt;/span&gt;是最小方差无偏估计量”不矛盾，因为&lt;span class=&#34;math inline&#34;&gt;\(S_n^{2}\)&lt;/span&gt;是有偏估计量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;启发：无偏估计量不一定是最有效的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为总体&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;, 其中&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;已知，&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;未知。证明&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的估计量
&lt;span class=&#34;math display&#34;&gt;\[T(X_1,\dots,X_n)=\frac 1n\sum_{i=1}^n(X_i-\mu)^2\]&lt;/span&gt;
的方差达到C-R不等式的下界。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;: 令&lt;span class=&#34;math inline&#34;&gt;\(\theta=\sigma^2,f(x;\theta)\)&lt;/span&gt;为总体密度函数。于是，
&lt;span class=&#34;math display&#34;&gt;\[\log f(x;\theta)= \log  \frac{1}{\sqrt{2\pi}\sqrt{\theta}}e^{-\frac{(x-\mu)^2}{2\theta}}=-(1/2)\log(2\pi\theta)-\frac{(x-\mu)^2}{2\theta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{d\log f(x;\theta)}{d\theta}=-\frac{1}{2\theta}+\frac{(x-\mu)^2}{2\theta^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，Fisher信息量为：
&lt;span class=&#34;math display&#34;&gt;\[I(\theta)=E[(\frac{d\log f(X;\theta)}{d\theta})^2]=\frac{1}{4\theta^2}E[(\frac{(X-\mu)^2}{\theta}-1)^2]=\frac{1}{2\theta^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，C-R不等式下界为:
&lt;span class=&#34;math display&#34;&gt;\[\frac{1}{nI(\theta)}=\frac{2\sigma^4}{n}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因为&lt;span class=&#34;math inline&#34;&gt;\(nT/\sigma^2\sim \chi^2(n)\)&lt;/span&gt;, 所以
&lt;span class=&#34;math display&#34;&gt;\[Var[nT/\sigma^2]=2n\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;于是，&lt;span class=&#34;math inline&#34;&gt;\(Var[T]=2\sigma^4/n\)&lt;/span&gt;达到C-R不等式下界。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 5: Hierarchial models</title>
      <link>/post/bayes_chap05/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/bayes_chap05/</guid>
      <description>&lt;div id=&#34;introduction-to-hierarchial-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction to hierarchial models&lt;/h2&gt;
&lt;p&gt;Many statistical applications involve multiple parameters (say, &lt;span class=&#34;math inline&#34;&gt;\(\theta_1,\dots,\theta_J\)&lt;/span&gt;) that can be regarded as related or connected in some way by the structure of the problem.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;for the group &lt;span class=&#34;math inline&#34;&gt;\(j\in 1{:}J\)&lt;/span&gt;, we have the observed data &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(i=1,\dots,n_j\)&lt;/span&gt; from the population distribution with unknown parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;we use a prior distribution in which the &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;’s are viewed as a sample from a common &lt;em&gt;population distribution&lt;/em&gt;, say &lt;span class=&#34;math inline&#34;&gt;\(p(\theta|\phi)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is known as &lt;em&gt;hyperparameters&lt;/em&gt;. Assume that &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; are iid, i.e.,
&lt;span class=&#34;math display&#34;&gt;\[p(\theta|\phi)=\prod_{j=1}^Jp(\theta_j|\phi)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchical-model-for-rats-experiment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hierarchical model for Rats experiment&lt;/h2&gt;
&lt;p&gt;The experiment is used to estimate the probability &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; of tumor in a population of female laboratory rats of type ‘F344’ that receive a zero dose of the drug. The data show that 4 out of 14 rats developed a kind of tumor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;assume a binomial model for the number of tumors&lt;/li&gt;
&lt;li&gt;select a prior from the conjugate family, i.e., &lt;span class=&#34;math inline&#34;&gt;\(\theta\sim Beta(\alpha,\beta)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the posterior is therefore &lt;span class=&#34;math inline&#34;&gt;\(Beta(\alpha+1,\beta+10)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The question is how to determine the hyperparameters &lt;span class=&#34;math inline&#34;&gt;\(\phi=(\alpha,\beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;historical data are available on previous experiments on similar groups of rats: in the jth historical experiments, let the number of rats with tumors be &lt;span class=&#34;math inline&#34;&gt;\(y_j\)&lt;/span&gt; and the total number of rats be &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt;, the parameters for the populations are &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(j=1,\dots,70\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;for current experiment, let &lt;span class=&#34;math inline&#34;&gt;\(y_{71},n_{71},\theta_{71}\)&lt;/span&gt; be the associated notations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;historical-data-for-the-70-historical-experiments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Historical data for the 70 historical experiments&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  2
## [24]  2  2  2  2  2  2  2  2  1  5  2  5  3  2  7  7  3  3  2  9 10  4  4
## [47]  4  4  4  4  4 10  4  4  4  5 11 12  5  5  6  5  6  6  6  6 16 15 15
## [70]  9  4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 20 20 20 20 20 20 20 19 19 19 19 18 18 17 20 20 20 20 19 19 18 18 25
## [24] 24 23 20 20 20 20 20 20 10 49 19 46 27 17 49 47 20 20 13 48 50 20 20
## [47] 20 20 20 20 20 48 19 19 19 22 46 49 20 20 23 19 22 20 20 20 52 46 47
## [70] 24 14&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;viewed-as-separate-models-using-uniform-priors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Viewed as separate models using uniform priors&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;separate_model.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;viewed-as-a-pooled-model-using-uniform-prior&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Viewed as a pooled model using uniform prior&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;pool_model.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-the-historical-data-to-estimate-the-hyperparameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using the historical data to estimate the hyperparameters&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the sample mean and standard deviation of the 70 values &lt;span class=&#34;math inline&#34;&gt;\(y_i/n_i\)&lt;/span&gt; are 0.136 and 0.103&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;let &lt;span class=&#34;math inline&#34;&gt;\(E[\theta]=\frac{\alpha}{\alpha+\beta}=0.136\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Var[\theta]=\frac{E[\theta](1-E[\theta])}{\alpha+\beta+1}=0.103\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat{\alpha}=1.4,\ \hat{\beta}=8.6\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;for the current exeriment, the posterior for &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(Beta(5.4,18.6)\)&lt;/span&gt;, posterior mean is &lt;span class=&#34;math inline&#34;&gt;\(0.223\)&lt;/span&gt;, standard deviation is 0.083.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are several logical and practical problems with the approach of directly estimating a prior distribution from existing data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the data will be used twice for inference about the first 70 experiments – overestimate our precision&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the point estimate for &lt;span class=&#34;math inline&#34;&gt;\(\alpha,\beta\)&lt;/span&gt; seems arbitrary that necessarily ignores some posterior uncertainty&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;this is not the logic of Bayesian inference&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;the-full-bayesian-treatment-of-the-hierarchical-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The full Bayesian treatment of the hierarchical model&lt;/h2&gt;
&lt;p&gt;Suppose the hyperparameters &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; has its own prior distribution &lt;span class=&#34;math inline&#34;&gt;\(p(\phi)\)&lt;/span&gt;, which is called &lt;em&gt;hyperprior distribution&lt;/em&gt;. The appropriate Bayesian posterior distribution is of the vector &lt;span class=&#34;math inline&#34;&gt;\((\phi,\theta)\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the joint prior distribution is
&lt;span class=&#34;math display&#34;&gt;\[p(\phi,\theta)=p(\phi)p(\theta|\phi)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the joint posterior distribution is
&lt;span class=&#34;math display&#34;&gt;\[p(\phi,\theta|y)\propto p(\phi,\theta)p(y|\phi,\theta)=p(\phi)p(\theta|\phi)p(y|\theta)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Previously, we assumed &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; was known, which is unrealistic; now we include the uncertainty in &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; in the model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fully-bayesian-analysis-of-conjugate-hierarchical-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fully Bayesian analysis of conjugate hierarchical models&lt;/h2&gt;
&lt;p&gt;Consider the setting in which &lt;span class=&#34;math inline&#34;&gt;\(p(\theta|\phi)\)&lt;/span&gt; is conjugate to the likelihood &lt;span class=&#34;math inline&#34;&gt;\(p(y|\theta)\)&lt;/span&gt;. For this case, it is easy to determine analytically &lt;span class=&#34;math display&#34;&gt;\[p(\theta|\phi,y)\propto p(\theta|\phi)p(y|\theta)\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the joint posterior density:
&lt;span class=&#34;math display&#34;&gt;\[p(\phi,\theta|y)\propto p(\phi)p(\theta|\phi)p(y|\theta)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the marginal posterior density &lt;span class=&#34;math inline&#34;&gt;\(p(\phi|y)\)&lt;/span&gt; can be computed via
&lt;span class=&#34;math display&#34;&gt;\[p(\phi|y)=\int p(\phi,\theta|y)d \theta\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{or }p(\phi|y)=\frac{p(\phi,\theta|y)}{p(\theta|\phi,y)}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;application-to-the-model-for-rat-tumors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Application to the model for rat tumors&lt;/h2&gt;
&lt;p&gt;The binomial model:
&lt;span class=&#34;math display&#34;&gt;\[y_j\sim Bin(n_j,\theta_j),\ j=1,\dots,J=71\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The parameters &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; are assumed to be independent samples from a beta distribution:
&lt;span class=&#34;math display&#34;&gt;\[\theta_j\sim Beta(\alpha,\beta)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The joint posterior density is
&lt;span class=&#34;math display&#34;&gt;\[p(\theta,\alpha,\beta|y)\propto p(\alpha,\beta)p(\theta|\alpha,\beta)p(y|\theta)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\propto p(\alpha,\beta)\prod_{j=1}^J\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta_j^{\alpha-1}(1-\theta_j)^{\beta-1}\prod_{j=1}^J\theta_j^{y_j}(1-\theta_j)^{n_j-y_j}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p(\theta|\alpha,\beta,y)=\prod_{j=1}^J\frac{\Gamma(\alpha+\beta+n_j)}{\Gamma(\alpha+y_j)\Gamma(\beta+n_j-y_j)}\theta_j^{\alpha+y_i-1}(1-\theta_j)^{\beta+n_j-y_j-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;application-to-the-model-for-rat-tumors-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Application to the model for rat tumors&lt;/h2&gt;
&lt;p&gt;The marginal posterior density:
&lt;span class=&#34;math display&#34;&gt;\[p(\alpha,\beta|y)\propto p(\alpha,\beta)\prod_{j=1}^J\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\frac{\Gamma(\alpha+y_j)\Gamma(\beta+n_j-y_j)}{\Gamma(\alpha+\beta+n_j)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Choosing a noninformative hyperprior distribution:
&lt;span class=&#34;math display&#34;&gt;\[p(\alpha,\beta)\propto (\alpha+\beta)^{-5/2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This implies that &lt;span class=&#34;math inline&#34;&gt;\((\alpha/(\alpha+\beta),(\alpha+\beta)^{-1/2})\)&lt;/span&gt; is uniformly distributed.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the prior mean is &lt;span class=&#34;math inline&#34;&gt;\(\alpha/(\alpha+\beta)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the prior variance is approximately &lt;span class=&#34;math inline&#34;&gt;\((\alpha+\beta)^{-1}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-of-the-marginal-posterior-density&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot of the marginal posterior density&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;alphabeta.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compare-the-separate-model-and-hierarchical-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Compare the separate model and hierarchical model&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;hier_sep.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchical-model-based-on-normal-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hierarchical model based on normal distribution&lt;/h2&gt;
&lt;p&gt;Consider &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; independent experiments, with experiment &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; estimating &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; form &lt;span class=&#34;math inline&#34;&gt;\(n_j\)&lt;/span&gt; independent distributed data points &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}\)&lt;/span&gt;, each with known error variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;, that is
&lt;span class=&#34;math display&#34;&gt;\[y_{ij}|\theta_j\stackrel{iid}{\sim} N(\theta_j,\sigma^2), \text{ for }i=1,\dots,n_j;\ j=1,\dots,J\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;denote the sample mean of each group &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; as
&lt;span class=&#34;math display&#34;&gt;\[\bar{y}_{\cdot j}=\frac 1{n_j}\sum_{i=1}^{n_j}y_{ij}\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;let &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_j=\sigma^2/n_j\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the likelihood for each &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\bar{y}_{\cdot j}|\theta_j\sim N(\theta_j,\sigma_j^2)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;for the convenience of conjugacy, assume the paramerters &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; are drawn from a normal distribution with hyperparameters &lt;span class=&#34;math inline&#34;&gt;\(\mu,\tau\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(\theta_1,\dots,\theta_J|\mu,\tau)=\prod_{j=1}^J N(\theta_j|\mu,\tau^2)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;assign noninformative uniform hyperprior density to &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; given &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(\mu,\tau)=p(\mu|\tau)p(\tau)\propto p(\tau)\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;prior distribution for &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(p(\tau)\propto 1\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the joint posterior density is
&lt;span class=&#34;math display&#34;&gt;\[p(\theta,\mu,\tau|y)\propto p(\mu,\tau)p(\theta|\mu,\tau)p(y|\theta)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p(\theta,\mu,\tau|y)\propto p(\mu,\tau)\prod_{j=1}^J N(\theta_j|\mu,\tau^2)\prod_{j=1}^JN(\bar{y}_{\cdot j}|\theta_j,\sigma_j^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the conditional posterior distirbution:
&lt;span class=&#34;math display&#34;&gt;\[\theta_j|\mu,\tau,y\sim N(\hat{\theta}_j,V_j)\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where
&lt;span class=&#34;math display&#34;&gt;\[\hat{\theta}_j=\frac{\frac 1{\sigma^2}\bar{y}_{\cdot j}+\frac 1{\tau^2}\mu}{\frac 1{\sigma^2}+\frac 1{\tau^2}},\ V_j=\frac{1}{\frac 1{\sigma^2}+\frac 1{\tau^2}}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the marginal posterior density can be computed in a simple way
&lt;span class=&#34;math display&#34;&gt;\[p(\mu,\tau|y)\propto p(\mu,\tau)p(y|\mu,\tau)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{y}_{\cdot j}|\mu,\tau\sim N(\mu,\sigma_j^2+\tau^2)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p(\mu,\tau|y)\propto p(\mu,\tau)\prod_{j=1}^JN(\bar{y}_{\cdot j}|\mu,\sigma_j^2+\tau^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;posterior distribution of &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; given &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\mu|\tau,y\sim N(\hat{\mu},V_{\mu})\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where
&lt;span class=&#34;math display&#34;&gt;\[\hat{\mu}=\frac{\sum_{j=1}^J \frac 1{\sigma_j^2+\tau^2}\bar{y}_{\cdot j}}{\sum_{j=1}^J \frac 1{\sigma_j^2+\tau^2}},\ V_{\mu}^{-1}=\sum_{j=1}^J \frac 1{\sigma_j^2+\tau^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;posterior distribution of &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(\tau|y)=\frac{p(\mu,\tau|y)}{p(\mu|\tau,y)}\propto \frac{p(\tau)\prod_{j=1}^JN(\bar{y}_{\cdot j}|\mu,\sigma_j^2+\tau^2)}{N(\mu|\hat{\mu},V_{\mu})}\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p(\tau|y)\propto p(\tau)V_{\mu}^{1/2}\prod_{j=1}^J(\sigma_j^2+\tau^2)^{-1/2}\exp\left(-\frac{(\bar{y}_{\cdot j}-\hat{\mu})^2}{2(\sigma_j^2+\tau^2)}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-parallel-experiments-in-eight-schools&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example: parallel experiments in eight schools&lt;/h2&gt;
&lt;p&gt;A study was performanced for the Educational Testing Service to analyze the effects of special coaching programs on test scores. Seperate randomized experiments were performed to estimate the effects of coaching programs for the SAT-V (Verbal).&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;33%&#34; /&gt;
&lt;col width=&#34;33%&#34; /&gt;
&lt;col width=&#34;33%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;School&lt;/th&gt;
&lt;th&gt;Estiamted treatment effect &lt;span class=&#34;math inline&#34;&gt;\(y_j\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Standard error of effect estimate &lt;span class=&#34;math inline&#34;&gt;\(\sigma_j\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;-3&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;E&lt;/td&gt;
&lt;td&gt;-1&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;F&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;G&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;H&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;comparisons&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparisons&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;8schools.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-posterior-summaries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the posterior summaries&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;8schools2.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 4: Asymptotics and connections to non-Bayesian approaches</title>
      <link>/post/bayes_chap04/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/bayes_chap04/</guid>
      <description>&lt;div id=&#34;large-sample-theory&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Large-sample theory&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Assumptions and notations&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;true distribution: &lt;span class=&#34;math inline&#34;&gt;\(y_i\stackrel {iid}{\sim} f(\cdot)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\theta\in\Theta\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;prior distribution: &lt;span class=&#34;math inline&#34;&gt;\(p(\theta)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;model distribution: &lt;span class=&#34;math inline&#34;&gt;\(p(y_i|\theta)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Kullback-Leibler divergence&lt;/em&gt;: a measure of ‘discrepancy’ between the model and the true distribution
&lt;span class=&#34;math display&#34;&gt;\[KL(\theta)= E\left[\log\left(\frac{f(y_i)}{p(y_i|\theta)}\right)\right]=\int \log\left(\frac{f(y_i)}{p(y_i|\theta)}\right)f(y_i)dy_i\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\theta_0\)&lt;/span&gt;: the &lt;strong&gt;unique minimizer&lt;/strong&gt; of &lt;span class=&#34;math inline&#34;&gt;\(KL(\theta)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;if &lt;span class=&#34;math inline&#34;&gt;\(f(y_i) = p(y_i|\theta)\)&lt;/span&gt; then &lt;span class=&#34;math inline&#34;&gt;\(\theta=\theta_0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;convergence-of-the-posterior-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Convergence of the posterior distribution&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Discrete parmeter space&lt;/strong&gt;: If the parameter space &lt;span class=&#34;math inline&#34;&gt;\(\Theta\)&lt;/span&gt; is finite and &lt;span class=&#34;math inline&#34;&gt;\(P(\theta=\theta_0)&amp;gt;0\)&lt;/span&gt;, then
&lt;span class=&#34;math display&#34;&gt;\[P(\theta=\theta_0|y)\to 1\text{ as }n\to \infty,\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\theta_0=\arg_{\theta\in\Theta} KL(\theta)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Continuous parmeter space&lt;/strong&gt;: If &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is defined on a compace set &lt;span class=&#34;math inline&#34;&gt;\(\Theta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is a neighborhood of &lt;span class=&#34;math inline&#34;&gt;\(\theta_0\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(P(\theta\in A)&amp;gt;0\)&lt;/span&gt;, then
&lt;span class=&#34;math display&#34;&gt;\[P(\theta\in A|y)\to 1\text{ as }n\to \infty,\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\theta_0=\arg_{\theta\in\Theta} KL(\theta)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;See the proofs in Appendix B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;normal-approximations-to-the-posterior-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normal approximations to the posterior distribution&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat \theta\)&lt;/span&gt;: the posterior mode&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Taylor series expansion of &lt;span class=&#34;math inline&#34;&gt;\(\log p(\theta|y)\)&lt;/span&gt; gives
&lt;span class=&#34;math display&#34;&gt;\[\log(\theta|y) = \log p(\hat \theta|y)-\frac 12 (\theta-\hat\theta)^\top I(\hat \theta) (\theta-\hat\theta) + \cdots \]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(I(\theta)\)&lt;/span&gt; is the &lt;em&gt;observed&lt;/em&gt; information
&lt;span class=&#34;math display&#34;&gt;\[I(\theta)=-\frac{d^2}{d\theta^2}\log p(\theta|y)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Normal approximation: &lt;span class=&#34;math inline&#34;&gt;\(p(\theta|y)\approx N(\hat\theta,[I(\hat\theta)]^{-1})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Fisher information&lt;/em&gt;:
&lt;span class=&#34;math display&#34;&gt;\[J(\theta)=-E_f\left[\frac{d^2}{d\theta^2}\log p(y_j|\theta)\right]\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;convergence-of-the-posterior-distribution-to-normality&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Convergence of the posterior distribution to normality&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: Under some regularity conditions (notably that &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; not be on the boundary of &lt;span class=&#34;math inline&#34;&gt;\(\Theta\)&lt;/span&gt;), as &lt;span class=&#34;math inline&#34;&gt;\(n\to \infty\)&lt;/span&gt;, the posterior distribution of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; approaches normality with mean &lt;span class=&#34;math inline&#34;&gt;\(\theta_0\)&lt;/span&gt; and variance &lt;span class=&#34;math inline&#34;&gt;\([nJ(\theta_0)]^{-1}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\theta_0=\arg_{\theta\in\Theta} KL(\theta)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; is the Fisher information.&lt;/p&gt;
&lt;p&gt;Oberved that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\hat\theta\to \theta_0\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(n\to \infty\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(I(\hat\theta)=-\frac{d^2}{d\theta^2}\log p(\hat\theta)-\sum_{i=1}^n\frac{d^2}{d\theta^2}\log p(y_i|\hat\theta)\approx nJ(\theta_0)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(J(\theta_0)=\frac{d^2}{d\theta^2} KL(\theta_0)&amp;gt;0\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;counterexamples-to-the-theorems&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Counterexamples to the theorems&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;underidentified models: &lt;span class=&#34;math inline&#34;&gt;\(p(y|\theta)\)&lt;/span&gt; is equal for a range of values of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;nonindentified parameters: for example, consider the model,
&lt;span class=&#34;math display&#34;&gt;\[\left(
\begin{matrix}
u\\
v
\end{matrix}
\right)\sim N \left( \left(\begin{matrix}
0\\
0
\end{matrix}
\right),\left(\begin{matrix}
1&amp;amp;\rho\\
\rho &amp;amp; 1
\end{matrix}
\right)\right)\]&lt;/span&gt;
only one of &lt;span class=&#34;math inline&#34;&gt;\(u,v\)&lt;/span&gt; is observed from each pair &lt;span class=&#34;math inline&#34;&gt;\((u,v)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;number of parameters increasing with sample sizes: new latent parameters with each data point&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;point-estimation-consistency-and-efficiency&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Point estimation, consistency, and efficiency&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;point estimations&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;posterior mode &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta(y)=\arg \max_{\theta\in\Theta} p(\theta|y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;posterior mean &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta(y)=E[\theta|y]=\int \theta p(\theta|y)d \theta\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;posterior median &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta(y)=F^{-1}_{\theta|y}(0.5)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;consistency&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta(y)\to \theta_0\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(n\to \infty\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;asymptotic unbiasedness&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(E[\hat\theta|\theta_0]\to\theta_0\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(n\to \infty\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;efficiency&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\text{eff}(\hat\theta)=\frac{\inf_T E[(T(y)-\theta_0)^2|\theta_0]}{E[(\hat\theta-\theta_0)^2|\theta_0]}\le 1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;asymptotically efficient&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\text{eff}(\hat\theta)\to 1\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(n\to \infty\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chapter 3: Introduction to multiparameter models</title>
      <link>/post/bayes_chap03/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/bayes_chap03/</guid>
      <description>&lt;div id=&#34;nuisance-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Nuisance parameters&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;there are more than one unknown or unobservable parameters&lt;/li&gt;
&lt;li&gt;conclusions will often be drawn about one, or only a few parameters at a time&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no interest in making inferences about many of the unknown parameters – &lt;em&gt;nuisance parameters&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;suppose &lt;span class=&#34;math inline&#34;&gt;\(\theta=(\theta_1,\theta_2)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;interest centers only on &lt;span class=&#34;math inline&#34;&gt;\(\theta_1\)&lt;/span&gt;; &lt;span class=&#34;math inline&#34;&gt;\(\theta_2\)&lt;/span&gt; is a ‘nuisance’ parameter.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the joint posterior density:
&lt;span class=&#34;math display&#34;&gt;\[p(\theta_1,\theta_2|y)\propto p(y|\theta_1,\theta_2)p(\theta_1,\theta_2)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the marginal posterior density:
&lt;span class=&#34;math display&#34;&gt;\[p(\theta_1|y)=\int p(\theta_1,\theta_2|y)d\theta_2=\int p(\theta_1|\theta_2,y)p(\theta_2|y)d\theta_2\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;normal-data-with-a-noninformative-prior-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normal data with a noninformative prior distribution&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Likelihood function&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(y|\mu,\sigma^2)=\prod_{i=1}^n \frac 1{\sqrt{2\pi}\sigma}e^{-\frac{(y_i-\mu)^2}{2\sigma^2}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Noninformative prior distribution&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(\mu,\sigma^2)\propto (\sigma^2)^{-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Posterior distribution&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(\mu,\sigma^2|y)\propto \sigma^{-n-2}e^{-\frac{\sum_{i=1}^n(y_i-\mu)^2}{2\sigma^2}}=\sigma^{-n-2}e^{-\frac{(n-1)s^2+n(\bar y-\mu)^2}{2\sigma^2}}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(s^2=\frac 1{n-1}\sum_{i=1}^n(y_i-\bar y)^2\)&lt;/span&gt; is the sample variance&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;normal-data-with-a-noninformative-prior-distribution-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normal data with a noninformative prior distribution&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Conditional posterior distribution&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(\mu|\sigma^2,y)\sim N(\bar y,\sigma^2/n)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Marginal posterior distribution &lt;span class=&#34;math inline&#34;&gt;\(p(\sigma^2|y)\)&lt;/span&gt;&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(\sigma^2|y)\propto \int \sigma^{-n-2}e^{-\frac{(n-1)s^2+n(\bar y-\mu)^2}{2\sigma^2}} d\mu=(\sigma^2)^{-\frac{n+1}2}e^{-\frac{(n-1)s^2}{2\sigma^2}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma^2|y\sim \text{Inv-}\chi^2(n-1,s^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;normal-data-with-a-noninformative-prior-distribution-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normal data with a noninformative prior distribution&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Marginal posterior distribution &lt;span class=&#34;math inline&#34;&gt;\(p(\mu|y)\)&lt;/span&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p(\mu|y)\propto \int_0^\infty \sigma^{-n-2}e^{-\frac{(n-1)s^2+n(\bar y-\mu)^2}{2\sigma^2}} d\sigma^2\propto \left[1+\frac{n(\mu-\bar y)^2}{(n-1)s^2}\right]^{-\frac n2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu|y\sim t_{n-1}(\bar y,s^2/n),\ \frac{\mu-\bar y}{s/\sqrt{n}}\Big|y\sim t_{n-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Posterior predictive distribution for a future observation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\tilde y|y \sim t_{n-1}(\bar y,(1+1/n)s^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-estimating-the-speed-of-light&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example: Estimating the speed of light&lt;/h2&gt;
&lt;p&gt;Simon Newcomb set up an experiment in 1882 to measure the speed of light. Newcom measured the amount of time rquired for light to travel a distance of 7442 meters (66 measurements, from Stigler (1977), the data are recorded as deviations from 24800 nanoseconds).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(n=66,\ \bar y = 26.2,\ s = 10.8\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\mu-26.2)/(10.8/\sqrt{66})|y\sim t_{65}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; central posterior interval for &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(26.2\pm 10.8t_{65,0.975}/\sqrt{66}=[23.6,28.8]\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the speed of light is 299792458 m/s, so the true value for &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(23.8\)&lt;/span&gt; nanoseconds&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example-estimating-the-speed-of-light-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example: Estimating the speed of light&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;newcomb.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;normal-data-with-a-conjugate-prior-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normal data with a conjugate prior distribution&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Prior distribution&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\mu|\sigma^2\sim N(\mu_0,\sigma^2/\kappa_0),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma^2\sim \text{Inv-}\chi^2(\nu_0,\sigma^2).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p(\mu,\sigma^2)\propto \sigma^{-1}(\sigma^2)^{-(\nu_0/2+1)}\exp\left(-\frac 1{2\sigma^2}[\nu_0\sigma^2+\kappa_0(\mu_0-\mu)^2]\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;denoted by &lt;span class=&#34;math inline&#34;&gt;\(\text{N-Inv-}\chi^2(\mu_0,\sigma^2_0/\kappa_0;\nu_0,\sigma_0^2)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;normal-data-with-a-conjugate-prior-distribution-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normal data with a conjugate prior distribution&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Posterior distribution&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu,\sigma^2|y\sim \text{N-Inv-}\chi^2(\mu_n,\sigma^2_n/\kappa_n;\nu_n,\sigma_n^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{cases}
\mu_n &amp;amp;= \frac{\kappa_0}{\kappa_0+n}\mu_0+\frac{n}{\kappa_0+n}\bar y\\
\kappa_n &amp;amp;= \kappa_0+n\\
\nu_n&amp;amp;=\nu_0+n\\
\nu_n\sigma_n^2 &amp;amp;= \nu_0\sigma_0^2+(n-1)s^2+\frac{\kappa_0n}{\kappa_0+n}(\bar y-\mu_0)^2
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu|\sigma^2,y\sim N(\mu_n,\sigma^2/\kappa_n)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2|y\sim \text{Inv-}\chi^2(\nu_n,\sigma_n^2)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu|y\sim t_{\nu_n}(\mu_n,\sigma_n^2/\kappa_n)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;multinormal-model-for-categorical-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multinormal model for categorical data&lt;/h2&gt;
&lt;p&gt;The multinomial sampling distribution is used to describe data for which each observation is one of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; possible outcomes. If &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is the vector of counts of the number of observations of each outcome, then
&lt;span class=&#34;math display&#34;&gt;\[p(y|\theta)\propto \prod_{j=1}^k\theta_j^{y_j},\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\sum_{j=1}^k\theta_j=1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conjugate prior&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(\theta|\alpha)\propto \prod_{j=1}^k\theta_j^{\alpha_j-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dirichlet distribution&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Posterior distribution&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(\alpha|\theta)\propto \prod_{j=1}^k\theta_j^{y_j+\alpha_j-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multivariate-normal-model-with-known-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multivariate normal model with known variance&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Likelihood function&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[p(y_1,\dots,y_n|\mu,\Sigma)\propto |\Sigma|^{-n/2}\exp\left(-\frac 12\sum_{i=1}^n(y_i-\mu)^\top\Sigma^{-1}(y_i-\mu)\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conjuate prior&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu\sim N(\mu_0,\Lambda_0)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Posterior distribution&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu|y\sim N(\mu_n,\Lambda_n)\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_n=(\Lambda_n^{-1}+n\Sigma^{-1})^{-1}(\Lambda_0^{-1}\mu_0+n\Sigma^{-1}\bar y)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Lambda_n^{-1} = \Lambda_n^{-1}+n\Sigma^{-1}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;multivariate-normal-model-with-unknown-mean-and-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multivariate normal model with unknown mean and variance&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Prior distribution&lt;/strong&gt;: the normal-inverse-Wishart &lt;span class=&#34;math inline&#34;&gt;\((\mu_0,\Lambda_0/\kappa_0;\nu_0,\Lambda_0)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Sigma\sim \text{Inv-Wishart}_{\nu_0}(\Lambda_0^{-1})\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\mu|\Sigma\sim N(\mu_0,\Sigma/\kappa_0)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[p(\mu,\Sigma)\propto |\Sigma|^{-\frac{\nu_0+d}{2}-1}\exp\left(-\frac{1}{2}tr(\Lambda_0\Sigma^{-1})-\frac {\kappa_0}2(\mu-\mu_0)^\top\Sigma^{-1}(\mu-\mu_0)\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Posterior distribution&lt;/strong&gt;: the normal-inverse-Wishart &lt;span class=&#34;math inline&#34;&gt;\((\mu_n,\Lambda_n/\kappa_n;\nu_0,\Lambda_n)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{cases}
\mu_n &amp;amp;= \frac{\kappa_0}{\kappa_0+n}\mu_0+\frac{n}{\kappa_0+n}\bar y\\
\kappa_n &amp;amp;= \kappa_0+n\\
\nu_n&amp;amp;=\nu_0+n\\
\Lambda_n &amp;amp;= \Lambda_0+\sum_{i=1}^n(y_i-\bar y)(y_i-\bar y)^\top+\frac{\kappa_0n}{\kappa_0+n}(\bar y-\mu_0)(\bar y-\mu_0)^\top
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>第三次作业</title>
      <link>/post/homework3/</link>
      <pubDate>Tue, 25 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/homework3/</guid>
      <description>&lt;p&gt;（课本p.59, 第2题）设&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的分布密度函数为
&lt;span class=&#34;math display&#34;&gt;\[f(x)=\frac{1}{2\sigma} e^{-|x|/\sigma}\ (\sigma&amp;gt;0),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的样本，求&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;的最大似然估计。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;: 似然函数为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\sigma)=\prod_{i=1}^n f(x_i)=\prod_{i=1}^n \left(\frac{1}{2\sigma} e^{-|x_i|/\sigma}\right)=(2\sigma)^{-n}e^{-\sum_{i=1}^n|x_i|/\sigma}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对数似然函数为：
&lt;span class=&#34;math display&#34;&gt;\[\ln L(\sigma) = -n \ln (2\sigma)-\left(\sum_{i=1}^n|x_i|\right)/\sigma.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对数似然方程为：
&lt;span class=&#34;math display&#34;&gt;\[\frac{d \ln L(\sigma)}{d\sigma}=-\frac{n}{\sigma}+\frac{\sum_{i=1}^n|x_i|}{\sigma^2}=0.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其根是&lt;span class=&#34;math inline&#34;&gt;\(\sigma^* = \frac{\sum_{i=1}^n|x_i|}{n}\)&lt;/span&gt;. 又
&lt;span class=&#34;math display&#34;&gt;\[\frac{d^2 \ln L(\sigma)}{d\sigma^2}\Bigg|_{\sigma=\sigma^*}=\frac{n}{\sigma^{*2}}-\frac{2\sum_{i=1}^n|x_i|}{\sigma^{*3}}=-\frac{n}{\sigma^{*2}}&amp;lt;0.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，&lt;span class=&#34;math inline&#34;&gt;\(\ln L(\sigma)\)&lt;/span&gt;在&lt;span class=&#34;math inline&#34;&gt;\(\sigma=\sigma^*\)&lt;/span&gt;处取得最大值，故&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;的最大似然估计为&lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}= \frac{\sum_{i=1}^n|X_i|}{n}\)&lt;/span&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：最终的估计量要用大写字母&lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;表示，这样才是估计量。用小写字母&lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;表示的是估计值，是具体的数值，而不是估计量。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;（课本p.59, 第3题）设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是来自&lt;span class=&#34;math inline&#34;&gt;\([\theta,\theta+1]\)&lt;/span&gt;上均匀分布的样本，其中&lt;span class=&#34;math inline&#34;&gt;\(\theta\in\mathbb{R}\)&lt;/span&gt;, 证明&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的最大似然估计不止一个，并求出所有的最大似然估计。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;证明&lt;/code&gt;：似然函数为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[L(\theta)=\prod_{i=1}^n f(x_i)=\prod_{i=1}^n 1\{\theta\le x_i\le \theta+1\}=1\{x_{(n)}-1\le\theta\le x_{(1)}\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;观察得知，当&lt;span class=&#34;math inline&#34;&gt;\(\theta\in [x_{(n)}-1,x_{(1)}]\)&lt;/span&gt;时，似然函数取得最大值&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. 所以，&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的最大似然估计不止一个，所有的最大似然估计为集合&lt;span class=&#34;math inline&#34;&gt;\([X_{(n)}-1,X_{(1)}]\)&lt;/span&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;（课本p.59, 第4题）设随机变量&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;以均等机会按&lt;span class=&#34;math inline&#34;&gt;\(N(0,1)\)&lt;/span&gt;分布取值和按&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;分布取值，其中&lt;span class=&#34;math inline&#34;&gt;\(\mu\in \mathbb{R},\sigma^2&amp;gt;0\)&lt;/span&gt;. 这时&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的分布密度函数为这两个分布的密度的平均，即
&lt;span class=&#34;math display&#34;&gt;\[f(x;\mu,\sigma^2) = \frac 12\frac{1}{\sqrt{2\pi}}e^{-x^2/2}+\frac 12\frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^2/(2\sigma^2)},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为此混合分布的简单随机样本，证明&lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma^2\)&lt;/span&gt;不存在最大似然估计。能否通过矩法估计&lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma^2\)&lt;/span&gt;？&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;证明&lt;/code&gt;：似然函数为
&lt;span class=&#34;math display&#34;&gt;\[L(\mu,\sigma^2)=\prod_{i=1}^n \left(\frac 12\frac{1}{\sqrt{2\pi}}e^{-x_i^2/2}+\frac 12\frac{1}{\sqrt{2\pi}\sigma}e^{-(x_i-\mu)^2/(2\sigma^2)}\right)\]&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;取&lt;span class=&#34;math inline&#34;&gt;\(\mu=x_1\)&lt;/span&gt;, 则有
&lt;span class=&#34;math display&#34;&gt;\[L(x_1,\sigma^2)\ge \frac{1}{2\sqrt{2\pi}\sigma}\prod_{i=2}^n\left(\frac 12\frac{1}{\sqrt{2\pi}}e^{-x_i^2/2}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;因为&lt;span class=&#34;math inline&#34;&gt;\(\sigma\to 0\)&lt;/span&gt;时，上式右端趋于无穷，所以似然函数&lt;span class=&#34;math inline&#34;&gt;\(L(\mu,\sigma^2)\)&lt;/span&gt;在&lt;span class=&#34;math inline&#34;&gt;\(\mathbb{R}\times[0,\infty)\)&lt;/span&gt;上无界，故最大似然估计不存在。&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;解&lt;/code&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E[X]=\int_{-\infty}^\infty xf(x;\mu,\sigma^2) dx= \frac \mu2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E[X^2] = \int_{-\infty}^\infty x^2f(x;\mu,\sigma^2)dx = \frac{1+\sigma^2+\mu^2}{2} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，
&lt;span class=&#34;math display&#34;&gt;\[\begin{cases}
\mu &amp;amp;= 2E[X]\\
\sigma^2 &amp;amp;= 2E[X^2]-4(E[X])^2-1 = 2Var[X]-2(E[X])^2-1
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;矩估计为：
&lt;span class=&#34;math display&#34;&gt;\[\begin{cases}
\hat{\mu} &amp;amp;= 2\bar X\\
\hat{\sigma^2} &amp;amp;= 2S_n^2-2\bar X^2-1
\end{cases}
\text{ 或者 }\begin{cases}
\hat{\mu} &amp;amp;= \frac{2}{n}\sum_{i=1}^n X_i\\
\hat{\sigma^2} &amp;amp;= \frac 2n\sum_{i=1}^n X_i^2-\frac{4}{n^2}(\sum_{i=1}^nX_i)^2-1
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;（附加题I，选做）考虑上题的模型。设&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;为一随机变量，&lt;span class=&#34;math inline&#34;&gt;\(Y=1\)&lt;/span&gt;表示&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;来自&lt;span class=&#34;math inline&#34;&gt;\(N(0,1)\)&lt;/span&gt;分布，&lt;span class=&#34;math inline&#34;&gt;\(Y=0\)&lt;/span&gt;表示&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;来自&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;分布，即&lt;span class=&#34;math inline&#34;&gt;\(Y\sim b(1,0.5)\)&lt;/span&gt;. 假设我们可以观测&lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt;的值，基于样本&lt;span class=&#34;math inline&#34;&gt;\((X_i,Y_i),i=1,\dots,n\)&lt;/span&gt;，是否可以求出&lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma^2\)&lt;/span&gt;的最大似然估计？事实上，&lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt;的值不可观测（通常称为潜变量），此时你有没有更好的办法估计&lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma^2\)&lt;/span&gt;？&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;：当&lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt;可观测时，似然函数为
&lt;span class=&#34;math display&#34;&gt;\[L(\mu,\sigma^2)=\prod_{i=1}^n \left(\frac{y_i}{\sqrt{2\pi}}e^{-x_i^2/2}+\frac{1-y_i}{\sqrt{2\pi}\sigma}e^{-(x_i-\mu)^2/(2\sigma^2)}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令&lt;span class=&#34;math inline&#34;&gt;\(I = \{i=1,\dots,n|y_i=0\}\)&lt;/span&gt;, 则
&lt;span class=&#34;math display&#34;&gt;\[L(\mu,\sigma^2)=\prod_{i\notin I}\frac{1}{\sqrt{2\pi}}e^{-x_i^2/2}\prod_{i\in I}\frac{1}{\sqrt{2\pi}\sigma}e^{-(x_i-\mu)^2/(2\sigma^2)}\]&lt;/span&gt;
因为&lt;span class=&#34;math inline&#34;&gt;\(\prod_{i\notin I}\frac{1}{\sqrt{2\pi}}e^{-x_i^2/2}\)&lt;/span&gt;与参数&lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma^2\)&lt;/span&gt;无关, 则只需求出
&lt;span class=&#34;math display&#34;&gt;\[\tilde{L}(\mu,\sigma^2):=\prod_{i\in I}\frac{1}{\sqrt{2\pi}\sigma}e^{-(x_i-\mu)^2/(2\sigma^2)}\]&lt;/span&gt;
的最大值点即可。这就等价于求样本为&lt;span class=&#34;math inline&#34;&gt;\(\{X_i,i\in I\}\)&lt;/span&gt;时，正态总体的最大似然估计，所以最大似然估计为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\mu}=\frac{1}{|I|}\sum_{i\in I} X_i,\ \hat{\sigma^2} = \frac{1}{|I|} \sum_{i\in I}(X_i-\hat{\mu})^2 \]&lt;/span&gt;
考虑到&lt;span class=&#34;math inline&#34;&gt;\(I\)&lt;/span&gt;中元素的个数&lt;span class=&#34;math inline&#34;&gt;\(|I|\)&lt;/span&gt;可能为0。当&lt;span class=&#34;math inline&#34;&gt;\(I= \varnothing\)&lt;/span&gt;时，似然函数不含未知参数，此时估计量可以为任意常数。故最终的估计量可以写成&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\mu}=
\begin{cases}
\frac{1}{n-\sum_{i=1}^n Y_i}\sum_{i=1}^n X_i(1-Y_i), &amp;amp; \sum_{i=1}^n Y_i&amp;lt;n\\
c_1, &amp;amp;\sum_{i=1}^n Y_i=n
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat{\sigma^2} = 
\begin{cases}
\frac{1}{n-\sum_{i=1}^n Y_i} \sum_{i=1}^n(X_i-\hat{\mu})^2(1-Y_i), &amp;amp; \sum_{i=1}^n Y_i&amp;lt;n\\
c_2, &amp;amp;\sum_{i=1}^n Y_i=n
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(c_1\in \mathbb{R}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(c_2&amp;gt;0\)&lt;/span&gt;为常数。&lt;/p&gt;
&lt;p&gt;当&lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt;不可观测时，我们可以利用EM算法求出最大似然估计值。参考：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://cs229.stanford.edu/notes/cs229-notes7b.pdf&#34;&gt;Andrew Ng’s lecture notes 1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://cs229.stanford.edu/notes/cs229-notes8.pdf&#34;&gt;Andrew Ng’s lecture notes 2&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;（附加题II，选做）若考虑更一般的混合分布：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x;\lambda,\mu_1,\sigma_1^2,\mu_2,\sigma_2^2)=\frac{\lambda}{\sqrt{2\pi}\sigma_1}e^{-(x-\mu_1)^2/(2\sigma_1^2)}+\frac{1-\lambda}{\sqrt{2\pi}\sigma_2}e^{-(x-\mu_2)^2/(2\sigma_2^2)}\]&lt;/span&gt;
其中&lt;span class=&#34;math inline&#34;&gt;\(\lambda\in[0,1],\mu_1,\mu_2\in \mathbb{R},\sigma_1^2,\sigma_2^2&amp;gt;0\)&lt;/span&gt;, 你能求出未知参数&lt;span class=&#34;math inline&#34;&gt;\(\lambda,\mu_1,\sigma_1^2,\mu_2,\sigma_2^2\)&lt;/span&gt;的矩估计吗？&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;：参考文献: &lt;a href=&#34;paper.pdf&#34;&gt;Estimation in Mixtures of Two Normal Distributions&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;（课本p.59, 第9题）设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是来自分布密度为
&lt;span class=&#34;math display&#34;&gt;\[f(x;\theta)=\frac{\Gamma(\theta+1)}{\Gamma(\theta)\Gamma(1)}x^{\theta-1}1\{0\le x\le 1\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;的总体的样本，其中&lt;span class=&#34;math inline&#34;&gt;\(\theta&amp;gt;0\)&lt;/span&gt;, 试用矩法估计&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E[X]=\int_0^1 x\theta x^{\theta-1}d x=\frac{\theta}{\theta+1}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\theta = \frac{E[X]}{1-E[X]}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，矩估计为
&lt;span class=&#34;math display&#34;&gt;\[\hat\theta =\frac{\bar X}{1-\bar X}=\frac{\sum_{i=1}X_i}{n-\sum_{i=1}^nX_i}\]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;（课本p.60, 第10题）设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是来自分布密度为
&lt;span class=&#34;math display&#34;&gt;\[f(x;c,\theta)=\frac{1}{2\theta}1\{c-\theta\le x\le c+\theta\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;的总体的样本，其中&lt;span class=&#34;math inline&#34;&gt;\(\theta&amp;gt;0,c\in\mathbb{R}\)&lt;/span&gt;, 试用矩法估计&lt;span class=&#34;math inline&#34;&gt;\(c,\theta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;：已知总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim U[c-\theta,c+\theta]\)&lt;/span&gt;, 所以&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E[X]=\frac{(c+\theta)+(c-\theta)}{2}=c\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var[X] = \frac{(2\theta)^2}{12}=\frac{\theta^2}{3}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以矩估计为：
&lt;span class=&#34;math display&#34;&gt;\[\hat{c}=\bar X=\frac 1n\sum_{i=1}^nX_i,\ \hat{\theta} = \sqrt{3S_n^2}=\sqrt{\frac{3}{n}\sum_{i=1}^n(X_i-\bar X)^2}.\]&lt;/span&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>第二章：估计</title>
      <link>/post/chap02/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/chap02/</guid>
      <description>&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;目录&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;1. 点估计&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;1.1 矩估计法&lt;/li&gt;
&lt;li&gt;1.2 极大似然估计法&lt;/li&gt;
&lt;li&gt;1.3 估计的优良性准则&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;2. 区间估计&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;2.1 单个正态总体的区间估计&lt;/li&gt;
&lt;li&gt;2.2 两个独立正态总体的区间估计&lt;/li&gt;
&lt;li&gt;2.3 非正态总体的区间估计&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;3. 分布估计&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;3.1 直方图法&lt;/li&gt;
&lt;li&gt;3.2 核估计法&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;参数估计&lt;/h2&gt;
&lt;p&gt;在实际问题中，对于一个总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;往往是仅知其分布的类型&lt;span class=&#34;math inline&#34;&gt;\(f(x, \theta)\)&lt;/span&gt;，而参数&lt;span class=&#34;math inline&#34;&gt;\(\theta=(\theta_1,\dots,\theta_m)\in \Theta \subset \mathbb{R}^m\)&lt;/span&gt;是未知的。对任给的实值函数&lt;span class=&#34;math display&#34;&gt;\[g:\ \mathbb{R}^m\to \mathbb{R},\]&lt;/span&gt;
如何根据&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的样本&lt;span class=&#34;math inline&#34;&gt;\(x_1,\dots,x_n\)&lt;/span&gt;估计&lt;span class=&#34;math inline&#34;&gt;\(g( \theta)\)&lt;/span&gt;的值呢？这就是统计推断中的“&lt;strong&gt;参数估计&lt;/strong&gt;”问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;点估计&lt;/strong&gt;：寻找一个统计量&lt;span class=&#34;math inline&#34;&gt;\(\hat{ \theta} = T(X_1,\dots,X_n)\)&lt;/span&gt;作为$ $的点估计&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;区间估计&lt;/strong&gt;：寻找两个统计量&lt;span class=&#34;math inline&#34;&gt;\(\hat{ \theta}_1 = T_1(X_1,\dots,X_n)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\hat{ \theta}_2 = T_2(X_1,\dots,X_n)\)&lt;/span&gt;，所构成的区间&lt;span class=&#34;math inline&#34;&gt;\([\hat{ \theta}_1,\hat{ \theta}_2]\)&lt;/span&gt;作为$ $的区间估计&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.1 矩估计法&lt;/h2&gt;
&lt;p&gt;矩估计的想法来源于大数定理。如果总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;存在&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶矩，对任意&lt;span class=&#34;math inline&#34;&gt;\(\epsilon&amp;gt;0\)&lt;/span&gt;,
&lt;span class=&#34;math display&#34;&gt;\[
\lim_{n\to \infty} P(|\frac 1 n\sum_{i=1}^n X_i^k-E[X^k]|\ge \epsilon )=0.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这说明，当样本容量&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;较大时，样本&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶矩与总体&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶矩差别很小。&lt;strong&gt;矩法估计就是用样本&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶矩代替总体的&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶矩。&lt;/strong&gt;通常用&lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}_M\)&lt;/span&gt;表示。一般步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;列出估计式&lt;span class=&#34;math inline&#34;&gt;\(E[X^k]=g_k(\theta_1,\dots,\theta_m),\ k=1,\dots,m.\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;求解关于估计量的方程组&lt;span class=&#34;math inline&#34;&gt;\(\theta_k = \theta_k(E[X^1],\dots,E[X^m])\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;用&lt;span class=&#34;math inline&#34;&gt;\(M_k=\frac 1 n\sum_{i=1}^n X_i^k\)&lt;/span&gt;替代&lt;span class=&#34;math inline&#34;&gt;\(E[X^k]\)&lt;/span&gt;得到矩估计&lt;span class=&#34;math inline&#34;&gt;\(\hat\theta_k = \theta_k(M_1,\dots,M_m)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例1&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：求总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的期望&lt;span class=&#34;math inline&#34;&gt;\(\mu=E[X]\)&lt;/span&gt;与方差&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2=Var[X]\)&lt;/span&gt;的矩估计。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;: (1)列出估计式&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{cases}
E[X] &amp;amp;= \mu\\
E[X^2] &amp;amp;= \mu^2+\sigma^2
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(2)求解关于估计量的方程组
&lt;span class=&#34;math display&#34;&gt;\[
\begin{cases}
\mu &amp;amp;= E[X]\\
\sigma^2 &amp;amp;= E[X^2]-(E[X])^2
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，&lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}_M = \bar X\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\hat{\sigma}^2_M = \frac{1}{n}\sum_{i=1}^n X_i^2-(\bar X)^2 = S_n^2.\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注：不难证明，总体的各阶中心矩的矩估计就是样本各阶中心矩。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例2&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim U[a,b]\)&lt;/span&gt;, 求&lt;span class=&#34;math inline&#34;&gt;\(a,b\)&lt;/span&gt;的矩估计。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;: 易知，&lt;span class=&#34;math inline&#34;&gt;\(E[X]=(a+b)/2,\ Var[X]= (b-a)^2/12\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;所以，
&lt;span class=&#34;math display&#34;&gt;\[
\begin{cases}
a &amp;amp;= E[X]-\sqrt{3Var[X]}\\
b &amp;amp;= E[X]+\sqrt{3Var[X]}
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{cases}
\hat a_M &amp;amp;= \bar{X}-\sqrt{3}S_n\\
\hat b_M &amp;amp;= \bar{X}+\sqrt{3}S_n
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例3&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的分布密度为
&lt;span class=&#34;math display&#34;&gt;\[
f(x)=\frac{\theta}{2}e^{-\theta|x|},\ x\in\mathbb{R}, \theta&amp;gt;0.
\]&lt;/span&gt;
求&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的矩估计。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
E[X]= 0,\ E[X^2]=\int_{-\infty}^{\infty}x^2\frac{\theta}{2}e^{-\theta|x|}d x=\theta\int_{0}^{\infty}x^2e^{-\theta x}d x=\frac{2}{\theta^2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\theta}_M=\sqrt{\frac{2n}{\sum_{i=1}^n X_i^2}}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;除外，还可以由&lt;span class=&#34;math inline&#34;&gt;\(E[|X|]=1/\theta\)&lt;/span&gt;得到另一种矩估计。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.2 最大似然估计法&lt;/h2&gt;
&lt;p&gt;最大似然估计法最早由高斯(C.F.Gauss)提出，后来被 Fisher完善。最大似然估计这一名称也是Fisher给的。这是一个目前仍得到广泛应用的方法。它是建立在最大似然原理基础上的一个统计方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;最大似然原理：最先出现的是概率最大的&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：设有外形完全相同的两个箱子，甲箱中有99个白球和1个黑球，乙箱中有99个黑球和1个白球，今随机地抽取一箱并从中随机抽取一球，结果取得白球，问这球是从哪个箱子中取出？&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;最大似然估计法&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;似然函数&lt;/strong&gt;：
&lt;span class=&#34;math display&#34;&gt;\[L(x_1,\dots,x_n;\theta)=L(\theta)=\prod_{i=1}^{n}f(x_i;\theta)
\]&lt;/span&gt;
给定样本观测值&lt;span class=&#34;math inline&#34;&gt;\((x_1,\dots,x_n)\)&lt;/span&gt;, 记&lt;span class=&#34;math inline&#34;&gt;\(L(x_1,\dots,x_n;\theta)\)&lt;/span&gt;的最大值点为&lt;span class=&#34;math inline&#34;&gt;\(\theta=T(x_1,\dots,x_n)\)&lt;/span&gt;. 则&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的最大似然估计量(MLE, maximum likelihood estimator)为
&lt;span class=&#34;math display&#34;&gt;\[\hat{\theta}_L=T(X_1,\dots,X_n).\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;最大似然估计的一般步骤&lt;/h2&gt;
&lt;p&gt;第一步：写出似然函数&lt;span class=&#34;math inline&#34;&gt;\(L(x_1,\dots,x_n;\theta)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;第二步：若似然函数&lt;span class=&#34;math inline&#34;&gt;\(L\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的可微函数，则最大值必然满足&lt;strong&gt;似然方程&lt;/strong&gt;
&lt;span class=&#34;math display&#34;&gt;\[\frac{d L}{d \theta}=0\]&lt;/span&gt;
解出&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, 并验证其是否是极大值：&lt;span class=&#34;math display&#34;&gt;\[\frac{d^2 L}{d \theta^2}&amp;lt;0.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注1：为方便求导，一般求对数似然函数&lt;span class=&#34;math inline&#34;&gt;\(\ln L(x_1,\dots,x_n;\theta)\)&lt;/span&gt;求极大值点&lt;/p&gt;
&lt;p&gt;注2：若有多个参数&lt;span class=&#34;math inline&#34;&gt;\(\theta_1,\dots,\theta_m\)&lt;/span&gt;，对每个变量求偏导，联立&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;个方程求解&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;10-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例1：0-1离散型&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim B(1,p)\)&lt;/span&gt;, 从中抽取样本&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;的观测值为&lt;span class=&#34;math inline&#34;&gt;\(x_1,\dots,x_n\)&lt;/span&gt;. 求参数&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;的最大似然估计。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;: 似然函数为
&lt;span class=&#34;math display&#34;&gt;\[ L(x_1,\dots,x_n;p)=\prod_{i=1}^{n}p^{x_i}(1-p)^{1-x_i}=p^{\sum_{i=1}^nx_i}(1-p)^{n-\sum_{i=1}^nx_i}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令&lt;span class=&#34;math inline&#34;&gt;\(y=\sum_{i=1}^nx_i\)&lt;/span&gt;, 对数似然函数为：
&lt;span class=&#34;math display&#34;&gt;\[\ln L = y \ln p + (n-y)\ln (1-p).\]&lt;/span&gt;
对数似然方程为：
&lt;span class=&#34;math inline&#34;&gt;\(\frac{d \ln L}{d p} = y/p - (n-y)/(1-p)=0.\)&lt;/span&gt;
解得&lt;span class=&#34;math inline&#34;&gt;\(p= y/n=\frac{1}{n}\sum_{i=1}^nx_i\)&lt;/span&gt;. 因为&lt;span class=&#34;math inline&#34;&gt;\(\frac{d^2\ln L}{d p^2}&amp;lt;0\)&lt;/span&gt;, 所以&lt;span class=&#34;math inline&#34;&gt;\(p= y/n\)&lt;/span&gt;是极大值。&lt;span class=&#34;math inline&#34;&gt;\(\hat{p}_L = \bar X.\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例2：正态分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu,\sigma^2)\)&lt;/span&gt;, 从中抽取样本&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;的观测值为&lt;span class=&#34;math inline&#34;&gt;\(x_1,\dots,x_n\)&lt;/span&gt;. 求参数&lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma^2\)&lt;/span&gt;的最大似然估计。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;: 似然函数为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ L(x_1,\dots,x_n;\mu,\sigma^2)=\prod_{i=1}^{n}f(x_i)=\prod_{i=1}^{n}\frac{1}{\sqrt{2\pi}\sigma}e^{-(x_i-\mu)^2/(2\sigma^2)}\]&lt;/span&gt;
令&lt;span class=&#34;math inline&#34;&gt;\(\theta_1=\mu,\theta_2=\sigma^2\)&lt;/span&gt;, 对数似然函数为：
&lt;span class=&#34;math display&#34;&gt;\[\ln L = (n/2)\ln (2\pi)-(n/2)\ln\theta_2-\frac{\sum_{i=1}^n(x_i-\theta_1)^2}{2\theta_2}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;2-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例2：正态分布&lt;/h2&gt;
&lt;p&gt;对数似然方程组为：
&lt;span class=&#34;math display&#34;&gt;\[
\begin{cases}
\frac{\partial \ln L}{\partial \theta_1} &amp;amp;=\frac{\sum_{i=1}^n(x_i-\theta_1)}{\theta_2}=0\\
\frac{\partial \ln L}{\partial \theta_2} &amp;amp;=-\frac{n}{2\theta_2}+\frac{\sum_{i=1}^n(x_i-\theta_1)^2}{2\theta_2^2}=0
\end{cases}
\]&lt;/span&gt;
解得&lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}_L=\bar X,\ \hat{\sigma}^2_L = S_n^2\)&lt;/span&gt;. (可以验证二阶导函数非正定，即取得极大值。)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;3-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例3&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim U[a,b]\)&lt;/span&gt;, 从中抽取样本&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;的观测值为&lt;span class=&#34;math inline&#34;&gt;\(x_1,\dots,x_n\)&lt;/span&gt;. 求参数&lt;span class=&#34;math inline&#34;&gt;\(a,b\)&lt;/span&gt;的最大似然估计。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;: 似然函数为
&lt;span class=&#34;math display&#34;&gt;\[ L(x_1,\dots,x_n;a,b)=\frac{1}{(b-a)^n}\prod_{i=1}^{n} 1\{a\le x_i\le b\}\]&lt;/span&gt;
注意到&lt;span class=&#34;math inline&#34;&gt;\(L\)&lt;/span&gt;关于&lt;span class=&#34;math inline&#34;&gt;\(a,b\)&lt;/span&gt;不可微。容易观察到，当&lt;span class=&#34;math inline&#34;&gt;\(a=\min_{i=1,\dots,n}\{x_i\},\ b=\max_{i=1,\dots,n}\{x_i\}\)&lt;/span&gt;时&lt;span class=&#34;math inline&#34;&gt;\(L\)&lt;/span&gt;取得最大值。故&lt;span class=&#34;math display&#34;&gt;\[\hat{a}_L = X_{(1)},\ \hat{b}_L = X_{(n)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;关于最大似然估计的一些说明&lt;/h2&gt;
&lt;p&gt;最大似然估计的不变性：如果&lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的最大似然估计，则对任一函数&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;, 其最大似然估计为&lt;span class=&#34;math inline&#34;&gt;\(g(\hat{\theta})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;当分布中有&lt;em&gt;多余的参数&lt;/em&gt;或者&lt;em&gt;数据为截尾或缺失&lt;/em&gt;时，似然函数的求极大值比较困难。针对这种问题，文献&lt;/p&gt;
&lt;p&gt;Dempster, A.P.; Laird, N.M.; Rubin, D.B. (1977). &lt;a href=&#34;https://www.jianguoyun.com/p/DSfhflcQpvLJBhjv42s&#34;&gt;Maximum Likelihood from Incomplete Data via the EM Algorithm&lt;/a&gt;. &lt;em&gt;Journal of the Royal Statistical Society, Series B&lt;/em&gt;. 39 (1): 1–38. (cited by 54539, 2018/8/18)&lt;/p&gt;
&lt;p&gt;提出了一种有效的&lt;strong&gt;Expectation–Maximization (EM)&lt;/strong&gt;算法。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;矩估计与最大似然估计的对比&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;矩估计法（也称数字特征法）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;直观意义比较明显，但要求总体&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶矩存在。&lt;/li&gt;
&lt;li&gt;缺点是不唯一，此时尽量使用样本低阶矩。&lt;/li&gt;
&lt;li&gt;观测值受异常值影响较大，不够稳健，实际中避免使用样本高阶矩。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;极大似然估计法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;具有一些理论上的优点（不变性、渐近正态性）&lt;/li&gt;
&lt;li&gt;缺点是如果似然函数不可微，没有一般的求解法则。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;矩估计与最大似然估计的对比&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;estimations.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.3 估计的优良性标准&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;估计量的无偏性&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;估计量的有效性&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;估计量的大样本性质：相合性与渐近正态性&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;无偏性&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim F(x;\theta),\theta\in \Theta\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的估计量。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;无偏估计量：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E[T(X_1,\dots,X_n)]=g(\theta), \forall \theta\in \Theta\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;渐近无偏估计量：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\lim_{n\to \infty}E[T(X_1,\dots,X_n)]=g(\theta), \forall \theta\in \Theta\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;无偏性意味着：虽然估计量&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;由于随机可能偏离真值&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;, 但取其平均值（期望）却等于&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;. 即没有系统偏差。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;例&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;样本均值是总体的均值的无偏估计，即&lt;span class=&#34;math inline&#34;&gt;\(E[\bar X]=E[X]\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;样本方差是总体方差的渐近无偏估计，即&lt;span class=&#34;math inline&#34;&gt;\(\lim_{n\to \infty}E[S_n^{2}]=Var[X]\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;修正样本方差是总体方差的无偏估计，即&lt;span class=&#34;math inline&#34;&gt;\(E[S_n^{*2}]=Var[X]\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;均方误差&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的估计量，其均方误差 (mean squared error, MSE)为
&lt;span class=&#34;math display&#34;&gt;\[M_{\theta}(T):=E_\theta[(T(X_1,\dots,X_n)-g(\theta))^2].\]&lt;/span&gt;
均方根误差 (root mean squared error, RMSE)为
&lt;span class=&#34;math display&#34;&gt;\[R_{\theta}(T):=\sqrt{E_\theta[(T(X_1,\dots,X_n)-g(\theta))^2]}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意到：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[M_{\theta}(T)=(E[T]-g(\theta))^2+Var(T)=偏差^2+方差\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：如果&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的无偏估计，则&lt;span class=&#34;math inline&#34;&gt;\(M_{\theta}(T)=Var(T)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;比较两个估计量的优劣&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：若&lt;span class=&#34;math inline&#34;&gt;\(T_1(X_1,\dots,X_n)\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(T_2(X_1,\dots,X_n)\)&lt;/span&gt;都为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的估计量，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果&lt;span class=&#34;math inline&#34;&gt;\(M_{\theta}(T_1)\le M_{\theta}(T_2),\forall \theta\in \Theta\)&lt;/span&gt;, 则称&lt;span class=&#34;math inline&#34;&gt;\(T_1\)&lt;/span&gt;不次于&lt;span class=&#34;math inline&#34;&gt;\(T_2\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;在此基础上，如果存在一个&lt;span class=&#34;math inline&#34;&gt;\(\theta_0\in\Theta\)&lt;/span&gt;使得&lt;span class=&#34;math inline&#34;&gt;\(M_{\theta_0}(T_1)&amp;lt; M_{\theta_0}(T_2)\)&lt;/span&gt;, 则称&lt;span class=&#34;math inline&#34;&gt;\(T_1\)&lt;/span&gt;比&lt;span class=&#34;math inline&#34;&gt;\(T_2\)&lt;/span&gt;有效。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的期望&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;方差为&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为其样本(&lt;span class=&#34;math inline&#34;&gt;\(n&amp;gt;1\)&lt;/span&gt;)，证明下列估计量&lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu} = \sum_{i=1} C_iX_i\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的无偏估计的充要条件是&lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^nC_i = 1.\)&lt;/span&gt; 在满足该条件前提下，&lt;span class=&#34;math inline&#34;&gt;\(C_i\)&lt;/span&gt;取何值时，&lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}\)&lt;/span&gt;的最有效。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(E[\hat{\mu}]=\mu\Leftrightarrow \sum_{i=1}^nC_i = 1\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[Var[\hat{\mu}]=\sigma^2\sum_{i=1}^nC_i^2\ge \sigma^2\frac{(C_1+\dots+C_n)^2}{n}=\frac{\sigma^2}{n}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;而且唯一的最小值在&lt;span class=&#34;math inline&#34;&gt;\(C_i=1/n,i=1,\dots,n\)&lt;/span&gt;处取得。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;一致最小方差无偏估计&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：如果&lt;span class=&#34;math inline&#34;&gt;\(T_0(X_1,\dots,X_n)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的无偏估计，如果对于&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的任意无偏估计量&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;都有
&lt;span class=&#34;math display&#34;&gt;\[Var[T_0]\le Var[T],\ \forall\theta\in\Theta\]&lt;/span&gt;
则称&lt;span class=&#34;math inline&#34;&gt;\(T_0\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的&lt;strong&gt;一致最小方差无偏估计量&lt;/strong&gt; (uniformly minimum-variance unbiased estimator, UMVUE)。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;思考&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;无偏估计量是不是一定存在？（反例见课本例2.5, p27）&lt;/li&gt;
&lt;li&gt;如果存在多个无偏估计量，如何找到UMVUE？（Blackwell, Rao, Lehmann, Scheffe等统计学家获得了一系列寻求UMVUE的理论和方法）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;black-lehmann-scheffe&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Black-Lehmann-Scheffe定理&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;为统计量。如果对任何(Borel可测)函数&lt;span class=&#34;math inline&#34;&gt;\(u(\cdot)\)&lt;/span&gt;, 只要&lt;span class=&#34;math inline&#34;&gt;\(E[u(T)]=0\)&lt;/span&gt;(对一切&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;)就可以推出&lt;span class=&#34;math inline&#34;&gt;\(P(u(T)=0)=1\)&lt;/span&gt;, 这次称统计量&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;为&lt;em&gt;完全的统计量&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;B-L-S定理&lt;/strong&gt;：如果&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;为&lt;em&gt;完全的充分统计量&lt;/em&gt;，&lt;span class=&#34;math inline&#34;&gt;\(\psi(T)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的无偏估计，则&lt;span class=&#34;math inline&#34;&gt;\(\psi(T)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的最小方差无偏估计。&lt;/p&gt;
&lt;div id=&#34;section&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;：可以证明，如果参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的集合有内点，则指数型分布族的充分统计量
&lt;span class=&#34;math inline&#34;&gt;\(\left(\sum_{i=1}^nT_1(x_i),\dots,\sum_{i=1}^nT_k(x_i)\right)\)&lt;/span&gt;
是完全的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;cramer-rao&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cramer-Rao不等式&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的密度为&lt;span class=&#34;math inline&#34;&gt;\(f(x;\theta)\)&lt;/span&gt;, 参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\in (a,b)\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的样本，&lt;span class=&#34;math inline&#34;&gt;\(\psi(X_1,\dots,X_n)\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的一个无偏估计，且满足下列正则性条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的支撑与&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;无关；&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(g&amp;#39;(\theta)\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(\frac{df(x;\theta)}{d\theta}\)&lt;/span&gt;都存在且对一切&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;有&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\int_{-\infty}^\infty \frac{df(x;\theta)}{d\theta} d x = 0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\int_{-\infty}^\infty\frac d{d\theta} L(\vec x;\theta) d \vec x=0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac d{d\theta}\int_{-\infty}^\infty \psi(\vec x) L(\vec x;\theta) d \vec x=\int_{-\infty}^\infty \psi(\vec x) \frac d{d\theta}L(\vec x;\theta) d \vec x\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cramer-rao-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cramer-Rao不等式&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(I(\theta):=E[(\frac {d\ln f(X;\theta)}{d\theta})^2]&amp;gt;0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;则有
&lt;span class=&#34;math display&#34;&gt;\[Var_\theta[\psi(X_1,\dots,X_n)]\ge \frac{[g&amp;#39;(\theta)]^2}{nI(\theta)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;证明见p. 28&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(I(\theta)\)&lt;/span&gt;叫做&lt;strong&gt;Fisher信息量&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;离散情形有类似的结论&lt;/li&gt;
&lt;li&gt;C-R不等式的下界不一定达到，见例2.9, p30.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例&lt;/h2&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu,\sigma^2)\)&lt;/span&gt;, 其中&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;未知，&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;已知。
Fisher信息量为
&lt;span class=&#34;math display&#34;&gt;\[I(\mu) = E[(\frac {d\ln f(X;\mu)}{d\mu})^2]=\frac 1{\sigma^4}E[(X-\mu)^2]=\frac 1{\sigma^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var[\bar X] = \frac{\sigma^2}{n}=\frac{1}{nI(\mu)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;可以证明：若&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;已知，则&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的估计量&lt;span class=&#34;math inline&#34;&gt;\(\frac 1n\sum_{i=1}^n(X_i-\mu)^2\)&lt;/span&gt;的方差达到了C-R不等式的下界。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;统计量的大样本性质&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;统计量的相合性&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;统计量的渐近正态性&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;统计量的相合性&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;（弱）相合估计&lt;/strong&gt;：称&lt;span class=&#34;math inline&#34;&gt;\(T_n(X_1,\dots,X_n)\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的相合估计，如果对任何
&lt;span class=&#34;math inline&#34;&gt;\(\epsilon&amp;gt;0\)&lt;/span&gt;, 有&lt;span class=&#34;math display&#34;&gt;\[\lim_{n\to\infty}P(|T_n-g(\theta)|\ge \epsilon)=0.\]&lt;/span&gt; 等价于依概率收敛&lt;span class=&#34;math inline&#34;&gt;\(T_n\stackrel p\to g(\theta)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;强相合估计&lt;/strong&gt;：称&lt;span class=&#34;math inline&#34;&gt;\(T_n(X_1,\dots,X_n)\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的强相合估计，如果&lt;span class=&#34;math display&#34;&gt;\[P(\lim_{n\to\infty}T_n=g(\theta))=1.\]&lt;/span&gt; 等价于概率1收敛&lt;span class=&#34;math inline&#34;&gt;\(T_n\stackrel {w.p.1}\to g(\theta)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由强大数定理知，矩估计一般是强估计的&lt;/li&gt;
&lt;li&gt;最大似然估计在十分广泛的条件下也是有强相合性（见p31)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例&lt;/h2&gt;
&lt;p&gt;设总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的期望&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;方差为&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为其样本，证明&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;样本均值&lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的相合估计量；&lt;/li&gt;
&lt;li&gt;样本&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶原点矩&lt;span class=&#34;math inline&#34;&gt;\(M_k\)&lt;/span&gt;是总体&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶原点矩&lt;span class=&#34;math inline&#34;&gt;\(E[X^k]\)&lt;/span&gt;的相合估计量；&lt;/li&gt;
&lt;li&gt;样本方差&lt;span class=&#34;math inline&#34;&gt;\(S_n^2\)&lt;/span&gt;和修正样本方差&lt;span class=&#34;math inline&#34;&gt;\(S_n^{2*}\)&lt;/span&gt;都是&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的相合估计量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;证明&lt;/strong&gt;：由辛钦大数定律知，&lt;span class=&#34;math inline&#34;&gt;\(\bar X\stackrel p\to \mu\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(M_k\stackrel p\to E[X^k]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[S_n^2 = \frac{1}{n}\sum_{i=1}^nX_i^2-\bar X^2\stackrel p\to E[X^2]-E[X]^2=\sigma^2\]&lt;/span&gt;
同理，&lt;span class=&#34;math inline&#34;&gt;\(S_n^{2*}=\frac{n-1}{n}S_n^2\stackrel p\to \sigma^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：这里用到依概率收敛的性质：假设&lt;span class=&#34;math inline&#34;&gt;\(X_n\stackrel p\to X,\ Y_n\stackrel p\to Y\)&lt;/span&gt;. 则&lt;span class=&#34;math inline&#34;&gt;\(X_n+Y_n\stackrel p\to X+Y\)&lt;/span&gt;. 如果&lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;连续，则&lt;span class=&#34;math inline&#34;&gt;\(g(X_n)\stackrel p\to g(X)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(g(X_n,Y_n)\stackrel p\to g(X,Y)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;相合估计的充分条件&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim F(x;\theta),\ \theta\in \Theta\)&lt;/span&gt;, 统计量&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的估计量。如果
&lt;span class=&#34;math display&#34;&gt;\[\lim_{n\to \infty}E[T(X_1,\dots,X_n)] = g(\theta),\ \lim_{n\to \infty}Var[T(X_1,\dots,X_n)] =0,\]&lt;/span&gt;
则&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的相合估计量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;证明&lt;/strong&gt;：令&lt;span class=&#34;math inline&#34;&gt;\(T_n=T(X_1,\dots,X_n)\)&lt;/span&gt;.
注意到&lt;span class=&#34;math display&#34;&gt;\[\{|T_n-g(\theta)|\ge \epsilon\}\subset \{|T_n-E[T_n]|\ge \epsilon/2\}\cup \{|E[T_n]-g(\theta)|\ge \epsilon/2\}.\]&lt;/span&gt;
对任意&lt;span class=&#34;math inline&#34;&gt;\(\epsilon&amp;gt;0\)&lt;/span&gt;, 存在&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;, 当&lt;span class=&#34;math inline&#34;&gt;\(n\ge N\)&lt;/span&gt;时，&lt;span class=&#34;math inline&#34;&gt;\(|E[T_n]-g(\theta)|&amp;lt; \epsilon/2\)&lt;/span&gt;.
此时&lt;span class=&#34;math display&#34;&gt;\[\{|T_n-g(\theta)|\ge \epsilon \}\subset \{|T_n-E[T_n]|\ge \epsilon/2\}\]&lt;/span&gt;
所以，
&lt;span class=&#34;math display&#34;&gt;\[P(|T_n-g(\theta)|\ge \epsilon)\le P(|T_n-E[T_n]|\ge \epsilon/2)\le \frac{4 VaR[T_n]}{\epsilon^2}\to 0.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;统计量的渐近正态性&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的估计量。如果存在一个趋于零的正数列&lt;span class=&#34;math inline&#34;&gt;\(\sigma_n(\theta)\)&lt;/span&gt;, 使得&lt;span class=&#34;math inline&#34;&gt;\([T-g(\theta)]/\sigma_n(\theta)\)&lt;/span&gt;的分布收敛到标准正态分布，则称&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的&lt;strong&gt;渐近正态估计&lt;/strong&gt;，或称&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;具备&lt;strong&gt;渐近正态性&lt;/strong&gt;，即&lt;span class=&#34;math display&#34;&gt;\[T\stackrel{\cdot}{\sim} N(\theta, \sigma_n(\theta)^2).\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;最大似然估计的渐近正态性&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的密度为&lt;span class=&#34;math inline&#34;&gt;\(f(x;\theta)\)&lt;/span&gt;, 其参数空间&lt;span class=&#34;math inline&#34;&gt;\(\Theta\)&lt;/span&gt;是非退化区间，且满足下列正则性条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;对一切&lt;span class=&#34;math inline&#34;&gt;\(\theta\in\Theta\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial \ln f}{\partial\theta}, \frac{\partial^2 \ln f}{\partial\theta^2}, \frac{\partial^3 \ln f}{\partial\theta^3}\)&lt;/span&gt; 都存在&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;对一切&lt;span class=&#34;math inline&#34;&gt;\(\theta\in\Theta\)&lt;/span&gt;, 有&lt;span class=&#34;math inline&#34;&gt;\(|\frac{\partial \ln f}{\partial\theta}|&amp;lt;F_1(x),\ |\frac{\partial^2 \ln f}{\partial\theta^2}|&amp;lt;F_2(x),\ |\frac{\partial^3 \ln f}{\partial\theta^3}|&amp;lt;H(x),\)&lt;/span&gt; 其中&lt;span class=&#34;math inline&#34;&gt;\(F_1(x),F_2(x)\)&lt;/span&gt;在实数轴上可积，且&lt;span class=&#34;math inline&#34;&gt;\(\int_{-\infty}^\infty H(x)f(x;\theta)dx&amp;lt;M\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;与&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;无关。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;对一切&lt;span class=&#34;math inline&#34;&gt;\(\theta\in\Theta\)&lt;/span&gt;, 有&lt;span class=&#34;math inline&#34;&gt;\(0&amp;lt;I(\theta)=E[(\frac{\partial \ln f}{\partial\theta})^2]&amp;lt;\infty\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;则在参数真值&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(\Theta\)&lt;/span&gt;内点的情况下，其似然方程有一个解&lt;span class=&#34;math inline&#34;&gt;\(\hat{\theta}_L\)&lt;/span&gt;存在，且&lt;span class=&#34;math display&#34;&gt;\[\hat{\theta}_L\stackrel{p}{\to}\theta,\ \hat{\theta}_L\stackrel{\cdot}{\sim} N(\theta,[nI(\theta)]^{-1}).\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;.-.--1992&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;证明参考：陈希孺. 概率论与数理统计. 中国科技大学出版社, 1992&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2 区间估计&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;区间估计的定义&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;单个正态总体的区间估计&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;两个独立正态总体的区间估计&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;非正态总体的区间估计&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;区间估计的定义&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim F(x;\theta),\ \theta\in \Theta\)&lt;/span&gt;. 如果统计量&lt;span class=&#34;math inline&#34;&gt;\(T_1(X_1,\dots,X_n),T_2(X_1,\dots,X_n)\)&lt;/span&gt;使得对给定的&lt;span class=&#34;math inline&#34;&gt;\(\alpha\in(0,1)\)&lt;/span&gt;有
&lt;span class=&#34;math display&#34;&gt;\[P(T_1\le g(\theta)\le T_2)=1-\alpha,\ \forall \theta\in\Theta,\]&lt;/span&gt;
则称随机区间&lt;span class=&#34;math inline&#34;&gt;\([T_1,T_2]\)&lt;/span&gt;为参数&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的&lt;strong&gt;置信度（置信概率）&lt;/strong&gt;为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的&lt;strong&gt;置信区间&lt;/strong&gt;，&lt;span class=&#34;math inline&#34;&gt;\(T_1,T_2\)&lt;/span&gt;分别称为&lt;strong&gt;置信下界&lt;/strong&gt;和&lt;strong&gt;置信上界&lt;/strong&gt;。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;说明&lt;/h3&gt;
&lt;p&gt;在一些情况下，定义中的“等式”无解，此时考虑的置信区间&lt;span class=&#34;math inline&#34;&gt;\([T_1,T_2]\)&lt;/span&gt;应满足
&lt;span class=&#34;math display&#34;&gt;\[P(T_1\le g(\theta)\le T_2)\ge 1-\alpha,\ \forall \theta\in\Theta.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;置信区间示意图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;CI.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;区间估计基本步骤——枢轴量法&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：找到&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的区间估计，置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Step 1: 选择恰当的&lt;strong&gt;枢轴量&lt;/strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(G(X_1,\dots,X_n;g(\theta))\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt;不含有其他未知参数&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt;的分布确定，即不含未知参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;一般地，&lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt;是关于参数&lt;span class=&#34;math inline&#34;&gt;\(g(\theta)\)&lt;/span&gt;的单调函数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Step 2: 求&lt;span class=&#34;math inline&#34;&gt;\(a,b\)&lt;/span&gt;使得&lt;span class=&#34;math inline&#34;&gt;\(P(a\le G\le b)=1-\alpha\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 3: 转化不等式&lt;span class=&#34;math inline&#34;&gt;\(a\le G\le b\)&lt;/span&gt;为如下形式：
&lt;span class=&#34;math display&#34;&gt;\[T_1\le g(\theta)\le T_2.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;指数分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：若总体为指数分布&lt;span class=&#34;math inline&#34;&gt;\(Exp(\lambda)\)&lt;/span&gt;，求未知参数&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的置信区间。&lt;/p&gt;
&lt;p&gt;Step 1: 选择枢轴量
&lt;span class=&#34;math display&#34;&gt;\[G(X_1,\dots,X_n;\lambda) = 2\lambda  n\bar X\sim Ga(n,1/2)=\chi^2(2n)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 2: 求&lt;span class=&#34;math inline&#34;&gt;\(a,b\)&lt;/span&gt;使得&lt;span class=&#34;math inline&#34;&gt;\(P(a\le G\le b)=1-\alpha\)&lt;/span&gt;，即
&lt;span class=&#34;math display&#34;&gt;\[P(a\le 2\lambda  n\bar X\le b)=1-\alpha\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Step 3: &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的置信区间为&lt;span class=&#34;math inline&#34;&gt;\([a/(2n\bar X),b/(2n\bar X)]\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;ab&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;如何选择&lt;span class=&#34;math inline&#34;&gt;\(a,b\)&lt;/span&gt;?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;平分法：&lt;span class=&#34;math inline&#34;&gt;\(a=\chi^2_{\alpha/2}(2n), b=\chi^2_{1-\alpha/2}(2n)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;最优方案？参考书p35&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;平分法示意图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;chiCI.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;2.1 单个正态总体的区间估计&lt;/h2&gt;
&lt;p&gt;设总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu,\sigma^2)\)&lt;/span&gt;, 如何找出未知参数&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的置信区间？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;已知&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;, 找出&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的置信区间&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;未知&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;, 找出&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的置信区间&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;已知&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, 找出&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的置信区间&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;未知&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, 找出&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的置信区间&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;已知方差，求期望的置信区间&lt;/h2&gt;
&lt;p&gt;由抽样定理知，&lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\sim N(\mu,\sigma^2/n)\)&lt;/span&gt;. 因此
&lt;span class=&#34;math inline&#34;&gt;\(U = \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim N(0,1)\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[P\left(a\le \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\le b\right) = 1-\alpha\]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间为&lt;span class=&#34;math display&#34;&gt;\[\left[\bar{X}-b\frac{\sigma}{\sqrt{n}},\  \bar{X}-a\frac{\sigma}{\sqrt{n}}\right]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最优的选择&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(b=-a=u_{1-\alpha/2}\)&lt;/span&gt;, 此时置信区间为：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left[\bar{X}-u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}},\  \bar{X}+u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\right]=\bar{X}\pm u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;方差未知，求期望的置信区间&lt;/h2&gt;
&lt;p&gt;由抽样定理知，
&lt;span class=&#34;math display&#34;&gt;\[T = \frac{\bar{X}-\mu}{S_n/\sqrt{n-1}}= \frac{\bar{X}-\mu}{S_n^*/\sqrt{n}}\sim t(n-1)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[P\left(a\le \frac{\bar{X}-\mu}{S_n^*/\sqrt{n}}\le b\right) = 1-\alpha\]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间为：
&lt;span class=&#34;math display&#34;&gt;\[\left[\bar{X}-b\frac{S_n^*}{\sqrt{n}},\  \bar{X}-a\frac{S_n^*}{\sqrt{n}}\right]=\left[\bar{X}-b\frac{S_n}{\sqrt{n-1}},\  \bar{X}-a\frac{S_n}{\sqrt{n-1}}\right]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最优的选择&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(b=-a=t_{1-\alpha/2}(n-1)\)&lt;/span&gt;, 此时置信区间为：
&lt;span class=&#34;math display&#34;&gt;\[\left[\bar{X}-t_{1-\alpha/2}(n-1)\frac{S_n^*}{\sqrt{n}},\  \bar{X}+t_{1-\alpha/2}(n-1)\frac{S_n^*}{\sqrt{n}}\right]=\bar{X}\pm t_{1-\alpha/2}(n-1)\frac{S_n^*}{\sqrt{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：假设OPPO手机充电五分钟通话时间&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu,\sigma^2)\)&lt;/span&gt;. 随机抽取6部手机测试通话时间（单位：小时）为
&lt;span class=&#34;math display&#34;&gt;\[1.6,\ 2.1,\ 1.9,\ 1.8,\ 2.2,\ 2.1,\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;已知&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2=0.06\)&lt;/span&gt;, 求&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt;的置信区间。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;未知, 求&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt;的置信区间。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;查表知，&lt;span class=&#34;math inline&#34;&gt;\(u_{1-\alpha/2}=u_{0.975}=1.96,\ t_{1-\alpha/2}=t_{0.975}=2.5706\)&lt;/span&gt;. 且&lt;span class=&#34;math inline&#34;&gt;\(\bar X = 1.95,\ S_n=0.206\)&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\left[1.95-1.96\frac{\sqrt{0.06}}{\sqrt{6}},\  1.95+1.96\frac{\sqrt{0.06}}{\sqrt{6}}\right]=[1.754,\ 2.146]\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\left[1.95-2.5706\frac{0.206}{\sqrt{6-1}},\  1.95+2.5706\frac{0.206}{\sqrt{6-1}}\right]=[1.713,\ 2.187]\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;一些思考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;分析这两种的结果会发现，由同一组样本观察值，按同样的置信概率，对&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;计算出的置信区间因为&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;的是否已知会不一样。这因为：当&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;为已知时，我们掌握的信息多一些，在其他条件相同的情况下，对&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的估计精度要高一些，即表现为&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的置信区间长度要小些。反之，当&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;为未知时，对&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的估计精度要低一些，即表现为&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的置信区间长度在大一些。这是因为当&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;比较小时，&lt;span class=&#34;math inline&#34;&gt;\(t_{1-\alpha/2}(n-1)&amp;gt;u_{1-\alpha/2}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;还可以发现，当样本量&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;不断增大时，两种情况下的置信区间会慢慢接近。
也就意味着大样本信息可以弥补&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;的缺失带来的偏差（&lt;strong&gt;大数定律&lt;/strong&gt;）。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;已知期望，求方差的置信区间&lt;/h2&gt;
&lt;p&gt;构造统计量
&lt;span class=&#34;math display&#34;&gt;\[T =\sum_{i=1}^n\frac{(X_i-\mu)^2}{\sigma^2}\sim \chi^2(n)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[P\left(\chi^2_{\alpha/2}(n)\le\sum_{i=1}^n\frac{(X_i-\mu)^2}{\sigma^2}\le \chi^2_{1-\alpha/2}(n)\right) = 1-\alpha\]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间为：
&lt;span class=&#34;math display&#34;&gt;\[\left[\frac{\sum_{i=1}^n(X_i-\mu)^2}{\chi^2_{1-\alpha/2}(n)},\  \frac{\sum_{i=1}^n(X_i-\mu)^2}{\chi^2_{\alpha/2}(n)}\right]\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;期望未知，求方差的置信区间&lt;/h2&gt;
&lt;p&gt;构造统计量
&lt;span class=&#34;math display&#34;&gt;\[T =\frac{nS_n^2}{\sigma^2}=\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}\sim \chi^2(n-1)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[P\left(\chi^2_{\alpha/2}(n-1)\le\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}\le \chi^2_{1-\alpha/2}(n-1)\right) = 1-\alpha\]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间为：
&lt;span class=&#34;math display&#34;&gt;\[\left[\frac{\sum_{i=1}^n(X_i-\bar X)^2}{\chi^2_{1-\alpha/2}(n-1)},\  \frac{\sum_{i=1}^n(X_i-\bar X)^2}{\chi^2_{\alpha/2}(n-1)}\right]=\left[\frac{nS_n^2}{\chi^2_{1-\alpha/2}(n-1)},\  \frac{nS_n^2}{\chi^2_{\alpha/2}(n-1)}\right]\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;2.2 两个独立正态总体的区间估计&lt;/h2&gt;
&lt;p&gt;设两个独立总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu_1,\sigma_1^2)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu_2,\sigma^2)\)&lt;/span&gt;, 如何找出未知参数&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的置信区间？其中&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的样本为&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_m\)&lt;/span&gt;, 样本方差为&lt;span class=&#34;math inline&#34;&gt;\(S_{1m}^2\)&lt;/span&gt;; &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;的样本为&lt;span class=&#34;math inline&#34;&gt;\(Y_1,\dots,Y_n\)&lt;/span&gt;, 样本方差为&lt;span class=&#34;math inline&#34;&gt;\(S_{2n}^2\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;已知&lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2,\sigma_2^2\)&lt;/span&gt;, 找出&lt;span class=&#34;math inline&#34;&gt;\(\mu_1-\mu_2\)&lt;/span&gt;的置信区间&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;以知&lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2=\sigma_2^2=\sigma^2\)&lt;/span&gt;, 找出&lt;span class=&#34;math inline&#34;&gt;\(\mu_1-\mu_2\)&lt;/span&gt;的置信区间&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;已知&lt;span class=&#34;math inline&#34;&gt;\(\mu_1,\mu_2\)&lt;/span&gt;, 找出&lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2/\sigma_2^2\)&lt;/span&gt;的置信区间&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;未知&lt;span class=&#34;math inline&#34;&gt;\(\mu_1,\mu_2\)&lt;/span&gt;, 找出&lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2/\sigma_2^2\)&lt;/span&gt;的置信区间&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;应用场景&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;比较男生、女生两个群体的身高/体重/成绩平均水平的差异&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;已知方差，求均值差的置信区间&lt;/h2&gt;
&lt;p&gt;选择枢轴量：
&lt;span class=&#34;math display&#34;&gt;\[U=\frac{(\bar X-\bar Y)-(\mu_1-\mu_2)}{\sqrt{\sigma_1^2/m+\sigma_2^2/n}}\sim N(0,1).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_1-\mu_2\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间为：
&lt;span class=&#34;math display&#34;&gt;\[\left[(\bar{X}-\bar{Y})-u_{1-\alpha/2}\sqrt{\frac{\sigma_1^2}m+\frac{\sigma_2^2}n},\  (\bar{X}-\bar{Y})+u_{1-\alpha/2}\sqrt{\frac{\sigma_1^2}m+\frac{\sigma_2^2}n}\right]\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;已知方差相同，求均值差的置信区间&lt;/h2&gt;
&lt;p&gt;选择枢轴量：
&lt;span class=&#34;math display&#34;&gt;\[T=\frac{(\bar X-\bar Y)-(\mu_1-\mu_2)}{S_w\sqrt{1/m+1/n}}\sim t(m+n-2).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(S_w =\sqrt{(mS_{1m}^2+nS_{2n}^2)/(m+n-2)}.\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令&lt;span class=&#34;math inline&#34;&gt;\(t_{1-\alpha/2}(m+n-2)=t_{1-\alpha/2}\)&lt;/span&gt;，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_1-\mu_2\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间为：
&lt;span class=&#34;math display&#34;&gt;\[\left[(\bar{X}-\bar{Y})-t_{1-\alpha/2}S_w\sqrt{\frac 1m+\frac 1n},\  (\bar{X}-\bar{Y})+t_{1-\alpha/2}S_w\sqrt{\frac 1m+\frac 1n}\right]\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-4&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：假设OPPO手机充电五分钟通话时间&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu_1,\sigma_1^2)\)&lt;/span&gt;, VIVO手机充电五分钟通话时间&lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu_2,\sigma_2^2)\)&lt;/span&gt;. 随机抽取6部手机测试通话时间（单位：小时）为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{OPPO}:\ 1.6,\   2.1,\  1.9,\  1.8,\   2.2,\   2.1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{VIVO}:\ 1.8,\   2.2,\ 1.5,\   1.4,\   2.0,\   1.7\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;求&lt;span class=&#34;math inline&#34;&gt;\(\mu_1-\mu_2\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt;的置信区间:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;已知&lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2 = 0.06,\ \sigma_2^2 = 0.08\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;已知&lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2 =\sigma_2^2\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;解&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(m=n=6\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}=1.95,\ \bar{Y}=1.77\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(S_{1m}^2=0.042, S_{2n}^2=0.064, S_w = 0.252.\)&lt;/span&gt; 查表知，&lt;span class=&#34;math inline&#34;&gt;\(u_{0.975}=1.96\)&lt;/span&gt;,
&lt;span class=&#34;math inline&#34;&gt;\(t_{0.975}(10)=2.23\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一种情况为&lt;span class=&#34;math inline&#34;&gt;\([-0.12,\ 0.48]\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;第二种情况为&lt;span class=&#34;math inline&#34;&gt;\([-0.14,\ 0.50]\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;已知均值，求方差比的置信区间&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T_1 =\sum_{i=1}^m\frac{(X_i-\mu_1)^2}{\sigma_1^2}\sim \chi^2(m),\ T_2 =\sum_{i=1}^n\frac{(Y_i-\mu_2)^2}{\sigma_2^2}\sim \chi^2(n)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{T_1/m}{T_2/n}=\frac{\frac 1 m\sum_{i=1}^m(X_i-\mu_1)^2}{\frac 1 n\sum_{i=1}^n(Y_i-\mu_2)^2}\frac{\sigma_2^2}{\sigma_1^2}\sim F(m,n)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2/\sigma_2^2\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间为：
&lt;span class=&#34;math display&#34;&gt;\[\left[\frac{1}{F_{1-\alpha/2}(m,n)}\frac{\frac 1 m\sum_{i=1}^m(X_i-\mu_1)^2}{\frac 1 n\sum_{i=1}^n(Y_i-\mu_2)^2},\ \frac{1}{F_{\alpha/2}(m,n)}\frac{\frac 1 m\sum_{i=1}^m(X_i-\mu_1)^2}{\frac 1 n\sum_{i=1}^n(Y_i-\mu_2)^2}  \right]\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;均值未知，求方差比的置信区间&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T_1=\frac{(m-1)S_{1m}^{*2}}{\sigma_1^2}=\sum_{i=1}^m\frac{(X_i-\bar X)^2}{\sigma_1^2}\sim \chi^2(m-1)\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[T_2=\frac{(n-1)S_{2n}^{*2}}{\sigma_2^2}=\sum_{i=1}^n\frac{(Y_i-\bar Y)^2}{\sigma_2^2}\sim \chi^2(n-1)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\frac{T_1/(m-1)}{T_2/(n-1)}=\frac{S_{1m}^{*2}}{S_{2n}^{*2}}\frac{\sigma_2^2}{\sigma_1^2}\sim F(m-1,n-1)\]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\sigma_1^2/\sigma_2^2\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的置信区间为：
&lt;span class=&#34;math display&#34;&gt;\[\left[\frac{1}{F_{1-\alpha/2}(m-1,n-1)}\frac{S_{1m}^{*2}}{S_{2n}^{*2}},\ \frac{1}{F_{\alpha/2}(m-1,n-1)}\frac{S_{1m}^{*2}}{S_{2n}^{*2}}  \right]\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;一些说明&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;枢轴量法的难点在于寻找枢轴量，没有统一的方法。正态总体下的应用应当熟练掌握。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;另外一种求置信区间方法叫&lt;strong&gt;统计量方法&lt;/strong&gt;，不作要求，感兴趣参考教材pp42-46.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“最优的置信区间”是否存在？目前尚缺乏对置信区间的优良性讨论。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;2.3 非正态总体参数的区间估计&lt;/h2&gt;
&lt;p&gt;令&lt;span class=&#34;math inline&#34;&gt;\(\mu=E[X],\sigma^2=Var[X]\)&lt;/span&gt;分别为总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的期望和方差。
由中心极限定理，
&lt;span class=&#34;math display&#34;&gt;\[\frac{\bar X-\mu}{\sigma/\sqrt{n}}\stackrel{\cdot}\sim N(0,1).\]&lt;/span&gt;
当&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;已知时，总体期望&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的置信度为&lt;span class=&#34;math inline&#34;&gt;\(1-\alpha\)&lt;/span&gt;的区间估计可以近似为
&lt;span class=&#34;math display&#34;&gt;\[\left[\bar X-u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}, \bar X+u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\right].\]&lt;/span&gt;
如果&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;未知，可以用样本标准差&lt;span class=&#34;math inline&#34;&gt;\(S_n\)&lt;/span&gt;（或者修正样本差&lt;span class=&#34;math inline&#34;&gt;\(S_n^*\)&lt;/span&gt;）替代&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;，
&lt;span class=&#34;math display&#34;&gt;\[\left[\bar X-u_{1-\alpha/2}\frac{S_n}{\sqrt{n}}, \bar X+u_{1-\alpha/2}\frac{S_n}{\sqrt{n}}\right].\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;3 分布的估计&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;分布函数的估计&lt;/li&gt;
&lt;li&gt;密度函数的直方图估计&lt;/li&gt;
&lt;li&gt;密度函数的核估计&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;分布函数的估计&lt;/h2&gt;
&lt;p&gt;经验分布函数：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
F_n(x) =\frac{1}{n}\sum_{i=1}^n 1\{x_i\le x\} = \begin{cases}
0,&amp;amp;\ x&amp;lt;x_{(1)}\\
1/n,&amp;amp;\ x_{(1)}\le x&amp;lt;x_{(2)}\\
2/n,&amp;amp;\ x_{(2)}\le x&amp;lt;x_{(3)}\\
&amp;amp;\vdots\\
k/n,&amp;amp;\ x_{(k)}\le x&amp;lt;x_{(k+1)}\\
&amp;amp;\vdots\\
1,&amp;amp;\ x&amp;gt;x_{(n)}\\
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.1 密度函数的估计——直方图法&lt;/h2&gt;
&lt;p&gt;只考虑一维连续型总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim f(x)\)&lt;/span&gt;。设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为样本，&lt;span class=&#34;math inline&#34;&gt;\(R_n(a,b)\)&lt;/span&gt;表示落在区间&lt;span class=&#34;math inline&#34;&gt;\((a,b]\)&lt;/span&gt;中的个数。由中值定理得，存在&lt;span class=&#34;math inline&#34;&gt;\(x_0\in(a,b]\)&lt;/span&gt;使得
&lt;span class=&#34;math display&#34;&gt;\[f(x_0)=\frac 1{b-a}\int_a^b f(x)dx\approx \frac {R_n(a,b)}{n(b-a)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(-\infty&amp;lt;t_0&amp;lt;t_1&amp;lt;\dots&amp;lt;t_m&amp;lt;\infty\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(t_{i+1}-t_i=h&amp;gt;0\)&lt;/span&gt;. 直方图法的密度估计为：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f_n(x)=
\begin{cases}
\frac{R_n(t_i,t_{i+1})}{nh},\ x\in(t_i,t_{i+1}],i=0,\dots,m-1\\
0, x\le t_0,x&amp;gt;t_m
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;实际上选取&lt;span class=&#34;math inline&#34;&gt;\(t_0\)&lt;/span&gt;为比&lt;span class=&#34;math inline&#34;&gt;\(X_{(1)}\)&lt;/span&gt;略小的数，选取&lt;span class=&#34;math inline&#34;&gt;\(t_m\)&lt;/span&gt;为比&lt;span class=&#34;math inline&#34;&gt;\(X_{(n)}\)&lt;/span&gt;略大的数。&lt;strong&gt;经验法则&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(m\approx 1+3.322\log_{10} n.\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;案例：身高数据&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/chap02_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;直方图法的相合性&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(f(\cdot)\)&lt;/span&gt;在点&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;连续且&lt;span class=&#34;math inline&#34;&gt;\(\lim_n h_n=0,\lim_n nh_n=\infty\)&lt;/span&gt;, 则对任何&lt;span class=&#34;math inline&#34;&gt;\(\epsilon&amp;gt;0\)&lt;/span&gt;有
&lt;span class=&#34;math display&#34;&gt;\[\lim_{n\to\infty} P(|f_n(x)-f(x)|\ge \epsilon)=0.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(f(\cdot)\)&lt;/span&gt;在&lt;span class=&#34;math inline&#34;&gt;\(\mathbb{R}\)&lt;/span&gt;上一致连续，&lt;span class=&#34;math inline&#34;&gt;\(\int_{-\infty}^\infty |x|^\delta d x&amp;lt;\infty\)&lt;/span&gt;(对某个&lt;span class=&#34;math inline&#34;&gt;\(\delta&amp;gt;0\)&lt;/span&gt;), 且&lt;span class=&#34;math inline&#34;&gt;\(\lim_n h_n=0,h_n\ge (\ln n)^2/n\)&lt;/span&gt;, 则
&lt;span class=&#34;math display&#34;&gt;\[P(\lim_{n\to\infty} \sup_x|f_n(x)-f(x)|=0)=1.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;证明见书pp54-55.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.2 核估计法&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;中心差分&lt;/strong&gt;：
&lt;span class=&#34;math display&#34;&gt;\[f(x)\approx \frac{F(x+h)-F(x-h)}{2h}\approx \frac{F_n(x+h)-F_n(x-h)}{2h}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{f}_n(x) = \frac{1}{2hn}\sum_{i=1}^n 1\{x-h&amp;lt;X_i\le x+h\}=\frac{1}{2hn}\sum_{i=1}^n K_0\left(\frac{x-X_i}{h}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中
&lt;span class=&#34;math display&#34;&gt;\[K_0(x)= \frac 12 1\{-1\le x&amp;lt;1\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核函数&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(K(x)\)&lt;/span&gt;是&lt;span class=&#34;math inline&#34;&gt;\(\mathbb{R}\)&lt;/span&gt;上的非负函数且满足&lt;span class=&#34;math inline&#34;&gt;\(\int_{-\infty}^\infty K(x)=1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核估计&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(\hat{f}_n(x) = \frac{1}{2hn}\sum_{i=1}^n K\left(\frac{x-X_i}{h}\right)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;常用的核函数&lt;/h2&gt;
&lt;p&gt;均匀核函数：
&lt;span class=&#34;math display&#34;&gt;\[K_0(x)= \frac 12 1\{-1\le x\le1\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[K_1(x)= 1\{-1/2\le x\le1/2\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;正态核函数：
&lt;span class=&#34;math display&#34;&gt;\[K_2(x)=\frac{1}{\sqrt{2\pi}}e^{-x^2/2}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;核估计的相合性&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设核函数&lt;span class=&#34;math inline&#34;&gt;\(K(x)\)&lt;/span&gt;满足条件
&lt;span class=&#34;math display&#34;&gt;\[\int_{-\infty}^\infty (K(x))^2 dx&amp;lt;\infty,\ \lim_{|x|\to \infty} |x|K(x)=0,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;又密度函数&lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;在点&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;处连续，且&lt;span class=&#34;math inline&#34;&gt;\(h_n\to 0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(nh_n\to\infty\)&lt;/span&gt;, 则对一切&lt;span class=&#34;math inline&#34;&gt;\(\epsilon&amp;gt;0\)&lt;/span&gt;, 有
&lt;span class=&#34;math display&#34;&gt;\[\lim_{n\to\infty} P(|\hat{f}_n(x)-f(x)|\ge \epsilon) = 0.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;证明见pp56-58.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;案例：身高数据&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/chap02_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;案例：身高数据&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/chap02_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;一些说明&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;收敛速度的比较&lt;/h3&gt;
&lt;p&gt;在满足一些正则性的条件（如，&lt;span class=&#34;math inline&#34;&gt;\(h_n\to 0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(nh_n\to\infty\)&lt;/span&gt;）下，可以证明&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;直方图法的均方误差为&lt;span class=&#34;math inline&#34;&gt;\(O(n^{-2/3})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;核估计的均方误差为&lt;span class=&#34;math inline&#34;&gt;\(O(n^{-4/5})\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;bandwidth-h_n&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;核估计的带宽(bandwidth) &lt;span class=&#34;math inline&#34;&gt;\(h_n\)&lt;/span&gt;如何选取?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;如果选择正态核函数，&lt;strong&gt;经验法则&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(h_n\approx 1.06S_nn^{-1/5}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;延伸阅读&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Kernel_density_estimation&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Kernel_density_estimation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Kernel smoothing techniques used in finance&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;used in Approximate Bayesian Computation (ABC)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;一些参考文献&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Liu, Guangwu; Hong, L. Jeff. Kernel estimation of the greeks for options with discontinuous payoffs. &lt;em&gt;Operations Research&lt;/em&gt;. Vol. 59, No. 1, pp. 96-108, 2011.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hong, L. Jeff; Juneja, Sandeep; Liu, Guangwu. Kernel smoothing for nested estimation with application to portfolio risk measurement. &lt;em&gt;Operations Research&lt;/em&gt;. Vol. 65, No. 3, pp. 657-673, 2017.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Amal B. Abdellah, Pierre L’Ecuyer, Art B. Owen, Florian Puchhammer. Density estimation by Randomized Quasi-Monte Carlo. &lt;a href=&#34;https://arxiv.org/abs/1807.06133&#34;&gt;arXiv:1807.06133&lt;/a&gt;, 2018&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>第二次作业</title>
      <link>/post/homework2/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/homework2/</guid>
      <description>&lt;p&gt;设随机变量&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(0,1)\)&lt;/span&gt;, 对给定的&lt;span class=&#34;math inline&#34;&gt;\(\alpha\in(0,1)\)&lt;/span&gt;, 数&lt;span class=&#34;math inline&#34;&gt;\(u_{\alpha}\)&lt;/span&gt; 满足&lt;span class=&#34;math inline&#34;&gt;\(P(X&amp;gt;u_\alpha)=\alpha\)&lt;/span&gt;. 若&lt;span class=&#34;math inline&#34;&gt;\(P(|X|&amp;lt;x)=\alpha\)&lt;/span&gt;, 则&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;等于（ ）。&lt;strong&gt;答案：C&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A. &lt;span class=&#34;math inline&#34;&gt;\(u_{\alpha/2}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;B. &lt;span class=&#34;math inline&#34;&gt;\(u_{1-\alpha/2}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;C. &lt;span class=&#34;math inline&#34;&gt;\(u_{(1-\alpha)/2}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;D. &lt;span class=&#34;math inline&#34;&gt;\(u_{1-\alpha}\)&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为总体&lt;span class=&#34;math inline&#34;&gt;\(N(1,2^2)\)&lt;/span&gt;的样本，下面正确的是（ ）。&lt;strong&gt;答案：D&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A. &lt;span class=&#34;math inline&#34;&gt;\(\frac{\bar X-1}{2/\sqrt{n}}\sim t(n)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;B. &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{4}\sum_{i=1}^n(X_i-1)^2\sim F(n,1)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;C. &lt;span class=&#34;math inline&#34;&gt;\(\frac{\bar X-1}{\sqrt{2}/\sqrt{n}}\sim N(0,1)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;D. &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{4}\sum_{i=1}^n(X_i-1)^2\sim \chi^2(n)\)&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_{15}\)&lt;/span&gt;为总体&lt;span class=&#34;math inline&#34;&gt;\(N(0,2^2)\)&lt;/span&gt;的样本，则统计量
&lt;span class=&#34;math display&#34;&gt;\[Y=\frac{X_1^2+\dots+X_{10}^2}{2(X_{11}^2+\dots+X_{15}^2)}\]&lt;/span&gt;
的分布为（ ）。&lt;strong&gt;答案：A&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A. &lt;span class=&#34;math inline&#34;&gt;\(F(10,5)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;B. &lt;span class=&#34;math inline&#34;&gt;\(F(11,4)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;C. &lt;span class=&#34;math inline&#34;&gt;\(\chi^2(10)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;D. 以上都不是&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是来自双参数指数分布
&lt;span class=&#34;math display&#34;&gt;\[p(x;\mu,\theta)=\frac 1\theta \exp\{-(x-\mu)/\theta\}, x&amp;gt;\mu,\theta&amp;gt;0\]&lt;/span&gt;
的一个样本，证明&lt;span class=&#34;math inline&#34;&gt;\((\bar X,X_{(1)})\)&lt;/span&gt;是该分布的充分统计量。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;证明&lt;/code&gt;：样本的联合密度函数为
&lt;span class=&#34;math display&#34;&gt;\[f(x_1,\dots,x_n) =\prod_{i=1}^n\frac 1\theta e^{-(x_i-\mu)/\theta}1\{x_i&amp;gt;\mu\}=\theta^{-n}e^{-(n\bar X-n\mu)/\theta}1\{x_{(1)}&amp;gt;\mu\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由此得知，样本的联合密度函数可以表示为形如&lt;span class=&#34;math inline&#34;&gt;\(h(\bar X,X_{(1)};\mu,\theta)\)&lt;/span&gt;的函数。由因子分解定理可得&lt;span class=&#34;math inline&#34;&gt;\((\bar X,X_{(1)})\)&lt;/span&gt;为该分布的充分统计量。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是来自密度函数
&lt;span class=&#34;math display&#34;&gt;\[p_\theta(x)=\theta/x^2,\ 0&amp;lt;\theta&amp;lt;x&amp;lt;\infty\]&lt;/span&gt;
的一个样本，求参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的充分统计量。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;解&lt;/code&gt;：样本的联合密度函数为
&lt;span class=&#34;math display&#34;&gt;\[f(x_1,\dots,x_n) = \prod_{i=1}^n \theta/x_i^2 1\{x_i&amp;gt;\theta\}=\left(\prod_{i=1}^nx_i^{-2}\right)\theta^n 1\{x_{(1)}&amp;gt;\theta\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由因子分解定理可得&lt;span class=&#34;math inline&#34;&gt;\(X_{(1)}\)&lt;/span&gt;为参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的充分统计量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：当然充分统计量不是唯一，比如一部分同学认为&lt;span class=&#34;math inline&#34;&gt;\((X_{(1)},\prod_{i=1}^nx_i^{-2})\)&lt;/span&gt;是充分统计量。这也是正确的，不过这个充分统计量&lt;code&gt;不是最优的&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;在R中使用命令&lt;code&gt;boxplot&lt;/code&gt;分析数据&lt;code&gt;OrchardSprays&lt;/code&gt;, 上传相应的箱线图并&lt;strong&gt;基于实验背景&lt;/strong&gt;分析结果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;关于数据&lt;code&gt;OrchardSprays&lt;/code&gt;的背景介绍查看帮助文档：&lt;code&gt;? OrchardSprays&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;R语言的代码供参考（&lt;strong&gt;请把“你的名字”替换成你真实的名字&lt;/strong&gt;)：boxplot(decrease ~ treatment, data = OrchardSprays, main=“你的名字”)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;实验背景&lt;/code&gt;：在蔗糖溶液中用&lt;a href=&#34;https://baike.baidu.com/item/%E7%9F%B3%E7%A1%AB%E5%90%88%E5%89%82/2228879?fr=aladdin&#34;&gt;石灰硫磺合剂&lt;/a&gt;填充蜂巢的每个蜂房,一共使用了七个不同浓度的石灰硫磺合剂，浓度分别为&lt;span class=&#34;math inline&#34;&gt;\(0.01\times 5^{-i+1},i=1,\dots,7\)&lt;/span&gt;, 以及一个不含石灰硫磺合剂的溶液。
通过将100只蜜蜂放在密室中两小时，测量不同浓度下蜂巢中蔗糖溶液体积的减少量。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;实验目的&lt;/code&gt;：研究不同浓度的石灰硫磺合剂对蜜蜂的驱赶效果&lt;/p&gt;
&lt;p&gt;&lt;code&gt;R代码&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boxplot(decrease ~ treatment, data = OrchardSprays,xlab=&amp;quot;石灰硫磺合剂浓度&amp;quot;,ylab=&amp;quot;溶液减少量&amp;quot;,main=&amp;quot;不同浓度的驱蜂效果比较&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/homework2_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;数据分析&lt;/code&gt;：由于蜜蜂是喜欢蔗糖溶液的，所以在正常情况下将100只蜜蜂放至密室两小时，蜂巢中蔗糖溶液体积是会变少的。实验中的“蔗糖溶液”的作用类比果园中的“花粉”。果园种植要除去害虫，但使用含石灰硫磺合剂的喷雾剂在消灭害虫的同时也会驱赶蜜蜂。本实验的目的是研究不同浓度的石灰硫磺合剂对蜜蜂的驱赶效果。因此，实验中溶液的减少量（即纵坐标）越小说明蜜蜂越排斥该溶液，这样驱赶效果越明显，也就意味着不利于花粉的传播。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;石灰硫磺合剂的浓度对驱赶蜜蜂是有显著影响的，而且浓度越高驱赶效果越明显，对应数据的中位数呈线性相关。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;当浓度比较低时(F、G组), 数据波动较大，且与不含石灰硫磺合剂的溶液(H组)中位数相差不大，这表明浓度比较低时驱蜂效果不显著。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从实际的角度出发，我们需要有一定浓度的石灰硫磺合剂才能取得较好的除去害虫的效果，但过高的浓度必然会导致驱赶蜜蜂（这不利于花粉传播）。如何权衡这两者？这就要对这两方面进行建模：一是建立石灰硫磺合剂浓度对去除害虫效果的关系；二是建立石灰硫磺合剂浓度对驱赶蜜蜂效果的关系。对于第二方面，我们可以利用这个数据进行深入建模，比如假设&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;表示溶液减少量，&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;表示浓度，可以通过引入恰当的模型刻画&lt;span class=&#34;math inline&#34;&gt;\(x,y\)&lt;/span&gt;的联系。而对于第一方面，根据目前的数据无法判断。基于这点，我们目前不能得到“哪种浓度的石灰硫磺合剂最好”的结论。或许我们可以排除两种极端情况：A（不利于花粉传播）和H（不利于去除害虫）。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>第一次作业</title>
      <link>/post/homework1/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/homework1/</guid>
      <description>&lt;p&gt;韦布尔分布(Weibull distribution)族
&lt;span class=&#34;math display&#34;&gt;\[p(x)=\frac k\lambda\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^k}1\{x\ge 0\},k&amp;gt;0,\lambda&amp;gt;0\]&lt;/span&gt;
是不是指数型分布族？&lt;strong&gt;答案：B&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A. 是&lt;/p&gt;
&lt;p&gt;B. 不是&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：这里的未知参数有两个，分别是&lt;span class=&#34;math inline&#34;&gt;\(k,\lambda\)&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;从均值为&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, 方差为&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的总体中随机抽取样本量为&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;的样本&lt;span class=&#34;math inline&#34;&gt;\(x_1,\dots,x_n\)&lt;/span&gt;, 其中&lt;span class=&#34;math inline&#34;&gt;\(\mu,\sigma^2\)&lt;/span&gt;均未知，指出下列样本函数中哪些为统计量（ ）。&lt;strong&gt;答案：ADE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A. &lt;span class=&#34;math inline&#34;&gt;\(T_1=x_1+x_2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;B. &lt;span class=&#34;math inline&#34;&gt;\(T_2=x_1+x_2-2\mu\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;C. &lt;span class=&#34;math inline&#34;&gt;\(T_3=(x_1-\mu)/\sigma\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;D. &lt;span class=&#34;math inline&#34;&gt;\(T_4=(\bar x-10)/5\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;E. &lt;span class=&#34;math inline&#34;&gt;\(T_5=\frac 1 n\sum_{i=1}^n(x_i-S_n)^2\)&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(\bar x_n,s_n^2\)&lt;/span&gt;表示样本&lt;span class=&#34;math inline&#34;&gt;\(x_1,\dots,x_n\)&lt;/span&gt;的样本均值与样本方差。已知&lt;span class=&#34;math display&#34;&gt;\[n=15,\bar x_{n}=168, s_n=11.43, x_{n+1}=170.\]&lt;/span&gt; 求&lt;span class=&#34;math inline&#34;&gt;\(\bar x_{n+1},s_{n+1}^2\)&lt;/span&gt;，以及修正样本方差&lt;span class=&#34;math inline&#34;&gt;\(s_{n+1}^{*2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;答案来自：&lt;a href=&#34;mailto:张华@16统计&#34;&gt;张华@16统计&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;1张华-16统计.jpeg&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：有同学把已知条件&lt;span class=&#34;math inline&#34;&gt;\(s_n=11.43\)&lt;/span&gt;看成&lt;span class=&#34;math inline&#34;&gt;\(s_n^2=11.43\)&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1\sim Ga(\alpha_1,\lambda)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_2\sim Ga(\alpha_2,\lambda)\)&lt;/span&gt;, 且&lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt;与&lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt;独立。证明&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_1=X_1+X_2\sim Ga(\alpha_1+\alpha_2,\lambda)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_2=X_1/(X_1+X_2)\sim Beta(\alpha_1,\alpha_2)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y_1\)&lt;/span&gt;与&lt;span class=&#34;math inline&#34;&gt;\(Y_2\)&lt;/span&gt;独立&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;答案来自：&lt;a href=&#34;mailto:王博@16统计&#34;&gt;王博@16统计&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;2王博-16统计.jpeg&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：大部分同学每一问都分别给出证明；实际上只需在求第三问时算出他们的联合密度函数即可，容易观察出联合密度函数是“可分离”的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是来自某连续总体的一个样本，总体的分布函数&lt;span class=&#34;math inline&#34;&gt;\(F(x)\)&lt;/span&gt;是连续严增函数，证明：统计量&lt;span class=&#34;math inline&#34;&gt;\(T=-2\sum_{i=1}^n \ln F(X_i)\sim \chi^2(2n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;答案来自：&lt;a href=&#34;mailto:刘霏@16信管&#34;&gt;刘霏@16信管&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;3刘霏-16信管.jpeg&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;从正态总体&lt;span class=&#34;math inline&#34;&gt;\(N(52,6.3^2)\)&lt;/span&gt;中随机抽取容量为36的样本。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;求样本均值&lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;的分布；&lt;/li&gt;
&lt;li&gt;求&lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;落在区间&lt;span class=&#34;math inline&#34;&gt;\((50.8,53.8)\)&lt;/span&gt;内的概率；&lt;/li&gt;
&lt;li&gt;若要以&lt;span class=&#34;math inline&#34;&gt;\(99\%\)&lt;/span&gt;的概率保证&lt;span class=&#34;math inline&#34;&gt;\(|\bar X-52|&amp;lt;2\)&lt;/span&gt;, 试问样本量至少应取多少？&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;答案来自：&lt;a href=&#34;mailto:甘桃菁@16信计&#34;&gt;甘桃菁@16信计&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;4.jpeg&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R的基本画图技巧</title>
      <link>/post/ex1-1/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/ex1-1/</guid>
      <description>&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;预备工作&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;R软件&lt;/code&gt;下载: &lt;a href=&#34;https://www.r-project.org/&#34; class=&#34;uri&#34;&gt;https://www.r-project.org/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;RStudio编辑器&lt;/code&gt;下载: &lt;a href=&#34;https://www.rstudio.com/&#34; class=&#34;uri&#34;&gt;https://www.rstudio.com/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例1：密度函数画图&lt;/h2&gt;
&lt;p&gt;画图的主要命令&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;为&lt;code&gt;plot(x,y,...)&lt;/code&gt;，里面各种参数的含义可查看帮助文档&lt;code&gt;help(plot)&lt;/code&gt;或者&lt;code&gt;? plot&lt;/code&gt;. 下面以画&lt;strong&gt;伽马分布&lt;/strong&gt;的密度为例。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;所有的图像都是离散点拼接起来，首先要确定横坐标，可用&lt;code&gt;seq(from = a, to = b, length=n)&lt;/code&gt;生成&lt;span class=&#34;math inline&#34;&gt;\([a,b]\)&lt;/span&gt;间的&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;个等分点。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;接着根据横坐标的值计算相应的密度函数值，常用分布的密度函数在R种有现成的函数（使用命令&lt;code&gt;? distribution&lt;/code&gt;查看常用的分布），直接调用即可。比如&lt;strong&gt;伽马分布&lt;/strong&gt;的密度为&lt;code&gt;dgamma(x,shape=alpha,rate = lambda)&lt;/code&gt;, 详情查看帮助文档&lt;code&gt;? dgamma&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;下面为三组参数下的画图代码（可复制到一个空白的R文件中保存运行）&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x = seq(0.001,10,length = 10000) #生成横坐标值
lambda = 0.5
alpha = 1
y = dgamma(x,shape=alpha,rate = lambda) #计算相应的密度值
par(mai=c(0.9,0.9,0.3,0.1),cex=1.1) #调整图像边缘空白处大小，初学者可不用设置
plot(x,y,type=&amp;quot;l&amp;quot;,ylab = &amp;quot;f(x)&amp;quot;,col=&amp;quot;blue&amp;quot;,cex.lab=1.2)

#画第二组参数的图像
alpha = 2
y = dgamma(x,shape=alpha,rate = lambda)
lines(x,y,col=&amp;quot;red&amp;quot;) #此次通过lines命令画第二组参数的图，若用plot命令则输出一副新的图像，而不是在上一幅图基础上叠加

#画第三组参数的图像
alpha = 3
y = dgamma(x,shape=alpha,rate = lambda)
lines(x,y,col=&amp;quot;green&amp;quot;)

#画出相应的标注，即图中的小矩形
expr1 = expression(alpha==1) #此命令用于希腊字母的转化
expr2 = expression(alpha==2)
expr3 = expression(alpha==3)
legend(6,0.5,legend=c(expr1,expr2,expr3),col=c(&amp;quot;blue&amp;quot;,&amp;quot;red&amp;quot;,&amp;quot;green&amp;quot;),lty = c(1,1,1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ex1-1_files/figure-html/gammaplot-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例2：经验分布函数画图&lt;/h2&gt;
&lt;p&gt;画经验分布函数主要用到命令&lt;code&gt;ecdf(x)&lt;/code&gt;. 下面的例子为标准正态样本的经验分布图。R中提供了生成常见分布的样本的命令（使用命令&lt;code&gt;? distribution&lt;/code&gt;查看常用的分布）。如生成正态分布&lt;span class=&#34;math inline&#34;&gt;\(N(a,b^2)\)&lt;/span&gt;的&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;个样本代码为&lt;code&gt;rnorm(n, mean = a, sd = b)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x = rnorm(100) #生成100个标准正态的样本
Fn1 = ecdf(x[1:10]) #计算前10个样本对应的经验分布函数
Fn2 = ecdf(x[1:100]) #计算前100个样本对应的经验分布函数

#计算标准正态分布函数
t = seq(-3,3,by=0.01) #横坐标
y = pnorm(t) #相应的分布函数值

#mfrow表示生成两行一列的图，后面的两个参数用于调整页边距，初学者可不用设置
#最终输出一幅图，包含两幅子图
par(mfrow=c(2,1),mgp=c(1.5,0.8,0),mar=.1+c(3,3,2,1)) 

# 第一幅子图
plot(Fn1,verticals=TRUE,do.points=FALSE,main=&amp;quot;n=10&amp;quot;,xlim=c(-3,3)) #画经验分布函数
lines(t,y,col=&amp;quot;red&amp;quot;) #画真实的正态分布函数图像

# 第二幅子图
plot(Fn2,verticals=TRUE,do.points=FALSE,main=&amp;quot;n=100&amp;quot;,xlim=c(-3,3)) #画经验分布函数
lines(t,y,col=&amp;quot;red&amp;quot;) #画真实的正态分布函数图像&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/ex1-1_files/figure-html/ecdf-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;课后练习&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;安装相应的软件&lt;/li&gt;
&lt;li&gt;参考上面两个例子，学会使用&lt;code&gt;plot(...)&lt;/code&gt;画相关的图形，了解该命令里面参数的作用。&lt;/li&gt;
&lt;li&gt;参考例1，画不同参数下&lt;strong&gt;贝塔分布&lt;/strong&gt;的密度函数；关键的命令查看帮助&lt;code&gt;? beta&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;参考例2，比较其他分布（查看R中的常用分布&lt;code&gt;?distribution&lt;/code&gt;）的经验分布函数与真实的分布函数，并观察他们的差距是否随着样本量的增加而减小。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;一些建议&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;充分利用帮助文档&lt;/strong&gt;。我们不可能记住所有命令的使用方式，使用帮助文档是一种高效的学习途径，此外帮助文档末尾还提供一些参考例子，有助于理解命令的使用方式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;充分利用网上资源&lt;/strong&gt;。编程过程中如果遇到问题，可以通过度娘等方式搜索寻找答案，现在的很多技术博客提供很多有价值的资源。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;要学会偷懒&lt;/strong&gt;。在编写一种算法之前，首先要去了解R软件中有没有现成的命令。如果有现成的，则只需学会如何运用即可。通过不断地积累，工作效率会大大提高。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;更高级的画图方式见&lt;code&gt;ggplot2&lt;/code&gt;, 初学者可先忽略&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>第一章：绪论</title>
      <link>/post/chap01/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/chap01/</guid>
      <description>&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;目录&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;1.1 数理统计是一门什么样的学科？&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;1.2 统计学的发展简史&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;1.3 基本概念&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;1.4 抽样分布&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;1.5 充分统计量&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.1 数理统计是一门什么样的学科？&lt;/h2&gt;
&lt;p&gt;它使用概率论和其它数学方法，研究怎样收集（通过试验和观察）带有随机误差的数据，并在设定的模型（称为统计模型）之下，对这种数据进行分析（称为统计分析），以对所研究的问题作出推断（称为统计推断）。
由于所收集的统计数据（资料）只能反映事物的局部特征，数理统计的任务就在于从统计资料所反映的局部特征以概率论作为理论基础去推断事物的整体特征。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;本质：由局部（有限样本）推断整体（总体）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;数据&lt;/li&gt;
&lt;li&gt;模型&lt;/li&gt;
&lt;li&gt;推断&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;数据是什么？&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;data.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;模型是什么？&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;刻画实际问题&lt;/li&gt;
&lt;li&gt;能够进行统计分析&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;essentially-all-models-are-wrong-but-some-are-useful.-george-box&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Essentially, all models are wrong, but some are useful. —— &lt;a href=&#34;https://en.wikipedia.org/wiki/All_models_are_wrong&#34;&gt;George Box&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;什么样的推断？&lt;/h2&gt;
&lt;p&gt;由样本到总体的推理称为&lt;strong&gt;统计推断&lt;/strong&gt;，有两种基本形式：&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;参数估计&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;模型中未知参数&lt;/li&gt;
&lt;li&gt;与“业务相关”的未知量&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;假设检验&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;判断命题的真假&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;案例&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;zhihu.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;案例&lt;/h2&gt;
&lt;p&gt;问题1：OPPO手机充电五分钟通话时间为多少？（参数估计）&lt;/p&gt;
&lt;p&gt;问题2：“OPPO手机充电五分钟通话2小时”是否可信？（假设检验）&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;一般步骤&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;数据收集：用&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;部手机进行测试，记录通话时间&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;模型假定：假设通话时间&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;服从正态分布&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;数据分析：通过观测数据&lt;span class=&#34;math inline&#34;&gt;\(x_1,\dots,x_n\)&lt;/span&gt;作出统计推断&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.2 统计学的发展简史&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;第一个时期（萌芽阶段）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;20世纪以前，描述性统计&lt;/li&gt;
&lt;li&gt;代表性人物：高斯(C. F. Gauss, 1777-1855), 皮尔逊(K. Pearson, 1857-1936)等&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;第二个时期（蓬勃发展阶段）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;20世纪初至第二次世界大战&lt;/li&gt;
&lt;li&gt;代表性人物：费希尔(R. A. Fisher, 1890-1962), 奈曼(J. Neyman, 1894-1981), 小皮尔逊(E. S. Pearson, 1895-1980), 许宝騄(1910-1970)等&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;第三个时期（理论与应用高速发展）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;二战后至今，得益于计算机的发展，统计方法渗透许多学科&lt;/li&gt;
&lt;li&gt;贝叶斯学派的兴起&lt;/li&gt;
&lt;li&gt;大数据时代与人工智能的发展&lt;/li&gt;
&lt;li&gt;现代统计依赖强大的计算能力&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;频率学派与贝叶斯学派&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;频率学派（传统学派）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;频率学派认为样本信息来自总体，仅通过研究&lt;strong&gt;样本信息&lt;/strong&gt;可以对&lt;strong&gt;总体信息&lt;/strong&gt;做出合理的推断和估计，并且样本越多，就越准确。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;代表性人物：费希尔 (R. A. Fisher, 1890-1962)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;贝叶斯学派&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;起源于英国学者贝叶斯(T. Bayes, 1702-1761)在1763年发表的著名论文《论有关机遇问题的求解》&lt;/li&gt;
&lt;li&gt;最基本观点：任何一个未知量都可以看作是随机的，应该用一个概率分布去描述未知参数，而不是频率派认为的固定值。这种信息称为&lt;strong&gt;先验信息&lt;/strong&gt;，是主观信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Good (1973)评价道：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“主观主义者直抒他们的判断，而客观主义者以假设来掩盖其判断，并以此享受科学客观性的荣耀。”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;贝叶斯公式&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;bigbang_bayes.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;贝叶斯统计的发展&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;应用领域&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;自然语言处理：计算机翻译语言、识别语音、认识文字和海量文献的检索&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;南京市长江大桥欢迎您!&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;人工智能、无人驾驶&lt;/li&gt;
&lt;li&gt;垃圾短信、垃圾邮件识别&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;贝叶斯决策&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;如何在一个陌生的地方找餐馆吃饭？&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;贝叶斯统计课程(研究生课程)&lt;/h2&gt;
&lt;p&gt;本课程不涉及贝叶斯统计内容，欢迎对贝叶斯统计感兴趣的同学参加以下课程。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;教材&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;贝叶斯数据分析（第三版）&lt;/strong&gt;, A. Gelman等，机械工业出版社
&lt;a href=&#34;https://item.jd.com/11886268.html&#34; class=&#34;uri&#34;&gt;https://item.jd.com/11886268.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;上课时间&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;1-12周，周一下午第5—8节，共48学时&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;上课地点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;四号楼4135&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;统计学专业&lt;/h2&gt;
&lt;p&gt;统计学的应用涉及金融、经济、社会学、工程学、环境等多个领域，从而形成的相应的研究分支。其特点是多学科交叉、实用为主。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;统计学专业包含理论统计和应用统计两方面&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;理论统计：模型选择，非参统计方法，贝叶斯统计，时间序列与生存分析，高维数据分析与机器学习，数据挖掘等等。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;应用统计：目前发展最为突出的是生物统计，金融统计等等。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;统计学专业&lt;/h2&gt;
&lt;p&gt;统计学经过漫长的发展，尤其是计算机的大量应用，目前包括但不限于下面这些分支（或者交叉领域）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理论研究：概率论（比如Stochastic Process），计算统计理论（比如Asymptotic Theory，在CS系的Computational Theory下面）等&lt;/li&gt;
&lt;li&gt;统计模型（在前人基础上继续发展各种Regression Model，Stratification，Clustering，Blocking，classification等等）、各种Test的发展（比如Time Series，Likelihood Ratio Test, Wald test, Permutation test 等）&lt;/li&gt;
&lt;li&gt;计算统计方法的发展（比如Monte Carlo Simulation，Bootstrap）&lt;/li&gt;
&lt;li&gt;数据采集（Census，Survey和Clinical Trial等）&lt;/li&gt;
&lt;li&gt;生物统计（比如Longitudinal Analysis，Spatial Analysis）&lt;/li&gt;
&lt;li&gt;Machine Learning
Data Mining&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前最火热的学科都是跟计算机结合比较紧密的。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;statistician-salaries-in-the-united-states&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Statistician Salaries in the United States&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;salary.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.3 基本概念&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(1) 总体&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(2) 样本&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(3) 分布族&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(4) 统计量与估计量&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(5) 经验分布函数&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;总体&lt;/h2&gt;
&lt;p&gt;我们把研究对象的全体（包括有形的和潜在的）称作&lt;strong&gt;总体&lt;/strong&gt;，其中每个成员称为&lt;strong&gt;个体&lt;/strong&gt;。常用随机变量&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;来刻画一个总体（或者总体的特征值）。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;网上购物居民占全市居民的比例&lt;/li&gt;
&lt;li&gt;过去一年内网购居民的购物次数&lt;/li&gt;
&lt;li&gt;某品牌灯泡的寿命&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的分布函数&lt;span class=&#34;math inline&#34;&gt;\(F(x)\)&lt;/span&gt;未知或者部分未知，统计学的核心任务就是要对总体进行观测，并对所得数据推断总体的分布信息。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;样本&lt;/h2&gt;
&lt;p&gt;研究总体可分为&lt;strong&gt;普查&lt;/strong&gt;和&lt;strong&gt;抽样&lt;/strong&gt;这两种方法。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;普查（全数检查）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;对总体中的每个个体进行观察，如我国每十年一次的人口普查&lt;/li&gt;
&lt;li&gt;缺点：费用高、时间长、不适合破坏性试验&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;抽样&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;从总体中抽取若干个体进行观察，用所获得数据对总体进行统计推断&lt;/li&gt;
&lt;li&gt;优点：费用低、时间短&lt;/li&gt;
&lt;li&gt;抽取的部分组成的集合&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;称为&lt;strong&gt;样本&lt;/strong&gt;，&lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;称为&lt;strong&gt;样品&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;样品个数&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;称为&lt;strong&gt;样本量或者样本容量&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;简单随机抽样&lt;/h2&gt;
&lt;p&gt;简单随机抽样满足以下两个特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;随机性：每个个体都有相同的机会选中（有放回随机抽取/独立重复观测），即&lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;与&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;同分布&lt;/li&gt;
&lt;li&gt;独立性：每个样本的选取是独立的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种方式得到的样本称为&lt;strong&gt;简单随机样本（简称样本）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;独立同分布(independent and identically distributed, iid)&lt;/li&gt;
&lt;li&gt;本课程所研究的均为简单随机样本&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;样本具有两重性&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;抽取之前无法预知它们的数值，故&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;维随机向量&lt;/li&gt;
&lt;li&gt;抽取后样本为具体的数，用小写字母&lt;span class=&#34;math inline&#34;&gt;\((x_1,\dots,x_n)\)&lt;/span&gt;表示，称为&lt;strong&gt;样本观测值&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注：所有的统计分析都是基于随机变量，统计推断结论基于样本观测值（数据）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;案例：&lt;/h2&gt;
&lt;p&gt;“二战”期间，为了加强对战机的防护，英美军方调查了作战后幸存飞机上弹痕的分布，决定哪里弹痕多就加强哪里，你支持这种做法吗？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plane.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;2018ii&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;案例：2018年高考全国II卷作文&lt;/h2&gt;
&lt;p&gt;2018年高考全国II卷（适用地区: 内蒙古、黑龙江、辽宁、吉林、重庆、陕西、甘肃、宁夏、青海、新疆、西藏、海南）作文题目如下:&lt;/p&gt;
&lt;p&gt;“二战”期间，为了加强对战机的防护，英美军方调查了作战后幸存飞机上弹痕的分布，决定哪里弹痕多就加强哪里，然而统计学家瓦尔德(Abrahom Wald, 1902–1950)力排众议，指出更应该注意弹痕少的部位，因为这些部位受到重创的战机，很难有机会返航，而这部分数据被忽略了。事实证明沃德是正确的。&lt;/p&gt;
&lt;p&gt;要求: 综合材料内容及含义，选好角度，确定立意，明确文体，自拟标题; 不要套作，不得抄袭; 不少于800字。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;这就是所谓的“幸存者偏见”&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;概率分布族&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;模型假定&lt;/strong&gt;：总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;分布&lt;span class=&#34;math inline&#34;&gt;\(F(x)\)&lt;/span&gt;属于某个分布族&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;. 分为以下三类：&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;参数族&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;中的分布的一般数学形式已知，但包含若干未知参数&lt;span class=&#34;math inline&#34;&gt;\(\theta=(\theta_1,\dots,\theta_m)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}:=\{F_\theta,\theta\in\Theta\}\)&lt;/span&gt;, 其中&lt;span class=&#34;math inline&#34;&gt;\(\Theta\subset \mathbb{R}^m\)&lt;/span&gt;称为参数空间。&lt;/li&gt;
&lt;li&gt;该模型为&lt;strong&gt;参数统计问题&lt;/strong&gt;，&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;为模型的维数&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(m=1\)&lt;/span&gt;为单参数统计问题，&lt;span class=&#34;math inline&#34;&gt;\(m&amp;gt;1\)&lt;/span&gt;为多参数统计问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;非参数族&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;当&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;中的分布不能通过有限个未知参数来刻画&lt;/li&gt;
&lt;li&gt;该模型为&lt;strong&gt;非参数统计问题&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;半参数族&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;中的分布有一部分可以用参数刻画，一部分则不可以。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;常用的参数族&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;离散型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;二项分布族&lt;span class=&#34;math inline&#34;&gt;\(\{b(n,p);0&amp;lt;p&amp;lt;1\}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;几何分布族&lt;span class=&#34;math inline&#34;&gt;\(\{Ge(p);0&amp;lt;p&amp;lt;1\}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;泊松分布族&lt;span class=&#34;math inline&#34;&gt;\(\{P(\lambda);\lambda&amp;gt;0\}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;连续型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;正态分布族&lt;span class=&#34;math inline&#34;&gt;\(\{N(\mu,\sigma^2);-\infty&amp;lt;\mu&amp;lt;\infty,\sigma&amp;gt;0\}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;均匀分布族&lt;span class=&#34;math inline&#34;&gt;\(\{U(a,b);-\infty&amp;lt;a&amp;lt;b&amp;lt;\infty\}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;指数分布族&lt;span class=&#34;math inline&#34;&gt;\(\{Exp(\lambda);\lambda&amp;gt;0\}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;伽玛分布族&lt;/h2&gt;
&lt;p&gt;伽玛分布族&lt;span class=&#34;math inline&#34;&gt;\(\{Ga(\alpha,\lambda),\alpha&amp;gt;0,\lambda&amp;gt;0\}\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;为形状参数，&lt;span class=&#34;math inline&#34;&gt;\(1/\lambda\)&lt;/span&gt;为尺度参数&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;密度函数&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x) = \frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}1\{x\ge 0\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(\Gamma(\alpha)=\int_0^{+\infty} x^{\alpha-1}e^{-x}dx\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Gamma(1)=1,\Gamma(1/2)=\sqrt{\pi}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Gamma(\alpha+1)=\alpha\Gamma(\alpha)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;当&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;为整数&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;时，&lt;span class=&#34;math inline&#34;&gt;\(\Gamma(n+1)=n!\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;frac-alpha-lambdafrac-alpha-lambda2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;期望：&lt;span class=&#34;math inline&#34;&gt;\(\frac \alpha \lambda\)&lt;/span&gt;；方差：&lt;span class=&#34;math inline&#34;&gt;\(\frac \alpha {\lambda^2}\)&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;两个特例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=1\)&lt;/span&gt;时伽玛分布为指数分布，即&lt;span class=&#34;math inline&#34;&gt;\(Ga(\alpha,\lambda)=Exp(\lambda)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\alpha=n/2,\lambda=1/2\)&lt;/span&gt;时伽玛分布为自由度为&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;的卡方分布，即&lt;span class=&#34;math inline&#34;&gt;\(Ga(n/2,1/2)=\chi^2(n)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;伽玛密度函数&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/chap01_files/figure-html/gammaplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;伽玛分布的性质&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;性质1（可加性）&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X_1\sim Ga(\alpha_1,\lambda),\ X_2\sim Ga(\alpha_2,\lambda)\)&lt;/span&gt;。如果&lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt;与&lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt;独立，则
&lt;span class=&#34;math display&#34;&gt;\[X_1+X_2\sim Ga(\alpha_1+\alpha_2,\lambda).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;性质2&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X\sim Ga(\alpha,\lambda)\)&lt;/span&gt;,则&lt;span class=&#34;math inline&#34;&gt;\(kX\sim Ga(\alpha,\lambda/k)\)&lt;/span&gt;, 其中&lt;span class=&#34;math inline&#34;&gt;\(k&amp;gt;0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;提示：&lt;span class=&#34;math inline&#34;&gt;\(Ga(\alpha,\lambda)\)&lt;/span&gt;分布的特征函数为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\phi(t)=E[e^{itX}]=\left(1-\frac{it}\lambda\right)^{-\alpha}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;贝塔分布族&lt;/h2&gt;
&lt;p&gt;贝塔分布族&lt;span class=&#34;math inline&#34;&gt;\(\{Beta(\alpha,\beta),\alpha&amp;gt;0,\beta&amp;gt;0\}\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(\alpha,\beta\)&lt;/span&gt;为形状参数&lt;/p&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;密度函数&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}1\{0&amp;lt;x&amp;lt;1\}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fracalphaalphabetafracalpha-betaalphabeta2alphabeta1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;期望：&lt;span class=&#34;math inline&#34;&gt;\(\frac{\alpha}{\alpha+\beta}\)&lt;/span&gt;；方差：&lt;span class=&#34;math inline&#34;&gt;\(\frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\)&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;alphabeta1beta11u01&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;特例：当&lt;span class=&#34;math inline&#34;&gt;\(\alpha=\beta=1\)&lt;/span&gt;时，&lt;span class=&#34;math inline&#34;&gt;\(Beta(1,1)=U(0,1)\)&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;适用场合&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;不合格率&lt;/li&gt;
&lt;li&gt;市场占有率&lt;/li&gt;
&lt;li&gt;命中率&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;贝塔密度函数&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;beta.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;指数型分布族&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：指数型分布族&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}=\{f_\theta(x);\theta\in\Theta\}\)&lt;/span&gt;中的分布（分布列或者密度函数）都可以表示成如下形式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f_\theta(x)=c(\theta)\exp\{\sum_{j=1}^kc_j(\theta)T_j(x)\}h(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;为正整数&lt;/li&gt;
&lt;li&gt;分布的支撑与参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;无关&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(c(\theta),c_j(\theta)\)&lt;/span&gt;为参数空间&lt;span class=&#34;math inline&#34;&gt;\(\Theta\)&lt;/span&gt;上的函数&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(h(x)&amp;gt;0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(T_1(x),\dots,T_k(x)\)&lt;/span&gt;线性无关&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;常见的指数型分布族&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;正态分布族是指数型分布族&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x,\mu,\sigma)=\frac 1{\sqrt{2\pi}\sigma}e^{-\mu^2/(2\sigma^2)}\exp\{\frac{\mu}{\sigma^2}x-\frac{1}{2\sigma^2}x^2\}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;二项分布族是指数型分布族&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(X=x) = C_n^x p^x(1-p)^{n-x}=(1-p)^n\exp\{\ln[p/(1-p)]x \}C_n^x\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;伽玛/贝塔分布族是指数型分布族&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;均匀分布族不是指数型分布族&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;指数型分布族的优点&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;性质&lt;/strong&gt;：如果&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是来自某指数型分布族中某分布的样本，则样本的联合分布还是指数型分布。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(f_\theta(x_1,\dots,x_n)=\prod_{i=1}^np_\theta(x_i)=c(\theta)^n\exp\{\sum_{j=1}^kc_j(\theta)\sum_{i=1}^nT_j(x_i)\}\prod_{i=1}^nh(x_i)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;统计量与估计量&lt;/h2&gt;
&lt;p&gt;样本是总体的反映，但样本所含信息不能直接用于解决我们所要研究的问题，而需要把样本所含的信息进行数学上的加工使其浓缩起来，从而解决我们的问题。为此，数理统计学往往构造一个合适的&lt;strong&gt;依赖于样本的函数&lt;/strong&gt;，我们称之为&lt;strong&gt;统计量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：如果&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;为来自总体的样本，若样本函数&lt;span class=&#34;math display&#34;&gt;\[T=T(X_1,\dots,X_n)\]&lt;/span&gt;中&lt;strong&gt;不含有任何未知参数&lt;/strong&gt;，则称&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;为统计量。统计量的分布称为&lt;strong&gt;抽样分布&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：用于估计未知参数的统计量称为&lt;strong&gt;点估计量&lt;/strong&gt;，或者简称&lt;strong&gt;估计量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;注：这里的未知参数常指以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分布中所含的未知参数&lt;/li&gt;
&lt;li&gt;分布的数字特征：期望、方差、标准差、分位数等&lt;/li&gt;
&lt;li&gt;某事件的概率&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例&lt;/h2&gt;
&lt;p&gt;设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为来自&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu,\sigma^2)\)&lt;/span&gt;的样本, 若&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;已知，&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;未知，判断&lt;span class=&#34;math inline&#34;&gt;\(T_1,T_2\)&lt;/span&gt;是否为统计量。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T_1 = \frac{\sqrt{n}(\sum_{i=1}^n X_i-\mu)}{\sigma}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T_2 = \min(X_1,\dots,X_n)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;常见的统计量&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;样本均值&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\bar{X}=\bar X_n=\frac{1}{n}\sum_{i=1}^n X_i\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;样本方差&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[S_n^2=\frac{1}{n}\sum_{i=1}^n (X_i-\bar{X})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;修正样本方差&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[S_n^{*2}=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2=\frac{n}{n-1}S_n^2\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;样本标准差&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[S_n=\sqrt{S_n^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;常见的统计量&lt;/h2&gt;
&lt;div id=&#34;k&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;样本&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶原点矩&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\overline{X^k}=\frac{1}{n}\sum_{i=1}^n X_i^k\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;k&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;样本&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;阶中心矩&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{1}{n}\sum_{i=1}^n (X_i-\bar X)^k\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;顺序统计量&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X_{(1)}\le X_{(2)}\le \dots\le X_{(n)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(X_{(1)}=\min\{X_1,\dots,X_n\}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_{(n)}=\max\{X_1,\dots,X_n\}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_{(k)}\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\({X_1,\dots,X_n}\)&lt;/span&gt;的递增排序的第&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;位。&lt;span class=&#34;math inline&#34;&gt;\(X_{(n)}-X_{(1)}\)&lt;/span&gt;样本极差。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;样本中位数&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tilde{X}=
        \begin{cases}
        X_{(\frac{n+1}{2})},\ &amp;amp;\text{$n$为奇数}\\
        (X_{(\frac{n}{2})}+X_{(\frac{n}{2}+1)})/2,\ &amp;amp;\text{$n$为偶数}
        \end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;经验分布函数&lt;/h2&gt;
&lt;p&gt;通过样本的观测值构造一种函数来近似总体的分布函数&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的样本&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;的一次观测值&lt;span class=&#34;math inline&#34;&gt;\((x_1,\dots,x_n)\)&lt;/span&gt;, 并将它们由小到大排列&lt;span class=&#34;math inline&#34;&gt;\(x_{(1)}\le x_{(2)}\le \dots\le x_{(n)}\)&lt;/span&gt;, 经验分布函数(或称样本分布函数)定义为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
F_n(x) =\frac{1}{n}\sum_{i=1}^n 1\{x_i\le x\} = \begin{cases}
0,&amp;amp;\ x&amp;lt;x_{(1)}\\
1/n,&amp;amp;\ x_{(1)}\le x&amp;lt;x_{(2)}\\
2/n,&amp;amp;\ x_{(2)}\le x&amp;lt;x_{(3)}\\
&amp;amp;\vdots\\
k/n,&amp;amp;\ x_{(k)}\le x&amp;lt;x_{(k+1)}\\
&amp;amp;\vdots\\
1,&amp;amp;\ x&amp;gt;x_{(n)}\\
\end{cases}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;经验分布函数示意图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/chap01_files/figure-html/ecdf-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;经验分布函数的性质&lt;/h2&gt;
&lt;p&gt;固定的&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(F_n(x)\)&lt;/span&gt;表示事件&lt;span class=&#34;math inline&#34;&gt;\(\{X\le x\}\)&lt;/span&gt;的频率，由强大数定律知，
&lt;span class=&#34;math display&#34;&gt;\[F_n(x)\to P(X\le x)=F(x),\]&lt;/span&gt;
即
&lt;span class=&#34;math display&#34;&gt;\[P\left(\lim_{n\to\infty}F_n(x)=F(x)\right)=1.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;格里汶科定理&lt;/strong&gt;(定理4.1, p48)给出更强的结果（几乎处处一致收敛）:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P\left(\lim_{n\to\infty}\sup_{x\in \mathbb{R}}|F_n(x)-F(x)|=0\right)=1.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：由此可见，当&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;相当大时，经验分布函数&lt;span class=&#34;math inline&#34;&gt;\(F_n(x)\)&lt;/span&gt;是母体分布函数&lt;span class=&#34;math inline&#34;&gt;\(F(x)\)&lt;/span&gt;的一个良好近似。数理统计学中一切都以样本为依据，其理由就在于此。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.4 抽样分布&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(1) 样本均值的分布&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(2) 正态总体的抽样分布&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(3) 顺序统计量的分布&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(4) 样本分位数的分布&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;抽样分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：统计量的概率分布称为抽样分布，分为如下三类：&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;精确抽样分布&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;当总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的分布已知时，如果对任意自然数&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;都能导出统计量&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;的分布的显示表达式&lt;/li&gt;
&lt;li&gt;对样本量&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;较小的统计推断问题（小样本问题）特别有用&lt;/li&gt;
&lt;li&gt;精确抽样分布多数是在正态总体下得到&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;渐近抽样分布&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;寻求在样本量&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;无限大时统计量&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;的极限分布&lt;/li&gt;
&lt;li&gt;适用于对样本量&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;较大的统计推断问题（大样本问题）&lt;/li&gt;
&lt;li&gt;常用的方法是中心极限定理&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;近似抽样分布&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;寻找一种分布来近似统计量&lt;span class=&#34;math inline&#34;&gt;\(T(X_1,\dots,X_n)\)&lt;/span&gt;的分布&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;样本均值的抽样分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为来自总体&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的样本，&lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;为其样本均值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu,\sigma^2)\)&lt;/span&gt;，则&lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;的精确分布为&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2/n)\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;如果总体不是正态分布，但&lt;span class=&#34;math inline&#34;&gt;\(E[X]=\mu,Var[X]=\sigma^2\)&lt;/span&gt;存在，则&lt;span class=&#34;math inline&#34;&gt;\(\bar X\)&lt;/span&gt;的渐近分布为
&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2/n)\)&lt;/span&gt;，记为&lt;span class=&#34;math inline&#34;&gt;\(\bar X\stackrel{\cdot}\sim N(\mu,\sigma^2/n)\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;不同总体均值的分布&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;CLT.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;卡方分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X_i\stackrel{iid}\sim N(0,1),i=1,\dots,n\)&lt;/span&gt;，则称随机变量
&lt;span class=&#34;math display&#34;&gt;\[X = X_1^2+\dots+X_n^2\]&lt;/span&gt;
服从自由度为&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;的卡方分布，记为&lt;span class=&#34;math inline&#34;&gt;\(X\sim \chi^2(n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;密度函数&lt;/strong&gt;：&lt;span class=&#34;math inline&#34;&gt;\(f(x)=\frac{1}{2^{\frac n2}\Gamma(n/2)}x^{\frac n2-1}e^{-\frac x2} 1\{x&amp;gt;0\}\)&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;exn-varx2n.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;期望和方差：&lt;span class=&#34;math inline&#34;&gt;\(E[X]=n,\ Var[X]=2n\)&lt;/span&gt;.&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;可加性&lt;/strong&gt;：如果&lt;span class=&#34;math inline&#34;&gt;\(X\sim \chi^2(n)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(Y\sim \chi^2(m)\)&lt;/span&gt;且它们独立，则
&lt;span class=&#34;math display&#34;&gt;\[X+Y\sim \chi^2(n+m).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;中心极限定理：
&lt;span class=&#34;math display&#34;&gt;\[\frac{X-n}{\sqrt{2n}}\stackrel{d}\to N(0,1).\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;卡方分布的密度函数曲线&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;Chi-square_pdf.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;样本方差的抽样分布（正态总体）&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理（定理3.3, p38）&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;为来自总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu,\sigma^2)\)&lt;/span&gt;的样本，则&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\sim N(\mu,\sigma^2/n)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{nS_n^2}{\sigma^2}=\frac{\sum_{i=1}^n(X_i-\bar{X})^2}{\sigma^2}\sim \chi^2(n-1)\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;样本均值&lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\)&lt;/span&gt;与样本方差&lt;span class=&#34;math inline&#34;&gt;\(S_n^2\)&lt;/span&gt;相互独立&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细证明见书P39.&lt;/p&gt;
&lt;p&gt;研究发现，只有正态总体才有“样本均值与方差独立”这一性质。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;t&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;t分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(0,1), Y\sim \chi^2(n)\)&lt;/span&gt;, 且它们独立，则称随机变量&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T = \frac{X}{\sqrt{Y/n}}\]&lt;/span&gt;
服从自由度为&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;的学生氏t分布（简称&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;分布），记为&lt;span class=&#34;math inline&#34;&gt;\(T\sim t(n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;密度函数&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f(x)=
\frac{\Gamma\left(\frac{n+1}2\right)}{\sqrt{n\pi }\Gamma\left(\frac n2\right)}\left(1+\frac{x^2}n\right)^{-\frac{n+1}{2}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;两种特例&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;当&lt;span class=&#34;math inline&#34;&gt;\(n=1\)&lt;/span&gt;时，t分布成为柯西分布.&lt;/li&gt;
&lt;li&gt;可以证明：&lt;span class=&#34;math inline&#34;&gt;\(\lim_{n\to\infty}f(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}\)&lt;/span&gt;.
当&lt;span class=&#34;math inline&#34;&gt;\(n\ge 25\)&lt;/span&gt;时,可以认为t分布与&lt;span class=&#34;math inline&#34;&gt;\(N(0,1)\)&lt;/span&gt;接近。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;t&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;t分布的密度函数曲线&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;tpdf.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;t&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;t分布的起源&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;tinfo.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;样本均值与标准差之比的抽样分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;为来自总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu,\sigma^2)\)&lt;/span&gt;的样本，则&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{\sqrt{n-1}(\bar{X}-\mu)}{S_n}=\frac{\sqrt{n}(\bar{X}-\mu)}{S_n^*}\sim t(n-1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;比较：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{\sqrt{n}(\bar{X}-\mu)}{\sigma}\sim N(0,1)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pxc&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;尾部概率P(|X|&amp;gt;c)的比较&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;分布&lt;/th&gt;
&lt;th&gt;c=2&lt;/th&gt;
&lt;th&gt;c=2.5&lt;/th&gt;
&lt;th&gt;c=3&lt;/th&gt;
&lt;th&gt;c=3.5&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;X~N(0,1)&lt;/td&gt;
&lt;td&gt;0.0455&lt;/td&gt;
&lt;td&gt;0.0124&lt;/td&gt;
&lt;td&gt;0.0027&lt;/td&gt;
&lt;td&gt;0.000465&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;X~t(4)&lt;/td&gt;
&lt;td&gt;0.1161&lt;/td&gt;
&lt;td&gt;0.0668&lt;/td&gt;
&lt;td&gt;0.0399&lt;/td&gt;
&lt;td&gt;0.0249&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;f&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;F分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X\sim \chi^2(m), Y\sim \chi^2(n)\)&lt;/span&gt;, 且&lt;span class=&#34;math inline&#34;&gt;\(X,Y\)&lt;/span&gt;相互独立，则随机变量&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Z=\frac{X/m}{Y/n}\]&lt;/span&gt;
称为服从第一自由度为&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;、第二自由度为&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;的F分布，记&lt;span class=&#34;math inline&#34;&gt;\(Z\sim F(m,n)\)&lt;/span&gt;. 其密度函数为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x)=
\frac{\Gamma((m+n)/2)}{\Gamma(m/2)\Gamma(n/2)}\left(\frac{m}{n}\right)^{m/2}x^{\frac m2-1}(1+mx/n)^{-(m+n)/2} 1\{x&amp;gt;0\}
\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;f&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;F分布的性质&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(Z\sim F(m,n)\)&lt;/span&gt;, 则&lt;span class=&#34;math inline&#34;&gt;\(1/Z\sim F(n,m)\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;如果&lt;span class=&#34;math inline&#34;&gt;\(T\sim t(n)\)&lt;/span&gt;, 则&lt;span class=&#34;math inline&#34;&gt;\(T^2\sim F(1,n)\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;f&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;F分布的密度函数曲线&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;fpdf.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;两个独立正态总体的抽样分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设两独立总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu_1,\sigma_1^2)\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(Y\sim N(\mu_2,\sigma_2^2)\)&lt;/span&gt;的样本分别为&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_m),(Y_1,\dots,Y_n)\)&lt;/span&gt;. 样本方差分别为&lt;span class=&#34;math inline&#34;&gt;\(S_{1m}^2,S_{2n}^2\)&lt;/span&gt;. 则&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{(\bar X-\bar Y)-(\mu_1-\mu_2)}{\sqrt{\sigma_1^2/m+\sigma_2^2/n}}\sim N(0,1).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{mS_{1m}^2/\sigma_1^2/(m-1)}{nS_{2n}^2/\sigma_2^2/(n-1)}=\frac{S_{1m}^{*2}\sigma_2^2}{S_{2n}^{*2}\sigma_1^2}\sim F(m-1,n-1).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果&lt;span class=&#34;math inline&#34;&gt;\(\sigma_1=\sigma_2=\sigma\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{(\bar X-\bar Y)-(\mu_1-\mu_2)}{S_w\sqrt{1/m+1/n}}\sim t(m+n-2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(S_w =\sqrt{(mS_{1m}^2+nS_{2n}^2)/(m+n-2)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;顺序统计量&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：若&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;独立同分布，分布函数和密度函数分别为&lt;span class=&#34;math inline&#34;&gt;\(F(x),f(x)\)&lt;/span&gt;. 则&lt;span class=&#34;math inline&#34;&gt;\(X_{(1)}=\min(X_1,\dots,X_n)\)&lt;/span&gt;的分布函数和密度函数分别&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{cases}
F_{X_{(1)}}(x) = 1-(1-F(x))^n\\
f_{X_{(1)}}(x) = n(1-F(x))^{n-1}f(x).
\end{cases}
\]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(X_{(n)}=\max(X_1,\dots,X_n)\)&lt;/span&gt;的分布函数和密度函数分别&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{cases}
F_{X_{(n)}}(x) = F(x)^n\\
f_{X_{(n)}}(x) = nF(x)^{n-1}f(x).
\end{cases}
\]&lt;/span&gt;
更一般地，&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f_{X_{(k)}}(x) = \frac{n!}{(n-k)!(k-1)!}F(x)^{k-1}(1-F(x))^{n-k}f(x),k=1,\dots,n.
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;顺序统计量的联合分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：顺序统计量&lt;span class=&#34;math inline&#34;&gt;\((X_{(i)},X_{(j)})(i&amp;lt;j)\)&lt;/span&gt;的联合密度函数为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
f_{X_{(i)},X_{(j)}}(x,y) = &amp;amp;\frac{n!}{(i-1)!(j-i-1)!(n-j)!}F(x)^{i-1}\\
&amp;amp;[F(y)-F(x)]^{j-i-1}[1-F(y)]^{n-j}f(x)f(y) 1\{x\le y\}.
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：顺序统计量&lt;span class=&#34;math inline&#34;&gt;\((X_{(1)},\dots,X_{(n)})\)&lt;/span&gt;的联合密度函数为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f(y_1,\dots,y_n)=
\begin{cases}
n!\prod_{i=1}^nf(y_i),&amp;amp;y_1&amp;lt;y_2&amp;lt;\dots&amp;lt;y_n\\
0,&amp;amp;else
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;分位数&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;的分布函数为&lt;span class=&#34;math inline&#34;&gt;\(F(x)\)&lt;/span&gt;. 对于任意&lt;span class=&#34;math inline&#34;&gt;\(\alpha\in(0,1)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;分位数&lt;span class=&#34;math inline&#34;&gt;\(x_\alpha\)&lt;/span&gt;满足&lt;span class=&#34;math inline&#34;&gt;\(F(x_\alpha)=\alpha\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;标准正态分布分位数记为&lt;span class=&#34;math inline&#34;&gt;\(u_{\alpha}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;分布分位数记为&lt;span class=&#34;math inline&#34;&gt;\(t_{\alpha}(n)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;分布分位数记为&lt;span class=&#34;math inline&#34;&gt;\(\chi^2_{\alpha}(n)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;分布分位数记为&lt;span class=&#34;math inline&#34;&gt;\(F_{\alpha}(m,n)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;一些说明&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在分位点表中对于标准正态分布、&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;分布和F分布只能查到&lt;span class=&#34;math inline&#34;&gt;\(\alpha&amp;gt;1/2\)&lt;/span&gt;的分位数，需利用以下对称性间接查&lt;span class=&#34;math inline&#34;&gt;\(\alpha&amp;lt;1/2\)&lt;/span&gt;的分位数：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[u_\alpha=-u_{1-\alpha},\  t_\alpha(n)=-t_{1-\alpha}(n),\ F_{\alpha}(m,n)=\frac{1}{F_{1-\alpha}(n,m)}\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;对于&lt;span class=&#34;math inline&#34;&gt;\(t(n)\)&lt;/span&gt;分布，由于当&lt;span class=&#34;math inline&#34;&gt;\(n\to \infty\)&lt;/span&gt;时，其极限分布为&lt;span class=&#34;math inline&#34;&gt;\(N(0,1)\)&lt;/span&gt;, 所以自由度&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;比较大时，&lt;span class=&#34;math inline&#34;&gt;\(t_{\alpha}(n)\approx u_{\alpha}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;若&lt;span class=&#34;math inline&#34;&gt;\(X\sim \chi^2(n)\)&lt;/span&gt;分布，由于当&lt;span class=&#34;math inline&#34;&gt;\(n\to \infty\)&lt;/span&gt;时，&lt;span class=&#34;math inline&#34;&gt;\((X-n)/\sqrt{2n}\stackrel{d}\to N(0,1)\)&lt;/span&gt;, 所以自由度&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;比较大时，&lt;span class=&#34;math inline&#34;&gt;\(\chi^2_{\alpha}(n)\approx u_{\alpha}\sqrt{2n}+n\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;分位数示意图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;quantile.png&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;样本分位数&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设&lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;为样本，其顺序统计量为&lt;span class=&#34;math inline&#34;&gt;\(X_{(1)},\dots,X_{(n)}\)&lt;/span&gt;.
对给定的&lt;span class=&#34;math inline&#34;&gt;\(0&amp;lt;\alpha&amp;lt;1\)&lt;/span&gt;, 该样本的&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;分位数定义为：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
m_\alpha = \begin{cases}
\frac{1}2[X_{([n\alpha])}+X_{([n\alpha]+1)}],&amp;amp;np\text{是整数}\\
X_{([n\alpha]+1)},&amp;amp;np\text{不是整数}
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\([a]\)&lt;/span&gt;表示&lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;的整数部分。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;样本分位数的渐近分布&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设总体的密度为&lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(x_\alpha\)&lt;/span&gt;为其&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;分位数，如果&lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;在&lt;span class=&#34;math inline&#34;&gt;\(x_\alpha\)&lt;/span&gt;处连续，且&lt;span class=&#34;math inline&#34;&gt;\(f(x_\alpha)&amp;gt;0\)&lt;/span&gt;, 则当&lt;span class=&#34;math inline&#34;&gt;\(n\to \infty\)&lt;/span&gt;时，样本的分位数&lt;span class=&#34;math inline&#34;&gt;\(m_\alpha\)&lt;/span&gt;的渐近分布为：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
m_\alpha \stackrel{\cdot}\sim N\left(x_\alpha,\frac{\alpha(1-\alpha)}{nf^2(x_\alpha)}\right).
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;6种杀虫剂的数据&lt;/h2&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:insectsprays&#34;&gt;Table 1: &lt;/span&gt;&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;spray&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;count&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;spray&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;count&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;spray&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;count&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;spray&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;count&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;spray&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;count&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;spray&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;count&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;22&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;D&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;E&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;F&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;箱线图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/post/chap01_files/figure-html/boxplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.5 充分统计量&lt;/h2&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(1) 充分统计量的定义&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;(2) 因子分解定理&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;充分统计量&lt;/h2&gt;
&lt;p&gt;目标&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;简化数据&lt;/li&gt;
&lt;li&gt;不损失重要信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;：设有一个分布族&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots,X_n\)&lt;/span&gt;是从某分布&lt;span class=&#34;math inline&#34;&gt;\(F\in\mathcal{F}\)&lt;/span&gt;中抽取的一个样本。&lt;span class=&#34;math inline&#34;&gt;\(T=T(X_1,\dots,X_n)\)&lt;/span&gt;是一个（向量）统计量。若在给定&lt;span class=&#34;math inline&#34;&gt;\(T=t\)&lt;/span&gt;下，样本&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;的条件分布与总体分布&lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt;无关，则称&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;为此分布族&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}\)&lt;/span&gt;的充分统计量。如果&lt;span class=&#34;math inline&#34;&gt;\(\mathcal{F}=\{F_\theta;\theta\in\Theta\}\)&lt;/span&gt;是参数分布族，在给定&lt;span class=&#34;math inline&#34;&gt;\(T=t\)&lt;/span&gt;下，样本&lt;span class=&#34;math inline&#34;&gt;\((X_1,\dots,X_n)\)&lt;/span&gt;的条件分布与参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;无关，则称&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;为参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的充分统计量。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例1：两点分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim b(1,p),0&amp;lt;p&amp;lt;1\)&lt;/span&gt;. 判断以下两个统计量是否是充分统计量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T_1=\sum_{i=1}^nX_i\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(T_2=X_1+X_2\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例2：几何分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim Ge(p),0&amp;lt;p&amp;lt;1\)&lt;/span&gt;, 证明&lt;span class=&#34;math inline&#34;&gt;\(T=\sum_{i=1}^nX_i\)&lt;/span&gt;是参数&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;的充分统计量。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;例3：正态分布&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：总体&lt;span class=&#34;math inline&#34;&gt;\(X\sim N(\mu,\sigma^2)\)&lt;/span&gt;，其中&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;已知。证明&lt;span class=&#34;math inline&#34;&gt;\(T=\sum_{i=1}^nX_i\)&lt;/span&gt;是参数&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的充分统计量。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;引理&lt;/h3&gt;
&lt;p&gt;设总体的密度为&lt;span class=&#34;math inline&#34;&gt;\(f_\theta(x)\)&lt;/span&gt;. 则在给定&lt;span class=&#34;math inline&#34;&gt;\(T=t\)&lt;/span&gt;下，样本的条件密度函数为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f_\theta(x_1,\dots,x_n|T=t)=\frac{\prod_{i=1}^nf_\theta(x_i) 1\{T(x_1,\dots,x_n)=t\}}{f^T_\theta(t)},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&#34;math inline&#34;&gt;\(f^T_\theta(t)\)&lt;/span&gt;为&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;的密度函数。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;思考题&lt;/h2&gt;
&lt;p&gt;顺序统计量&lt;span class=&#34;math inline&#34;&gt;\(X_{(1)},\dots,X_{(n)}\)&lt;/span&gt;是否充分统计量？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;连续分布族&lt;/li&gt;
&lt;li&gt;离散分布族&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;因子分解定理&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;J. Neyman和P. R. Halmos在20世纪40年代提出&lt;/li&gt;
&lt;li&gt;判断充分统计量的法则&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：设样本的分布为&lt;span class=&#34;math inline&#34;&gt;\(f_\theta(x_1,\dots,x_n)\)&lt;/span&gt;（在离散总体情况下表示样本的分布列，在连续总体情况下表示样本的密度函数）。则在统计量&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;是充分的当且仅当存在两个函数满足&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(h(x_1,\dots,x_n)\)&lt;/span&gt;非负&lt;/li&gt;
&lt;li&gt;在统计量&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;取值空间上的函数&lt;span class=&#34;math inline&#34;&gt;\(g_\theta(t)\)&lt;/span&gt;, 使得&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f_\theta(x_1,\dots,x_n) = g_\theta(T(x_1,\dots,x_n))h(x_1,\dots,x_n),\ \forall\theta\in\Theta, \forall x_i
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;因子分解定理的应用&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;例1&lt;/strong&gt;：总体分布为&lt;span class=&#34;math inline&#34;&gt;\(U(0,\theta)\)&lt;/span&gt;, 求参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的充分统计量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例2&lt;/strong&gt;：总体分布为&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;，求&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参数&lt;span class=&#34;math inline&#34;&gt;\((\mu,\sigma^2)\)&lt;/span&gt;的充分统计量&lt;/li&gt;
&lt;li&gt;当&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;已知时，&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;的充分统计量&lt;/li&gt;
&lt;li&gt;当&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;已知时，&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;的充分统计量&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;指数型分布族的充分统计量&lt;/h2&gt;
&lt;p&gt;指数型分布族下的样本分布为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f_\theta(x_1,\dots,x_n)=\prod_{i=1}^np_\theta(x_i)=c(\theta)^n\exp\{\sum_{j=1}^kc_j(\theta)\sum_{i=1}^nT_j(x_i)\}\prod_{i=1}^nh(x_i)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由因子分解定理知，参数&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;的一个充分统计量为&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left(\sum_{i=1}^nT_1(x_i),\dots,\sum_{i=1}^nT_k(x_i)\right).\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;充分统计量有无穷多个&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;：如果&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;是充分统计量，且&lt;span class=&#34;math inline&#34;&gt;\(T=\psi(S)\)&lt;/span&gt;, 其中&lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt;是可测函数，&lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;是另一个统计量，则&lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;也是充分统计量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例&lt;/strong&gt;：总体分布为&lt;span class=&#34;math inline&#34;&gt;\(N(\mu,\sigma^2)\)&lt;/span&gt;，以下哪些统计量为参数&lt;span class=&#34;math inline&#34;&gt;\((\mu,\sigma^2)\)&lt;/span&gt;的充分统计量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\bar X, S_n)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\bar X, S_n^2)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\bar X, S_n^*)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\bar X, S_n^{*2})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\sum_{i=1}^n X_i,\sum_{i=1}^n X_i^2)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\sum_{i=1}^n X_i,\sum_{i=1}^n |X_i|)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\((\sum_{i=1}^n X_i,\sum_{i=1}^n |X_i|,\sum_{i=1}^n X_i^2)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;思考&lt;/strong&gt;：哪种最好？&lt;em&gt;最小充分统计量&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>/tutorial/example/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0800</pubDate>
      
      <guid>/tutorial/example/</guid>
      <description>

&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;

&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
