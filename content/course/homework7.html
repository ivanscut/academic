---
title: 第七次作业

date: 2018-12-18 
lastmod: 2018-12-18 

draft: false
# toc: true
type: docs

linktitle: 第七次作业
menu:
  course: 
    parent: 数理统计
    weight: 12
---



<p>Let <span class="math inline">\(X_1,\dots,X_{100}\)</span> be a sample from <span class="math inline">\(N(\mu,1)\)</span>. Given a significance level <span class="math inline">\(\alpha=0.05\)</span>, derive a UMP rejection region <span class="math inline">\(W\)</span> of</p>
<p><span class="math display">\[H_0:\mu=0\ vs.\ H_1:\mu&gt;0.\]</span>
Let <span class="math inline">\(W&#39;=\{\vec x:|\bar x| &gt; u_{0.975}/10\}\)</span> be another rejection region. Show that the significance level for <span class="math inline">\(W&#39;\)</span> is <span class="math inline">\(0.05\)</span>, and graph the power functions for <span class="math inline">\(W\)</span> and <span class="math inline">\(W&#39;\)</span>. Try to explain that you observed.</p>
<!--
`Solution`: The UMP rejection region $W=\{\vec x:\bar x > u_{0.95}/10\}$. It is easy to see that $P(\vec X\in W'|\mu=0)=0.05$.


```r
curve(1-pnorm(qnorm(0.95)-10*x),0,1,ylab="power functions")
curve(1-pnorm(qnorm(0.975)-10*x)+pnorm(qnorm(0.025)-10*x),0,1,
      add = TRUE, col = "red")
legend(0.6,0.6,legend=c("W","W'"),col=c("black","red"),lty = c(1,1))
```

<img src="/course/homework7_files/figure-html/unnamed-chunk-1-1.png" width="672" />

-->
<hr />
<p>Let <span class="math inline">\(X_1,\dots,X_n\)</span> be a sample from an exponential distribution <span class="math inline">\(Exp(\lambda)\)</span>. Given a significance level <span class="math inline">\(\alpha\)</span>, derive a likelihood ratio test of</p>
<p><span class="math display">\[H_0:\lambda=\lambda_1\ vs.\ H_1:\lambda=\lambda_2,\]</span></p>
<p>where <span class="math inline">\(\lambda_1\neq\lambda_2\)</span>.</p>
<!-- 
`Solution`: The likelihood function is 
$$L(\lambda)=\prod_{i=1}^n (\lambda e^{-\lambda x_i}) = \lambda^ne^{-\lambda n\bar x}.$$


The likelihood ratio is given by
$$\lambda(\vec x)= \frac{L(\lambda_2)}{L(\lambda_1)}=\frac{\lambda_2^ne^{-\lambda_2 n\bar x}}{\lambda_1^ne^{-\lambda_1 n\bar x}}=(\lambda_2/\lambda_1)^ne^{(\lambda_1-\lambda_2)n\bar x}.$$

Choose the ``test statistic`` $T(\vec x) = 2\lambda_1n\bar x$. When $\lambda=\lambda_1$, $T(\vec X)\sim \chi^2(2n)$. Also, 
$$\lambda(\vec x) = (\lambda_2/\lambda_1)^ne^{(\lambda_1-\lambda_2)T(\vec x)/(2\lambda_1)}.$$


1. Note that $\lambda_1,\lambda_2>0$. If $\lambda_1>\lambda_2$, the rejection region is of the form $W=\{T(\vec x)>C\}$. We thus have $C=\chi_{1-\alpha}^2(2n)$.

2. If $\lambda_1<\lambda_2$, the rejection region is of the form $W=\{T(\vec x)<C\}$. We thus have $C=\chi_{\alpha}^2(2n)$.

-->
<hr />
<p>Let <span class="math inline">\(X_1,\dots,X_n\)</span> be a sample from an exponential distribution <span class="math inline">\(Exp(\lambda)\)</span>. Given a significance level <span class="math inline">\(\alpha\)</span>, derive a UMPU test of</p>
<p><span class="math display">\[H_0:\lambda=\lambda_0\ vs.\ H_1:\lambda\neq\lambda_0.\]</span></p>
<!-- 
`Solution`: Exponential distribution belongs to exponential family of the form $S(\lambda)h(x)e^{Q(\lambda)V(x)}$ with $V(x) = -x$ and $Q(\lambda)=\lambda$. Choose the ``test statistic`` $T(\vec x)=2\lambda_0 n\bar x$.  As a result, the UMPU rejection region has the form
$$W = \{T(\vec x)<C_1 \text{ or } >C_2\},$$
where $C_1,C_2$ satisfy 
$$P_{\lambda_0}(\bar X\in W)=\alpha$$
and
$$E_{\lambda_0}[1\{\vec X\in W\}T(\vec X)]=\alpha E_{\lambda_0}[T(\vec X)].$$
Let $f(x;n)$ be the density of $\chi^2(n)$, that is 
$$f(x;n)=\frac{1}{2^{n/2}\Gamma(n/2)}x^{n/2-1}e^{-x/2}1\{x>0\}.$$
If $\lambda=\lambda_0$, $T(\vec X)\sim \chi^2(2n)$. We thus have
$$\int_{C_1}^{C_2}f(x;2n) d x=1-\alpha,\quad(1)$$
$$\int_{C_1}^{C_2} x f(x;2n)dx = 2n(1-\alpha).$$
The later equality can be expressed as
$$\int_{C_1}^{C_2} \frac{x}{2n} f(x;2n)dx=\int_{C_1}^{C_2} \frac{x}{2n} \frac{1}{2^{n}\Gamma(n)}x^{n-1}e^{-x/2}dx=\int_{C_1}^{C_2} f(x;2n+2)dx=1-\alpha.\quad(2)$$

It is hard to solve the equations (1) and (2). In practice, we may take
$C_1=\chi_{\alpha/2}^2(2n)$ and $C_2=\chi_{1-\alpha/2}^2(2n)$ so that the significance level of the test is $\alpha$. BUT, it is not the exact UMPU test since (2) is not satisfied. If $n$ is large enough, $f(x;2n+2)\approx f(x;2n)$ (see figure below). This implies the resulting rejection region is almost UMPU when $n$ is large.

<img src="/course/homework7_files/figure-html/unnamed-chunk-2-1.png" width="672" />

Of course, you can solve the equations (1) and (2) by numerical algorithms, such as bisection and Newton's methods. Let $F(x;n)$ be the CDF of $\chi^2(n)$ and $F^{-1}$ denote its inverse. By (1), we have $C_2=F^{-1}(F(C_1;2n)+1-\alpha;2n)$. Substituting  it into (2), we arrive at an equation:
$$F(F^{-1}(F(C_1;2n)+1-\alpha;2n);2n+2)-F(C_1;2n+2)=1-\alpha.$$

We can slove the equation using R function `uniroot`. The code is given below.


```r
myfun <- function(c,n,alpha)
  pchisq(qchisq(pchisq(c,2*n)+1-alpha,2*n),2*n+2)-pchisq(c,2*n+2)-1+alpha

mysolver <- function(n,alpha){
  a = qchisq(alpha/2,2*n)
  b = qchisq(alpha/2,2*n+2)
  ## solve the equation by using the root finding algorithm
  r = uniroot(myfun,n=n,alpha=alpha,interval = c(a,b))
  c1 = r$root
  c2 = qchisq(pchisq(c1,2*n)+1-alpha,2*n)
  err1 = pchisq(c2,2*n+2)-pchisq(c1,2*n+2)-1+alpha #check the error for eq. (2)
  ## the approximate method
  c11 = qchisq(alpha/2,2*n)
  c22 = qchisq(1-alpha/2,2*n)
  err2 = pchisq(c22,2*n+2)-pchisq(c11,2*n+2)-1+alpha #check the error for eq. (2)
  output = data.frame(exact=c(c1,c2,abs(err1)),rough=c(c11,c22,abs(err2)),
                      row.names = c("C1","C2","error"))
  return(output)
}
alpha = 0.5
n = 10
output = mysolver(n,alpha)
knitr::kable(output,"html",caption = "n=10, alpha=0.05")
```

<table>
<caption>(\#tab:unnamed-chunk-3)n=10, alpha=0.05</caption>
 <thead>
  <tr>
   <th style="text-align:left;">   </th>
   <th style="text-align:right;"> exact </th>
   <th style="text-align:right;"> rough </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> C1 </td>
   <td style="text-align:right;"> 16.00121 </td>
   <td style="text-align:right;"> 15.451773 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C2 </td>
   <td style="text-align:right;"> 24.61524 </td>
   <td style="text-align:right;"> 23.827692 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> error </td>
   <td style="text-align:right;"> 0.00000 </td>
   <td style="text-align:right;"> 0.014194 </td>
  </tr>
</tbody>
</table>

For large $n=100$, we have the following results.


```r
n = 100
output = mysolver(n,alpha)
knitr::kable(output,"html",caption = "n=100, alpha=0.05")
```

<table>
<caption>(\#tab:unnamed-chunk-4)n=100, alpha=0.05</caption>
 <thead>
  <tr>
   <th style="text-align:left;">   </th>
   <th style="text-align:right;"> exact </th>
   <th style="text-align:right;"> rough </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> C1 </td>
   <td style="text-align:right;"> 186.8010 </td>
   <td style="text-align:right;"> 186.171668 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C2 </td>
   <td style="text-align:right;"> 213.8065 </td>
   <td style="text-align:right;"> 213.102185 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> error </td>
   <td style="text-align:right;"> 0.0000 </td>
   <td style="text-align:right;"> 0.001428 </td>
  </tr>
</tbody>
</table>

As expected, the error for the rough estimates $C_1=\chi_{\alpha/2}^2(2n)$ and $C_2=\chi_{1-\alpha/2}^2(2n)$ decreases as $n$ goes up. 

-->
<hr />
<p>Let <span class="math inline">\(X_1,\dots,X_n\)</span> be a sample from <span class="math inline">\(U[0,\theta]\)</span>. Given a significance level <span class="math inline">\(\alpha\)</span>, derive a UMP test of</p>
<p><span class="math display">\[H_0:\theta=\theta_0\ vs.\ H_1:\theta&gt;\theta_0.\]</span></p>
<!-- 
`Solution`: Firstly, consider the simple alternative:
$$H_0:\theta=\theta_0\ vs.\ H_1:\theta=\theta_1>\theta_0.$$

The likelihood function is $L(\theta)=\theta^{-n}1\{x_{(n)}\le \theta\}$.
The likelihood ratio for the simple test is 
$$\lambda(\vec x) = \frac{\theta_1^{-n}1\{x_{(n)}\le \theta_1\}}{\theta_0^{-n}1\{x_{(n)}\le \theta_0\}}
=\begin{cases}
(\theta_0/\theta_1)^n,\ &x_{(n)}\le \theta_0\\
\infty,\ &x_{(n)}> \theta_0
\end{cases}$$

We therefore cannot find a $\lambda_0$ such that $P_{\theta_0}(\lambda(\vec X)>\lambda_0)=\alpha$. This implies that the N-P lemma cannot be applied. As we can see, the likelihood ratio is a function of $x_{(n)}$. We thus can use $X_{(n)}$ as the test statistic. A resonable rejection region would be
$W = \{x_{(n)}>C\}$, where $C$ satisfies
$$P_{\theta_0}(X_{(n)}>C)=\alpha.$$

When $\theta=\theta_0$, the order statistic $X_{(n)}/\theta_0$ has a CDF $F(x)=x^n$ (see [Exercise 1](https://hezhijian.netlify.com/post/homework5/)). So we have $C=(1-\alpha)^{1/n}\theta_0$. The rejection region is
$$W = \{\vec x:x_{(n)}>(1-\alpha)^{1/n}\theta_0\}.$$


We next prove that $W$ is UMP. Suppose that there exists a rejection region $W'$ satisfying $P_{\theta_0}(\vec X\in W')\le \alpha$. Let $A=[0,\theta_0]^n$ be the sample space when $\theta=\theta_0$, and let $B=[0,\theta_1]^n$ be the sample space  when $\theta=\theta_1$. It is clear that $A\subseteq B$ since $\theta_1>\theta_0$. This implies 
$$P_{\theta_0}(\vec X\in W') = P_{\theta_0}(\vec X\in W'\cap A)=\frac{1}{\theta_0^n}\int_{W'\cap A} 1 d x_1\dots d x_n\le \alpha.$$
Similarly, 
$$P_{\theta_0}(\vec X\in W) = P_{\theta_0}(\vec X\in W\cap A)=\frac{1}{\theta_0^n}\int_{W\cap A} 1 d x_1\dots d x_n= \alpha.$$
Define $\mu(E) = \int_E 1 d x_1\dots d x_n$. So we have $\mu(W\cap A)\ge \mu(W'\cap A)$. 


On the other hand, noticing that $W\cap B=W\cap A+\bar A\cap B$, we thus have

$$
\begin{align}
P_{\theta_1}(\vec X\in W) &=\frac{1}{\theta_1^n}\int_{W\cap B} 1 d x_1\dots d x_n\\&=\frac{1}{\theta_1^n}\int_{W\cap A}1 d x_1\dots d x_n+\frac{1}{\theta_1^n}\int_{\bar A\cap B}1 d x_1\dots d x_n\\
&=\theta_1^{-n}[\mu(W\cap A)+\mu(\bar A\cap B)]\\
&\ge \theta_1^{-n}[\mu(W'\cap A)+\mu(W'\cap\bar A\cap B)\\
&=\theta_1^{-n}\mu(W'\cap B)=P_{\theta_1}(\bar X\in W').
\end{align}
$$

Therefore, $W$ is UMP rejection region. Since $W$ does not depend on $\theta_1$, it is also the UMP rejection region for the alternative $H_1:\theta>\theta_0$.

For this example, the UMP rejection region is not unique. Following the same procedure above, one can  easily prove that for any
set $W_0\subset A$ with $\mu(W_0)=\alpha\theta_0^n$, $W=W_0\cup \bar A$ is UMP.

-->
<hr />
<p>Let <span class="math inline">\(X_1,X_2,X_3,X_4\)</span> be a sample from <span class="math inline">\(N(\theta,1)\)</span>. Given a significance level <span class="math inline">\(\alpha=0.1\)</span>, derive a UMP test of</p>
<p><span class="math display">\[H_0:\theta\ge 10\ vs.\ H_1:\theta&lt;10.\]</span>
Calculate the power of the test when <span class="math inline">\(\theta=9\)</span>.</p>
<!--
`Solution`: The test statistics is $T(\vec x)=\frac{\bar x-10}{1/\sqrt{n}}=\sqrt{n}(\bar x-10)=2(\bar x-10)$, where $n=4$. The UMP rejection region has the form $W=\{T(\vec x)<C\}$, where $C$ satisfies
$$P(T(\vec X)<C|\theta=10)=\alpha=0.1$$
This gives $C= u_{0.1}=-u_{0.9}=-1.28$. So $$W=\{\vec x|2(\bar x-10)<-1.28\}=\{\vec x|\bar x<9.36\}.$$

The power of the test is 
$$P(\bar X<9.36|\theta=9)=P(2(\bar X-9)<0.72|\theta=9)=\Phi(0.72)=0.76.$$

-->
