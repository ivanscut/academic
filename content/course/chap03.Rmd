---
title: 第三章：假设检验

date: 2018-12-18
lastmod: 2018-12-18

draft: false
#toc: true
type: docs

linktitle: 第三章
menu:
  course: 
    parent: 数理统计
    weight: 4
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Contents

### 1. 假设检验基本概念

- 1.1 检验问题的提出
- 1.2 检验法则与两类错误
- 1.3 检验水平与功效

### 2. 似然比检验

- 2.1 似然比检验法原理
- 2.2 Neyman-Pearson引理
- 2.3 单参数指数型的假设检验

### 3. 广义似然比检验

- 3.1 广义似然比检验法原理
- 3.2 单个正态总体的假设检验
- 3.3 两个独立正态总体的假设检验

### 4. 拟合优度检验

- 4.1 卡方检验法
- 4.2 独立性检验
- 4.3 柯尔莫哥洛夫检验法
- 4.4 正态性检验

## Case study

奶茶是由牛奶与茶按一定比例混合而成，可以先倒茶后加奶，也可以先倒奶再倒茶。某女士声称她可以鉴别这两种混合方式，周围品茶的人对此产生了议论，都觉得不可思议。在场的费希尔也在思考这个问题，他提议做一项试验来检验如下命题是否可以接受：

> 假设H: 该女士无此种鉴别能力

他准备了10杯调好的奶茶（两种顺序的都有）给该女士鉴别，结果那位女士竟然能够正确地分辨出10杯奶茶中的每一杯的调制顺序。


**如何做出你的判断？**

**假如该女士只猜对了9杯（或者8杯），又该如何判断？**

## Some examples

1. 产品的次品率是否不超过$3\%$

2. 男生群体平均身高是否大于女生群体平均身高？

3. 身高是否服从正态分布？

4. 抽烟与慢性支气管炎是否有关？


## 1. Basis concepts for  HT

设有来自某一参数分布族$\{F(x,\theta)\}$, $\theta\in\Theta$, 其中$\Theta$为参数空间。

原假设（零假设, Null Hypothesis）

$$H_0:\theta \in \Theta_0$$

备选假设（对立假设，备择假设, Alternative Hypothesis）

$$H_1:\theta \in \Theta_1$$

其中$\varnothing\neq \Theta_0,\Theta_1\subset \Theta,\Theta_0\cap \Theta_1=\varnothing$. 最常见的情况$\Theta_1=\Theta-\Theta_0$.

简单原假设(simple null)：$\Theta_0$只包含一个点，如$H_0:\theta=\theta_0$

复杂原假设(composite null)：$\Theta_0$只包含多个点，如$H_0:\theta\le \theta_0$ 

备选假设$H_1$通常有三种可能：

1. 双边(two-sided)：$H_1:\theta\neq \theta_0$
2. 单边(one-sided)：$H_1:\theta> \theta_0$ 
3. 单边(one-sided)：$H_1:\theta< \theta_0$

## The decision rule for HT

**检验法则**：检验本质上是把样本空间划分成两个互不相交的部分$W$和$\bar{W}$, 当样本属于$W$时就拒绝$H_0$; 否则接受$H_0$. 称$W$为该检验的*拒绝域(rejection region)*，而$\bar W$为*接受域(acceptance region)*.

**例**：假设总体为$N(\theta,1)$, 样本为$X_1,\dots,X_n$. 考虑检验问题

$$H_0:\theta=\theta_0\ vs. \ H_1:\theta\neq\theta_0$$

拒绝域可以设为：$W=\{(x_1,\dots,x_n):|\bar x-\theta_0|\ge c\}$

一个检验法则对应一种拒绝域；一个拒绝域决定一种检验法则。**假设检验的目标是在给定准则下选取合适的拒绝域**。

- 原假设$H_0$在客观上只有“真”和“假”两种可能

- 样本也只有两种可能性：$(X_1,\dots,X_n)\in W$ 或者 $(X_1,\dots,X_n)\notin W$

- 由于样本的随机性，检验不可能$100\%$正确

## Two types of errors

|| 接受原假设 | 拒绝原假设 |
-|-|-|
原假设为真 | 正确 | 第一类（拒真, Type I）错误 |
备择假设为真 | 第二类（纳伪, Type II）错误 | 正确 | 

## A toy example 

**例**：假设总体为$N(\theta,1)$, 样本为$X_1,\dots,X_n$. 考虑简单的检验问题(simple hypothesis)

$$H_0:\theta=\theta_1\ vs. \ H_1:\theta=\theta_2$$

其中$\theta_1\neq\theta_2$. 拒绝域选择为$W=\{(x_1,\dots,x_n):|\bar x-\theta_1|\ge c\}$.

- 犯第一类错误的概率为

$$\alpha = P_{\theta_1}(|\bar{X}-\theta_1|\ge c)=2-2\Phi(c\sqrt{n})$$

- 犯第二类错误的概率为

$$\beta = P_{\theta_2}(|\bar{X}-\theta_1|< c)=\Phi((\theta_1-\theta_2+c)\sqrt{n})-\Phi((\theta_1-\theta_2-c)\sqrt{n})$$

- 如果$\alpha$变小，则$c$增大，于是$\beta$变大。
- 如果$\beta$变小，则$c$减小，于是$\alpha$变大。

**结论**：在样本量不变的前提下，两类错误不能同时减小。

## Significance level and power

**拒绝域的选取准则**：在保证犯第一类错误的概率不超过一定水平的前提下，选择犯第二类错误的概率尽可能小的拒绝域$W$


**功效函数(power function)**：

$$\rho_W(\theta):=P_{\theta}((X_1,\dots,X_n)\in W)$$

- 当$\theta\in \Theta_0$时，$\rho_W(\theta)$表示犯第一类错误的概率

- 当$\theta\in \Theta_1$时，$1-\rho_W(\theta)$表示犯第二类错误的概率，$\rho_W(\theta)$表示检验的功效(power of a test)

$W$的**检验水平**（显著性水平，level of significance）：
$$\sup_{\theta\in\Theta_0} \rho_W(\theta)= \alpha$$

- 一般取$\alpha=0.1,0.05,0.01$

**小概率原理**：小概率事件在一次试验中是几乎不发生的。若$H_0$为真，样本落在拒绝域$W$是小概率事件，不应发生。如发生，则拒绝原假设

## How to choose the significance level?

人们自然会产生这样的问题：概率小到什么程度才当作“小概率事件”呢？这要据实际情况而定，例如即使下雨的概率为10\%，仍有人会因为它太小而不带雨具。但某航空公司的事故率为1\%，人们就会因为它太大而不敢乘坐该公司的飞机，通常把概率不超过0.05  (或0.01)的事件当作“小概率事件(rare event)”。为此在假设检验时，必须先确定小概率即显著性的值$\alpha$ (即不超过$\alpha$的概率认为是小概率)。

## UMP tests

**定义**：称$W$为检验水平$\alpha$的一致最大功效(uniformly most powerful, UMP)的拒绝域，若$W$的水平为$\alpha$且对一切水平不超过$\alpha$的拒绝域$W'$均有
$$\rho_W(\theta)\ge \rho_{W'}(\theta),\ \forall \theta\in \Theta_1$$

**定义**：称$W$为检验水平$\alpha$的无偏拒绝域，若$\forall \theta\in \Theta_1$, 有$\rho_W(\theta)\ge \alpha$.

**定义**：称$W$为检验水平$\alpha$的一致最大功效无偏(uniformly most powerful unbiased, UMPU)的拒绝域，若$W$是水平为$\alpha$的无偏拒绝域且对一切水平不超过$\alpha$的无偏拒绝域$W'$均有
$$\rho_W(\theta)\ge \rho_{W'}(\theta),\ \forall \theta\in \Theta_1$$

- UMP意味着在犯第一类错误的概率不超过$\alpha$的前提下，犯第二类错误的概率最小

## Case study: two coins

Suppose that I
have two coins, coin 0 has probability of heads equal to **0.5** and coin 1 has probability
of heads equal to **0.7**. I choose one of the coins, **toss it 10 times** and tell you the
number of heads, but do not tell you whether it was coin 0 or coin 1. On the basis
of the number of heads, your task is to decide which coin it was. How should your
decision rule be?

- let $X$ be the number of heads

- let $\theta$ be the coin that produce this result. 

- your test might be: $H_0: \theta=0\ vs.\ \theta=1$

## The probability mass function (PMF)

![](2coins.png)


## The decision rule

- Suppose that you observed two heads. Then $P_0(2)/P_1(2)\approx 30$, which we
will call the **likelihood ratio (LR)**—coin 0 was about 30 times more likely to produce this
result than was coin 1. This result would favor coin 0. 

- On the other hand, if there were
8 heads, the likelihood ratio would be $P_0(8)/P_1(8)\approx 0.19$, which would favor coin 1. 

- The likelihood ratio will play a central role in the procedures we develop.

## 2. Likelihood ratio tests

考虑最简单的假设检验$(\theta_1\neq \theta_2)$：

$$H_0: \theta=\theta_1\ vs.\ \theta=\theta_2$$

令$\vec x=(x_1,\dots,x_n)$, 似然比检验的拒绝域为：

$$W=\{\vec x:\frac{L(\vec x;\theta_2)}{L(\vec x;\theta_1)}> \lambda\}$$

其中$\lambda\ge 0$满足

$$P_{\theta_1}((X_1,\dots,X_n)\in W)=\int_W L(\vec x;\theta_1)d\vec x=\alpha$$


**Neyman-Pearson Lemma**(课本P68)：上述定义的似然比检验$W$是一致最大功效的

**定理**：上述似然比拒绝域$W$是无偏的(unbiased)，即$\rho_{W}(\theta_2)\ge \alpha$

## UMP tests for normal mean 

**例**：假设总体为$N(\mu,\sigma^2)$, 其中$\sigma^2$已知， 样本为$X_1,\dots,X_n$. 考虑检验水平为$\alpha$的检验问题$(\mu_2>\mu_1)$, 

$$H_0:\mu=\mu_1\ vs. \ H_1:\mu=\mu_2$$

**解**：似然比检验的拒绝域为：$W=\{\vec x:\frac{L(\vec x;\mu_2)}{L(\vec x;\mu_1)}> \lambda\}$. 令似然比
$$\frac{L(X_1,\dots,X_n;\mu_2)}{L(X_1,\dots,X_n;\mu_1)}=\prod_{i=1}^n\frac{f(X_i;\mu_2,\sigma^2)}{f(X_i;\mu_1,\sigma^2)}=e^{\frac{n(\mu_2-\mu_1)(2\bar X-\mu_1-\mu_2)}{2\sigma^2}}$$

等价于找$C$, 使得$P_{\mu_1}(\bar X> C)=\alpha$, $C=\mu_1+u_{1-\alpha}\sigma/\sqrt{n}$, 所以似然比检验的拒绝域为$W=\{\vec x:\bar x> \mu_1+u_{1-\alpha}\sigma/\sqrt{n}\}$

与双侧拒绝域比较：$W'=\{\vec x:|\bar x-\mu_1|> u_{1-\alpha/2}\sigma/\sqrt{n}\}$, **哪个好？**

## Comparison

```{r}
a = 1
b = 2
x = seq(-4,4,by=0.01)+2
y1 = dnorm(x,a,1)
y2 = dnorm(x,b,1)
par(mfrow=c(2,1),mar=c(2,2,2,1))
plot(x,y1,type="l",xlab="",ylab="",main="H_0")
abline(v=c(a+qnorm(0.9),a+qnorm(0.95),a-qnorm(0.95)),col = c("red","green","green"),lty=2,lwd=3)
plot(x,y2,type="l",xlab="",ylab="",main="H_1")
abline(v=c(a+qnorm(0.9),a+qnorm(0.95),a-qnorm(0.95)),col = c("red","green","green"),lty=2,lwd=3)

```

## UMP tests for normal mean 

**例**：假设总体为$N(\mu,\sigma^2)$, 其中$\sigma^2$已知， 样本为$X_1,\dots,X_n$. 考虑检验水平为$\alpha$的检验问题$(\mu_2<\mu_1)$, 

$$H_0:\mu=\mu_1\ vs. \ H_1:\mu=\mu_2$$

**解**：似然比检验的拒绝域为：$W=\{\vec x:\frac{L(\vec x;\mu_2)}{L(\vec x;\mu_1)}> \lambda\}$. 令似然比
$$\frac{L(X_1,\dots,X_n;\mu_2)}{L(X_1,\dots,X_n;\mu_1)}=\prod_{i=1}^n\frac{f(X_i;\mu_2,\sigma^2)}{f(X_i;\mu_1,\sigma^2)}=e^{\frac{n(\mu_2-\mu_1)(2\bar X-\mu_1-\mu_2)}{2\sigma^2}}$$

等价于找$C$, 使得$P_{\mu_1}(\bar X< C)=\alpha$, $C=\mu_1+u_{\alpha}\sigma/\sqrt{n}$, 所以似然比检验的拒绝域为$W=\{\vec x:\bar x< \mu_1+u_{\alpha}\sigma/\sqrt{n}\}$

## UMP tests for normal mean 

**例**：假设总体为$N(\mu,\sigma^2)$, 其中$\sigma^2$已知， 样本为$X_1,\dots,X_n$. 分别求以下假设检验的一致最大功效拒绝域：

$$H_0:\mu=\mu_1\ vs. \ H_1:\mu>\mu_1$$

$$H_0:\mu\le\mu_1\ vs. \ H_1:\mu>\mu_1$$

$$H_0:\mu=\mu_1\ vs. \ H_1:\mu<\mu_1$$

$$H_0:\mu\ge\mu_1\ vs. \ H_1:\mu<\mu_1$$

**解**：前面两种情况的UMP拒绝域为$$W=\{\vec x:\bar x> \mu_1+u_{1-\alpha}\sigma/\sqrt{n}\}$$

后面两种情况的UMP拒绝域为$$W=\{\vec x:\bar x< \mu_1+u_{\alpha}\sigma/\sqrt{n}\}$$

## Single-parameter exponential families 

**定义**：设$X$的可能的集合为$\mathcal{X}$. 称$X$服从单参数指数型分布(single-parameter exponential family)，若$X$的密度函数（或者分布列）有下列表达式

$$f(x;\theta) =  S(\theta)h(x)\exp(Q(\theta)V(x))$$

其中$\theta\in\Theta=(a,b),-\infty\le a<b\le \infty,S(\theta)>0,x\in \mathcal{X},h(x)>0,Q(\theta)$是$\theta$的*严格增函数*。常见的分布都是指数型分布，比如：

- 指数分布：$f(x;\lambda)=\lambda e^{-\lambda x}$, $Q(\lambda)=\lambda$, $V(x)=-x$

- Poisson分布：$f(x;\lambda)=\frac{e^{-\lambda}\lambda^x}{x!}=\frac{e^{-\lambda}e^{\log(\lambda) x}}{x!}$, $Q(\lambda)=\log(\lambda)$, $V(x)=x$

- 正态分布($\sigma^2$已知)：$f(x;\mu) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$, $Q(\mu)=\mu/\sigma^2$, $V(x)=x$

- 正态分布($\mu$已知)：$Q(\sigma^2)=-\frac{1}{2\sigma^2}$, $V(x)=(x-\mu)^2$

## The tests

$$H_0:\theta\le \theta_1\ vs.\ H_1:\theta>\theta_1$$

$$H_0:\theta\ge \theta_1\ vs.\ H_1:\theta<\theta_1$$

$$H_0:\theta\notin (\theta_1,\theta_2)\ vs.\ H_1:\theta\in (\theta_1,\theta_2)$$

$$H_0:\theta\in [\theta_1,\theta_2]\ vs.\ H_1:\theta\notin [\theta_1,\theta_2]$$


$$H_0:\theta=\theta_0\ vs.\ H_1:\theta\neq\theta_0$$


## UMP tests I

**定理**：考虑上述单参数指数型分布，给定检验问题

$$H_0:\theta\le \theta_1\ vs.\ H_1:\theta>\theta_1$$

对$\alpha\in(0,1)$, 若存在$C$满足

$$P_{\theta_1}\left(\sum_{i=1}^n V(X_i)>C\right)=\alpha,$$

则检验水平为$\alpha$的一致最大功效的拒绝域为：$$W=\{\vec x:\sum_{i=1}^n V(x_i)>C\}.$$

## UMP tests II

**定理**：考虑上述单参数指数型分布，给定检验问题

$$H_0:\theta\ge \theta_1\ vs.\ H_1:\theta<\theta_1$$

对$\alpha\in(0,1)$, 若存在$C$满足

$$P_{\theta_1}\left(\sum_{i=1}^n V(X_i)<C\right)=\alpha,$$

则检验水平为$\alpha$的一致最大功效的拒绝域为：$$W=\{\vec x:\sum_{i=1}^n V(x_i)<C\}.$$



## UMP tests for normal mean 

**例1**：假设总体为$N(\mu,\sigma^2)$, 其中$\sigma^2$已知， 样本为$X_1,\dots,X_n$. 求下列检验的UMP

$$H_0:\mu\le\mu_1\ vs. \ H_1:\mu>\mu_1$$

**解**：因为在指数分布族形式中$V(x)=x$, UMP拒绝域为$$W=\{\vec x:\sum_{i=1}^nx_i>C\}=\{\vec x:\bar x>C'\},$$ 其中$C'$满足
$P_{\mu_1}(\bar X>C')=\alpha$, $C'=\mu_1+u_{1-\alpha}\sigma/\sqrt{n}$

## UMP tests for normal variance 

**例2**：假设总体为$N(\mu,\sigma^2)$, 其中$\mu$已知， 样本为$X_1,\dots,X_n$. 求下列检验的UMP

$$H_0:\sigma^2\le\sigma^2_1\ vs. \ H_1:\sigma^2>\sigma^2_1$$

**解**：因为在指数分布族形式中$V(x)=(x-\mu)^2$, UMP拒绝域为
$$W=\{\vec x:\sum_{i=1}^n(x_i-\mu)^2>C\}=\{\vec x:\sum_{i=1}^n\frac{(x_i-\mu)^2}{\sigma^2_1}>C'\},$$ 

其中$C'$满足$P_{\sigma^2_1}(\sum_{i=1}^n\frac{(x_i-\mu)^2}{\sigma^2_1}>C')=\alpha$, 所以$C'=\chi^2_{1-\alpha}(n)$



##  UMP tests III

**定理**：考虑上述单参数指数型分布，给定检验问题

$$H_0:\theta\notin (\theta_1,\theta_2)\ vs.\ H_1:\theta\in (\theta_1,\theta_2)$$

令
$$W=\{\vec x:C_1<\sum_{i=1}^n V(x_i)<C_2\}.$$

若存在$C_1,C_2$满足
$$P_{\theta_1}(\vec X\in W)=P_{\theta_2}(\vec X\in W)=\alpha$$

则检验水平为$\alpha$的一致最大功效的拒绝域为$W$.


## UMPU tests I

**定理**：考虑上述单参数指数型分布，给定检验问题

$$H_0:\theta\in [\theta_1,\theta_2]\ vs.\ H_1:\theta\notin [\theta_1,\theta_2]$$

令$$W=\{\vec x:\sum_{i=1}^n V(x_i)\notin[C_1,C_2]\}.$$

若存在$C_1,C_2$满足
$$P_{\theta_1}(\vec X\in W)=P_{\theta_2}(\vec X\in W)=\alpha$$


则检验水平为$\alpha$的一致最大功效无偏(UMPU)的拒绝域为$W$.

## UMPU tests II

**定理**：考虑上述单参数指数型分布，给定检验问题

$$H_0:\theta=\theta_0\ vs.\ H_1:\theta\neq\theta_0$$

令$W=\{\vec x:\sum_{i=1}^n V(x_i)\notin[C_1,C_2]\}.$

若存在$C_1,C_2$满足  
$$P_{\theta_0}(\vec X\in W)=\alpha$$

$$E_{\theta_0}\left[1\{\vec X\in W\}\sum_{i=1}^n V(X_i)\right]=\alpha E_{\theta_0}\left[\sum_{i=1}^n V(X_i)\right]$$

则检验水平为$\alpha$的一致最大功效无偏(UMPU)的拒绝域为$W$.

## UMPU tests II (continued)

**推论**：考虑上述单参数指数型分布，给定检验问题

$$H_0:\theta=\theta_0\ vs.\ H_1:\theta\neq\theta_0$$
如果在$\theta=\theta_0$下，$T(\vec X) = \sum_{i=1}^n V(X_i)$的分布关于某数$r_0$对称，取$$W=\{\vec x:|T(\vec x)-r_0|>C\}.$$

若存在$C$满足  
$$P_{\theta_0}(\vec X\in W)=\alpha,$$

则检验水平为$\alpha$的一致最大功效无偏(UMPU)的拒绝域为$W$.

## Two-sided tests for normal mean

**例**：假设总体为$N(\mu,\sigma^2)$, 其中$\sigma^2$已知， 样本为$X_1,\dots,X_n$. 求下列检验的UMPU拒绝域

$$H_0:\mu=\mu_0\ vs. \ H_1:\mu\neq\mu_0$$

**解**：因为在指数分布族形式中$V(x)=x$, 此时$T(\vec X)=\sum_{i=1}^nX_i$.
在$\mu=\mu_0$下，$T(\vec X)\sim N(n\mu_0,n\sigma^2)$, 故其分布关于$r_0=n\mu_0$对称，

UMPU拒绝域为
$$W=\{\vec x:|T(\vec x)-n\mu_0|>C\}=\{\vec x:|\bar x-\mu_0|>C'\},$$ 

其中$C'$满足$P_{\mu_0}(|\bar X-\mu_0|>C')=\alpha$, 所以$C'=u_{1-\alpha/2}\sigma/\sqrt{n}$


## Two-sided tests for normal variance

**例**：假设总体为$N(\mu,\sigma^2)$, 其中$\mu$已知， 样本为$X_1,\dots,X_n$. 求下列检验的UMPU拒绝域

$$H_0:\sigma^2=\sigma_0^2\ vs. \ H_1:\sigma^2\neq\sigma_0^2$$

**解**：为方便起见，令$T(\vec X)=\sum_{i=1}^n(X_i-\mu)^2/\sigma_0^2$. 这样，
在$\mu=\mu_0$下，$T(\vec X)\sim \chi^2(n)$. UMPU拒绝域表示为
$W=\{\vec x:T(\vec x)\notin [C_1,C_2]\}$，其中$C_1,C_2$满足
$$P_{\sigma^2_0}(T(\vec X)\notin W)=\int_{C_1}^{C_2} f(x;n) dx=1-\alpha$$

$$E_{\sigma^2_0}[1\{\vec X\notin W\}T(\vec X)]=\int_{C_1}^{C_2} x f(x;n)dx=(1-\alpha)E_{\sigma_0^2}[T(\vec X)]=n(1-\alpha)$$


## Two-sided tests for normal variance

其中，$f(x;n)$为$\chi^2(n)$的密度函数，即

$$f(x;n)=\frac{1}{2^{n/2}\Gamma(n/2)}x^{n/2-1}e^{-x/2}1\{x>0\}$$

$$\int_{C_1}^{C_2} \frac{x}{n} f(x;n)dx=\int_{C_1}^{C_2} \frac{x}{n} \frac{1}{2^{n/2}\Gamma(n/2)}x^{n/2-1}e^{-x/2}dx=\int_{C_1}^{C_2} f(x;n+2)dx=\int_{C_1}^{C_2} f(x;n) dx=1-\alpha$$

实际上，求解$C_1,C_2$比较困难，为方便起见，不妨用平均法取$C_1=\chi_{\alpha/2}^2(n), C_2=\chi_{1-\alpha/2}^2(n)$.


## Summary

我们已经在单参数指数型分布总体下给出常见的假设检验的UMP/UMPU, 具体步骤可以归纳如下：

- 根据指数型分布写出**检验统计量(test statistic)**$T(\vec X)=\sum_{i=1}^nV(X_i)$，或者它的常数倍

- 根据假设检验的类型写出拒绝域$W$的形式，一般有

$$T(\vec x)>C,T(\vec x)<C,T(\vec x)\in (C_1,C_2),T(\vec x)\notin [C_1,C_2]$$

- 如果是只有一个待定参数$C$时，可以检验水平$\alpha$来得到$C$的值，即

$$P_{\theta_0}(T(\vec X)\in W)=\alpha,\  \theta_0\text{为}\Theta_0\text{的边界点}$$

- 如果有两个待定参数$C_1,C_2$时, 可能还需另外一个等式来求解（比如双边假设检验）。

正态总体的期望的检验统计量为$n\bar X$或者$\bar X$, 称为**U检验(U test)**；方差的检验统计量为$\sum_{i=1}^n(X_i-\mu)^2$, 称为**卡方检验(chi-square test)**。

## 3. Generalized LR tests

设总体的密度函数(分布函数)为$f(x;\theta),\theta\in\Theta$, 研究检验问题

$$H_0:\theta\in \Theta_0\ vs.\ H_1:\theta \notin \Theta_0$$

设似然函数(likelihood function)为$L(\vec x;\theta)=\prod_{i=1}^nf(x_i;\theta)$, 令

$$L(A):= \sup_{\theta\in A}L(\vec x;\theta),\ A\subseteq \Theta$$

定义**广义似然比**为：

$$\lambda(\vec x):=\frac{L(\Theta)}{L(\Theta_0)}\ge 1$$

**广义似然比拒绝域**为：

$$W=\{\vec x:\lambda(\vec x)>\lambda_0\}$$

其中$\lambda_0$满足$\sup_{\theta\in\Theta_0}P_{\theta}(\vec X\in W)=\alpha$, $\alpha$为检验水平。

## Generalized LR and sufficient statistic

设充分统计量(sufficient statistic)为$\psi(\vec X)$, 由因子分解定理(factorization theorem)知，

$$L(\vec x;\theta)=g(\psi(\vec x),\theta)h(\vec x)$$

$$\lambda(\vec x):=\frac{\sup_{\theta\in\Theta} g(\psi(\vec x),\theta)h(\vec x)}{\sup_{\theta\in\Theta_0} g(\psi(\vec x),\theta)h(\vec x)}=\frac{\sup_{\theta\in\Theta} g(\psi(\vec x),\theta)}{\sup_{\theta\in\Theta_0} g(\psi(\vec x),\theta)}=\ell(\psi(\vec x))$$

**结论**：广义似然比是充分统计量的函数，所以拒绝域可以写成

$$W=\{\vec x:\lambda(\vec x)>\lambda_0\}=\{\vec x:\psi(\vec x)\in B\}$$


问题转化成求解集合$B$使得检验水平为$\alpha$. 如果充分统计量在给定$\theta=\theta_0$下容易得到，这个问题则比较容易处理。
下面只针对**正态总体**来分析。

## HT for normal distribution

前面我们已经分析了$N(\mu,\sigma^2)$只有一个未知参数的假设检验问题，现在利用广义似然比来分析两个未知参数的情形。我们只考虑下面三种情况：

$$\theta=\theta_0\ vs.\ \theta\neq \theta_0$$


$$\theta\le \theta_0\ vs.\ \theta>\theta_0$$

$$\theta\ge \theta_0\ vs.\ \theta<\theta_0$$

其中$\theta=\mu$ 或者 $\sigma^2$, 另外一个参数未知。

## Two-sided tests for normal mean

总体$X\sim N(\mu,\sigma^2)$, 考虑检验问题

$$\mu=\mu_0\ vs.\ \mu\neq \mu_0$$

则，$\theta=(\mu,\sigma^2),\Theta_0=\{(\mu_0,\sigma^2):\sigma^2>0\},\Theta=\{(\theta,\sigma^2):\theta\in\mathbb{R},\sigma^2>0\}$

似然函数：

$$L(\vec x;\theta)=(2\pi \sigma^2)^{-n/2}\exp\left(-\frac 1{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\right)$$

$L(\Theta)=L(\vec x;\bar x,s_n^2)=(2\pi s_n^2e)^{-n/2}$, 令$q_n^2=\frac 1n\sum_{i=1}^n (x_i-\mu_0)^2$. $L(\Theta_0)=L(\vec x;\mu_0, q_n^2)=(2\pi q_n^2e)^{-n/2}$. 似然比为
$$\lambda(\vec x)=(q_n^2/s_n^2)^{n/2}=\left(1+\frac{T(\vec x)^2}{n-1}\right)^{n/2}
,\ T(\vec x)=\frac{\bar x-\mu_0}{s_n/\sqrt{n-1}}$$

## Two-sided tests for normal mean

所以，拒绝域为$W=\{\vec x:|T(\vec x)|>C\}$, 其中

$$P_{\mu_0}(\vec X\in W)=P_{\mu_0}(|T(\vec X)|>C)=\alpha$$

因为在$\mu=\mu_0$时，$T\sim t(n-1)$, 所以，$C=t_{1-\alpha/2}(n-1)$


**注**：

- 可以证明$W$是UMPU的，证明较复杂（略）

- 这种检验方式称为**t检验**，$T$为检验统计量

## One-sided tests for normal mean I

总体$X\sim N(\mu,\sigma^2)$, 考虑检验问题

$$\mu\le\mu_0\ vs.\ \mu> \mu_0$$

此时，$\Theta_0=\{(\mu,\sigma^2):\mu\le \mu_0,\sigma^2>0\}$

$$L(\Theta_0)=
\begin{cases}
L(\vec x;\bar x,s_n^2),\ &\bar x\le \mu_0\\
L(\vec x;\mu_0,q_n^2),\ &\bar x> \mu_0
\end{cases}$$

似然比为
$$\lambda(\vec x)=\begin{cases}
\left(1+\frac{T(\vec x)^2}{n-1}\right)^{n/2}, \ &\bar x> \mu_0\\
1,\ &\bar x\le \mu_0
\end{cases}
$$

所以，拒绝域为$W=\{\vec x:T(\vec x)>C\}$, $C=t_{1-\alpha}(n-1)$, 是UMPU

## One-sided tests for normal mean II

总体$X\sim N(\mu,\sigma^2)$, 考虑检验问题

$$\mu\ge\mu_0\ vs.\ \mu< \mu_0$$

类似地，拒绝域为$W=\{\vec x:T(\vec x)<C\}$, $C=t_{\alpha}(n-1)$, 是UMPU


**总结**：在方差未知的情况下考虑期望的检验问题，由$t$检验可以得到UMPU拒绝域，检验统计量为
$$T=\frac{\bar X-\mu_0}{S_n/\sqrt{n-1}}=\frac{\bar X-\mu_0}{S_n^*/\sqrt{n}}$$

拒绝域$W$形式为$|T|>C,\ T>C,\ T<C$, 其中$C$满足$P_{\mu_0}(T\in W)=\alpha$

## Illustration

![](test.jpg)

## Two-sided tests for normal variance

总体$X\sim N(\mu,\sigma^2)$, 考虑检验问题

$$\sigma^2=\sigma^2_0\ vs.\ \sigma^2\neq \sigma^2_0$$

利用广义似然比检验法可以得到拒绝域为

$$W=\{\vec x: \chi^2>C_2, \chi^2<C_1\}$$

其中**检验统计量**$\chi^2 = \frac{1}{\sigma^2_0}\sum_{i=1}^n(x_i-\bar x)^2=ns_n^2/\sigma_0^2$, $C_1,C_2$满足

$$\int_{C_1}^{C_2} g_{n-1}(x) dx = 1-\alpha$$

其中$g_n(x)$表示$\chi^2(n)$的密度函数。可以证明当$C_1,C_2$再满足$\int_{C_1}^{C_2} g_{n+1}(x) dx = 1-\alpha$时，拒绝域$W$为UMPU.

为方便起见，取$C_1=\chi^2_{\alpha/2}(n-1),\ C_2=\chi^2_{1-\alpha/2}(n-1)$

## One-sided tests for normal variance

总体$X\sim N(\mu,\sigma^2)$, 考虑检验问题

$$\sigma^2\le\sigma^2_0\ vs.\ \sigma^2> \sigma^2_0$$

利用广义似然比检验法可以得到拒绝域为

$$W=\{\vec x: \chi^2>C\}$$

其中$C=\chi^2_{1-\alpha}(n-1)$

考虑检验问题

$$\sigma^2\ge\sigma^2_0\ vs.\ \sigma^2< \sigma^2_0$$

利用广义似然比检验法可以得到拒绝域为

$$W=\{\vec x: \chi^2<C\}$$

其中$C=\chi^2_{\alpha}(n-1)$

这两者都是UMPU.



## HT for two independent normals

设总体$X\sim N(\mu_1,\sigma_1^2)$, 另有与$X$独立的总体$Y\sim N(\mu_2,\sigma_2^2)$. 

$$H_0: \mu_1-\mu_2=\delta,\ H_1: \mu_1-\mu_2\neq \delta$$

- 如果$\sigma_1^2,\sigma_2^2$已知, 选择**U检验统计量**：

$$U=\frac{\bar X-\bar Y-\delta}{\sqrt{\sigma_1^2/m+\sigma_2^2/n}}$$

若$|U|> u_{1-\alpha/2}$拒绝$H_0$，否则接受$H_0$.

- 如果$\sigma_1^2,\sigma_2^2$未知，已知$\sigma_1^2=\sigma_2^2$，选择**t检验统计量**：

$$T=\frac{\bar X-\bar Y-\delta}{S_w\sqrt{1/m+1/n}}\sim t(m+n-2)$$



若$|T|> t_{1-\alpha/2}(n+m-2)$拒绝$H_0$，否则接受$H_0$.



## HT for two independent normals

如果$\sigma_1^2,\sigma_2^2$未知，但$\sigma_1^2\neq\sigma_2^2$, 选择**检验统计量**：

$$T=\frac{(\bar X-\bar Y)-\delta}{\sqrt{S_{1m}^{*2}/m+S_{2n}^{*2}/n}}$$

在$\mu_1-\mu_2=\delta$下，$T$近似服从自由度为$k$的$t$分布，其中$k$为接近$k^*$的整数，

$$k^*=\frac{(S_{1m}^{*2}/m+S_{2n}^{*2}/n)^2}{(S_{1m}^{*2}/m)^2/(m-1)+(S_{2n}^{*2}/n)^2/(n-1)}$$

这就是著名的**Behrens-Fisher问题**。

## HT for two independent normals
	
设总体$X\sim N(\mu_1,\sigma_1^2)$, 另有与$X$独立的总体$Y\sim N(\mu_2,\sigma_2^2)$. 
	
$$H_0: \sigma_1^2=\sigma_2^2,\ H_1: \sigma_1^2\neq \sigma_2^2$$
	
- 如果$\mu_1,\mu_2$已知，选择**F检验统计量**：
$$F=\frac{\frac 1 m\sum_{i=1}^m(X_i-\mu_1)^2}{\frac 1 n\sum_{i=1}^n(Y_i-\mu_2)^2}\sim F(m,n)\quad (在H_0下).$$
若$F> F_{1-\alpha/2}(m,n)$或者$F<F_{\alpha/2}(m,n)$拒绝$H_0$，否则接受$H_0$.
	
- 如果$\mu_1,\mu_2$未知，选择**F检验统计量**：
$$F=\frac{\frac 1 {m-1}\sum_{i=1}^m(X_i-\bar X)^2}{\frac 1 {n-1}\sum_{i=1}^n(Y_i-\bar Y)^2}=\frac{S_{1m}^{*2}}{S_{2n}^{*2}}\sim F(m-1,n-1)\quad (在H_0下).$$
	
若$F> F_{1-\alpha/2}(m-1,n-1)$或者$F<F_{\alpha/2}(m-1,n-1)$拒绝$H_0$，否则接受$H_0$.

## Case study: Heights dataset

假设男生身高$X\sim N(\mu_1,\sigma_1^2)$, 女生身高$X\sim N(\mu_2,\sigma_2^2)$, 比较他们的均值与方差的差异。

**均值的假设检验R命令**

t.test(x, y = NULL,
       alternative = c("two.sided", "less", "greater"),
       mu = 0, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95, ...)
       
**方差的假设检验R命令**

var.test(x, y, ratio = 1,
         alternative = c("two.sided", "less", "greater"),
         conf.level = 0.95, ...)

## Mean difference test (I)

```{r}
library(dslabs)
attach(heights)
female_height = height[sex=="Female"]#提取女生数据
male_height = height[sex=="Male"]#提取男生数据
## 方差相等时双边假设检验
t.test(male_height,female_height,var.equal = TRUE)

```

## Mean difference test (II)

```{r}
## 方差不相等时双边假设检验
t.test(male_height,female_height)

```

## Mean difference test (III)

```{r}
## 方差不相等时单边假设检验
t.test(male_height,female_height,alternative = "less")

```

## Variance ratio test

```{r}
var.test(male_height,female_height)

```

## Confidence intervals vs HT

假设$\theta$的100$(1-\alpha)\%$ 置信区间(confidence interval, CI)为 $[L(X_1,\dots,X_n),U(X_1,\dots,X_n)]$. 这表明

$$P_{\theta}(\theta\in [L,U])=1-\alpha,\ \forall\theta\in\Theta.$$

考虑假设检验: $$H_0:\theta=\theta_0\ vs.\ H_1:\theta\neq\theta_0$$

**检验法则**: 如果$\theta_0\notin [L,U]$, 拒绝原假设；否则接受原假设。于是得到一个拒绝域：$W=\{\vec x:\theta_0\notin [L(\vec x),U(\vec x)]\}$, 显著性水平为

$$P_{\theta_0}(\theta_0\notin [L,U])=\alpha$$

但这样得到的拒绝域不一定是UMP或者UMPU!

## Confidence intervals vs HT

反过来，假如我们有以下检验的一个拒绝域$W(\theta_0)$

$$H_0:\theta=\theta_0\ vs.\ H_1:\theta\neq\theta_0,$$

其中$P_{\theta_0}((X_1,\dots,X_n)\in W(\theta_0))=\alpha, \forall \theta_0\in\Theta$. 可以得到一个置信集**(confidence set)**:

$$S(X_1,\dots,X_n)=\{\theta:(X_1,\dots,X_n)\notin W(\theta)\}$$

$$P_\theta(\theta\in S) = P_{\theta}((X_1,\dots,X_n)\notin W(\theta)) = 1-\alpha,\ \forall\theta\in\Theta$$

- 该置信集是由所有“接受”的$\theta$的值组成的

- 一般情况下，该置信集为区间形式

## Example

考虑总体$X\sim N(\mu,\sigma^2)$，其中$\mu$未知，方差$\sigma^2$已知。则有
$$P(\bar X-u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\le \mu\le \bar X+u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}})=1-\alpha$$

于是得到一个置信区间：$[\bar X-u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}},\bar X+u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}]$

由此可以构造拒绝域：$$W=\{\mu_0\notin [\bar x-u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}},\bar x+u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}]\}$$
$$W=\{\vec x:|\bar x-\mu_0|>u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\}$$

此拒绝域和我们之前得到的一样的。

## Example: blood alcohol determinations 

The following are thirty blood alcohol determinations （血液酒精浓度测试） made by Analyzer GTE-10, a three-year-old unit that may be in need of recalibration. All thirty measurements were made using a test sample on which a properly adjusted machine would give a reading of 12.6%.


| 12.3 | 12.7 | 13.6 | 12.7 | 12.9 | 12.6| 
|-|-|-|-|-|-|
| 12.6 | 13.1 | 12.6 | 13.1 | 12.7 | 12.5| 
| 13.2 | 12.8 | 12.4 | 12.6 | 12.4 | 12.4| 
| 13.1 | 12.9 | 13.3 | 12.6 | 12.6 | 12.7| 
| 13.1 | 12.4 | 12.4 | 13.1 | 12.4 | 12.9| 

Assume that $\sigma=0.4$. Would you recommend that the machine be readjusted at the level of significance $\alpha=0.05$? Would you change your decision if $\alpha=0.01$?


`Solution`: If $\mu$ denotes the true average reading that Analyzer
GTE-10 would give for a person whose blood
alcohol concentration is 12.6%, test
$H_0:\,mu=12.6 v.s. H_1:\mu\neq 12.6$.

Note that $\bar x=12.757.$ The rection region is $W=\{\bar x-\mu_0|>u_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}\}$.
If $\alpha=0.05$, $W=\{\bar x-\mu_0|>0.143\}$. So I recommend that the machine be readjusted. On the other hand, if $\alpha$ goes down to $0.01$, the rejection region is $W=\{\bar x-\mu_0|>0.188\}$. For this case, I do NOT recommend that the machine be readjusted. 

## p-values

假设拒绝域具备如下形式

$$W=\{\vec x:T(\vec x)>\lambda\}$$

- $T$为检验统计量

- $\lambda_\alpha$满足$\sup_{\theta\in\Theta_0}P_{\theta}(T(\vec X)>\lambda_\alpha)=\alpha$


由此可得：

- 对于固定的样本，显著性水平$\alpha$越大，$\lambda$越小，这样越容易拒绝原假设

- 对于固定的样本，是否存在一个临界值$p$, 使得当$p<\alpha$时拒绝原假设，当$p\ge \alpha$时接受原假设？这个临界值称为$p$值(p-value)

$$p=p(\vec x)=\sup_{\theta\in\Theta_0}P_\theta(T(X_1,\dots,X_n)\ge T(x_1,\dots,x_n))$$

如果给定$\alpha$, $\lambda_\alpha$存在且唯一，则可以证明：$T(\vec x)>\lambda_\alpha$当且仅当$p(\vec x)<\alpha$

## p-values for simple null

如果原假设是简单的, 即$H_0:\theta=\theta_0$，则

$$p = P_{\theta_0}(T(X_1,\dots,X_n)\ge T(x_1,\dots,x_n))$$


**例**：总体$X\sim N(\mu,\sigma^2)$，其中$\mu$未知，方差$\sigma^2$已知，考虑检验$$H_0:\mu=\mu_0\ vs.\ H_1:\mu\neq\mu_0.$$ 拒绝域为$W=\{\vec x:\sqrt{n}|\bar x-\mu_0|/\sigma>u_{1-\alpha/2}\}$, 其中检验统计量为$T = \sqrt{n}|\bar X-\mu_0|/\sigma$. 故p值为

$$p = P_{\mu_0}(T(\vec X)\ge T(\vec x))=2-2\Phi(T(\vec x))=2-2\Phi\left(\frac{|\bar x-\mu_0|}{\sigma/\sqrt{n}}\right)$$

For blood alcohol determinations example,   

$$p = 2-2\Phi\left(\frac{|12.757-12.6|}{0.4/\sqrt{30}}\right)=0.032.$$
As a result, if $\alpha> 0.032$, reject $H_0$ (recommend); otherwise, accpete $H_0$ (NOT recommend).

## Comments

- p值可以看作样本与原假设**相容程度的度量**。p值越大相容度越高；反之，p值越小相容度越低。当p值小于$\alpha$时认为两者不相容，拒绝原假设


- 做检验时不需要事先确定显著性水平$\alpha$（它的具有一定的主观性），如果p值非常小，则毫不犹豫地拒绝原假设；同样地，如果p值比较大，则接受原假设，这样就不用争论$\alpha=0.1,0.05$或者其他。

- p值提供更多的信息，可以用于**保护隐私数据**

- 统计软件提供的是p值

## Multiple tests

- 如果独立检验同一个假设$k$次，我们可以得到$k$个p值: $p_1,\dots,p_k$, 可否由这$k$个p值汇总成一个p值来检验该假设？**元分析(meta-analysis)**

- 假如我们有$k$个不同的原假设$H_{0j},j=1,\dots,k$，这种问题称为**多重假设(multiple tests)**问题。可否利用$k$个不同假设的p值: $p_1,\dots,p_k$来进一步控制错误的发生概率?

例子：吃果冻与长青春痘的联系：[https://xkcd.com/882/](https://xkcd.com/882/)

![](https://imgs.xkcd.com/comics/significant.png)


How to annoy a statistician: [https://xkcd.com/2118/](https://xkcd.com/2118/)


## Binomial tests

设$X$服从两点分布$B(1,p)$, 下面考虑以下三种常见的假设检验

- $H_0:p\le p_0\ vs.\ H_1:p>p_0$

- $H_0:p\ge p_0\ vs.\ H_1:p<p_0$

- $H_0:p= p_0\ vs.\ H_1:p\neq p_0$


对于该总体，我们选$S=\sum_{i=1}^nX_i\sim B(n,p)$为检验统计量。相应的拒绝域形式为

- $W=\{s\ge c\}$

- $W=\{s\le c\}$

- $W=\{s\ge c_2\}\cup\{s\le c_1\}$

注意到$S$为离散型随机变量，所以满足$\sup_{p\in\Theta_0}P_p(\vec X\in W)=\alpha$的分界点不一定存在。因此，我们考虑$\sup_{p\in\Theta_0}P_p(\vec X\in W)\le \alpha$下分界点的选取。

## HT for ratio: one-sided I

考虑单边假设$H_0:p\le p_0\ vs.\ H_1:p>p_0$, 临界值$c$为满足下式**最小的整数**

$\sup_{p\le p_0}P_p(S\ge c)\le \alpha$

由于$P_p(S\ge c)=\sum_{i=c}^nC_n^ip^i(1-p)^{n-i}$关于$p$**单调递增**(=$Beta(c,n-c+1)$分布的CDF在$p$点的取值，见课本P44)，所以只需考虑

$$P_{p_0}(S\ge c)=\sum_{i=c}^nC_n^ip_0^i(1-p_0)^{n-i}\le \alpha$$

计算$c$比较复杂，为了避免此，我们将拒绝域$\{s\ge c\}$等价转化为

$$W=\{\sum_{i=s}^nC_n^ip_0^i(1-p_0)^{n-i}\le \alpha\}$$


## HT for ratio: one-sided I

更进一步，假设$p_\alpha(s)$为方程$\sum_{i=s}^nC_n^ip^i(1-p)^{n-i}=\alpha$的根，则拒绝域等价转化为

$$W=\{p_0\le p_\alpha(s)\}$$

其中$p_\alpha(s)=Beta_{\alpha}(s,n-s+1)$, 或者可以表示成

$$p_\alpha(s)=(1+\frac{n-s+1}{s}F_{1-\alpha}(2(n-s+1),2s))^{-1}$$


详细的转化见课本P105引理4.2.

## Example

考虑女士品茶问题，设该女士鉴别的成功率为$p$. 设$X_i$表示第$i$次鉴别结果，即$X_i=1$表示成功，$X_i=0$表示失败。如果$p>p_0$我们认为该女士具备这种辨别能力，其中$p_0\ge 1/2$为给定的数。故考虑检验

$$H_0: p\le p_0\ vs.\ H_1:p>p_0.$$


**二项分布检验的R代码**
 
binom.test(x, n, p = 0.5,
           alternative = c("two.sided", "less", "greater"),
           conf.level = 0.95)

## The results for n=10

```{r}
alpha = 0.1
n = 10
s = 1:n
pr = qbeta(alpha,s,n-s+1)

par(mfrow = c(1,2),mar=c(4,4,2,0.5))
plot(s,pr,type="b",ylab=expression(p[alpha](s)), main=expression(alpha==0.1))
abline(h=0.5,col="red")
lb = expression(p[0]==0.5)
text(3,0.55,lb)

alpha = 0.05
pr = qbeta(alpha,s,n-s+1)
plot(s,pr,type="b",ylab=expression(p[alpha](s)), main=expression(alpha==0.05))
abline(h=0.5,col="red")
text(3,0.55,lb)

```

## binom.test

```{r}
binom.test(8,10,0.5,alternative = "greater")
```


## HT for ratio: one-sided II

考虑单边假设$H_0:p\ge p_0\ vs.\ H_1:p<p_0$, 临界值$c$为满足下式**最大的整数**

$\sup_{p\ge p_0}P_p(S\le c)\le \alpha$

由于$P_p(S\le c)=\sum_{i=0}^cC_n^ip^i(1-p)^{n-i}$关于$p$**单调递减**，所以只需考虑

$$P_{p_0}(S\le c)=\sum_{i=0}^cC_n^ip_0^i(1-p_0)^{n-i}\le \alpha$$

计算$c$比较复杂，为了避免此，我们将拒绝域$\{s\ge c\}$等价转化为

$$W=\{\sum_{i=s+1}^nC_n^ip_0^i(1-p_0)^{n-i}\ge 1-\alpha\}$$


## HT for ratio: one-sided II

更进一步，假设$\tilde p_\alpha(s)$为方程$\sum_{i=s+1}^nC_n^ip^i(1-p)^{n-i}=1-\alpha$的根，则拒绝域等价转化为

$$W=\{p_0\ge \tilde p_\alpha(s)\}$$

其中$\tilde p_\alpha(s)=Beta_{1-\alpha}(s+1,n-s)$, 或者可以表示成

$$\tilde p_\alpha(s)=(1+\frac{n-s}{(s+1)F_{1-\alpha}(2(s+1),2(n-s))})^{-1}$$


详细的转化见课本P105引理4.2.

## HT for ratio: two-sided

考虑双边假设$$H_0:p= p_0\ vs.\ H_1:p\neq p_0$$
拒绝域为$\{s\le c_1\}\cup\{s\ge c_2\}$，其中临界值$c_1$为满足$P_{p_0}(S\le c_1)=\alpha/2$**最大的整数**，临界值$c_1$为满足$P_{p_0}(S\ge c_2)=\alpha/2$**最小的整数**。由前面分析，该拒绝域等价于

$$\{p_0\le p_{\alpha/2}(s)\}\cup\{p_0\ge \tilde{p}_{\alpha/2}(s)\}$$

## Example:  Mendel’s Data

In one of his famous experiments, Mendel crossed 556 smooth, yellow male peas
with wrinkled, green female peas. The counts that Mendel recorded are 

| smooth yellow | smooth green | wrinkled yellow | wrinkled green |
|-|-|-|-|
|315 | 108 | 102 | 31|

According to now established genetic theory, the
relative frequencies of the progeny should be as given below.

$$P(\text{smooth yellow}) = 9/16, P(\text{smooth green}) = 3/16$$

$$P(\text{wrinkled yellow}) = 3/16, P(\text{wrinkled green}) = 1/16$$

Would you conclude that Mendal’s experiment is correct at the level of significance $\alpha=0.05$?


## 4. Goodness-of-fit tests (拟合优度检验)


考虑离散型分布的假设检验，$X\in \{t_1,\dots,t_m\}$.

$$H_0: P(X=t_i)=p_i,\ i=1,\dots,m,\ vs.\ H_1: P(X=t_i)\neq p_i$$

其中$\sum_{i=1}^m p_i=1$.

卡方检验法检验统计量：

$$V=\sum_{i=1}^{m} \frac{(v_i-np_i)^2}{np_i}$$

其中$v_i$表示$X_1,\dots,X_n$中包含$t_i$的个数，即$v_i=\sum_{j=1}^m 1\{X_j=t_i\}$.

拒绝域$W=\{V>\lambda\}$. 可以证明在$H_0$下，$V\stackrel{\cdot}{\sim} \chi^2(m-1)$, 故$\lambda=\chi^2_{1-\alpha}(m-1)$


## Example:  Mendel’s Data

| $t_i$ | smooth yellow | smooth green | wrinkled yellow | wrinkled green |
|- |-|-|-|-|
| $v_i$ |315 | 108 | 102 | 31|
| $p_i$ | 9/16| 3/16 | 3/16| 1/16| 
| $np_i$ | 312.75 | 104.25 | 104.25 | 34.75 |


- the $\chi^2$ test statistic is $V=0.604$, $\chi^2_{1-0.05}(3)=7.81$, accept the null.

- p-value is $0.90$

- Key R code: 

**chisq.test**(x, y = NULL, correct = TRUE,
           p = rep(1/length(x), length(x)), rescale.p = FALSE,
           simulate.p.value = FALSE, B = 2000)
           
           
## chisq.test

```{r}
x = c(315, 108, 102, 31)
p = c(9/16,3/16,3/16,1/16)
chisq.test(x,p=p)
```

##  Goodness-of-fit tests

考虑连续型分布：

$$H_0:F(x)=F_0(x)\ vs. \ F(x)\neq F_0(x)$$

把整个实轴分成$m$份，$(-\infty,t_1],\ (t_1,t_2],\dots,(t_{m-2},t_{m-1}],\ (t_{m-1},\infty)$, 分别计算这$m$个区间的概率$p_i,i=1,\dots,m$, $v_i$表示$X_1,\dots,X_n$落到第$i$个区间的个数， 类似离散的分布的检验。

$t_{i},m$的选择？借鉴直方图法的选取


## Summary

其他检验：

- 独立性检验

- 正态性检验

- 柯尔莫哥洛夫检验法
