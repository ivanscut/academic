---
title: 第七次作业

date: 2018-12-18 
lastmod: 2018-12-18 

draft: false
# toc: true
type: docs

linktitle: 第七次作业
menu:
  course: 
    parent: 数理统计
    weight: 12
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Let $X_1,\dots,X_{100}$ be a sample from $N(\mu,1)$. Given a  significance level $\alpha=0.05$, derive a UMP rejection region $W$ of 

$$H_0:\mu=0\ vs.\ H_1:\mu>0.$$
Let $W'=\{\vec x:|\bar x| > u_{0.975}/10\}$ be another rejection region. Show that the significance level for $W'$ is $0.05$, and graph the power functions for $W$ and $W'$. Try to explain that you observed.


`Solution`: The UMP rejection region $W=\{\vec x:\bar x > u_{0.95}/10\}$. It is easy to see that $P(\vec X\in W'|\mu=0)=0.05$. The power function for $W$ is $$\rho_W(\mu) = P_\mu(\bar X> u_{0.95}/10)=1-\Phi(u_{0.95}-10\mu),$$
where $\Phi(\cdot)$ is the CDF of the standard normaml distribution.
The power function for $W'$ is $$\rho_{W'}(\mu) = P_\mu(|\bar X| > u_{0.975}/10)=1-\Phi(u_{0.975}-10\mu)+\Phi(-u_{0.975}-10\mu).$$


```{r}
curve(1-pnorm(qnorm(0.95)-10*x),0,0.6,ylab="power functions",xlab=expression(mu))
curve(1-pnorm(qnorm(0.975)-10*x)+pnorm(-qnorm(0.975)-10*x),0,0.6,
      add = TRUE, col = "red")
legend(0.3,0.6,legend=c("W","W'"),col=c("black","red"),lty = c(1,1))

```


We observe from the figure that

- $\rho_W(\mu)>\rho_{W'}(\mu)$ for any $\mu>0$, which is consistent with the UMP property of $W$.
- Both the two power functions go to $1$ as $\mu\to \infty$. This implies that if the true value of $\mu$ is far away from $0$, then two tests gain larger powers. 

---

Let $X_1,\dots,X_n$ be a sample from an exponential distribution $Exp(\lambda)$. Given a  significance level $\alpha$, derive a likelihood ratio test of 

$$H_0:\lambda=\lambda_1\ vs.\ H_1:\lambda=\lambda_2,$$

where $\lambda_1\neq\lambda_2$.


`Solution`: The likelihood function is 
$$L(\lambda)=\prod_{i=1}^n (\lambda e^{-\lambda x_i}) = \lambda^ne^{-\lambda n\bar x}.$$


The likelihood ratio is given by
$$\lambda(\vec x)= \frac{L(\lambda_2)}{L(\lambda_1)}=\frac{\lambda_2^ne^{-\lambda_2 n\bar x}}{\lambda_1^ne^{-\lambda_1 n\bar x}}=(\lambda_2/\lambda_1)^ne^{(\lambda_1-\lambda_2)n\bar x}.$$

Choose the ``test statistic`` $T(\vec x) = 2\lambda_1n\bar x$. When $\lambda=\lambda_1$, $T(\vec X)\sim \chi^2(2n)$. Also, 
$$\lambda(\vec x) = (\lambda_2/\lambda_1)^ne^{(\lambda_1-\lambda_2)T(\vec x)/(2\lambda_1)}.$$


1. Note that $\lambda_1,\lambda_2>0$. If $\lambda_1>\lambda_2$, the rejection region is of the form $W=\{T(\vec x)>C\}$. We thus have $C=\chi_{1-\alpha}^2(2n)$.

2. If $\lambda_1<\lambda_2$, the rejection region is of the form $W=\{T(\vec x)<C\}$. We thus have $C=\chi_{\alpha}^2(2n)$.



---

Let $X_1,\dots,X_n$ be a sample from an exponential distribution $Exp(\lambda)$. Given a  significance level $\alpha$, derive a UMPU test of 

$$H_0:\lambda=\lambda_0\ vs.\ H_1:\lambda\neq\lambda_0.$$


`Solution`: Exponential distribution belongs to exponential family of the form $S(\lambda)h(x)e^{Q(\lambda)V(x)}$ with $V(x) = -x$ and $Q(\lambda)=\lambda$. Choose the ``test statistic`` $T(\vec x)=2\lambda_0 n\bar x$.  As a result, the UMPU rejection region has the form
$$W = \{T(\vec x)<C_1 \text{ or } >C_2\},$$
where $C_1,C_2$ satisfy 
$$P_{\lambda_0}(\bar X\in W)=\alpha$$
and
$$E_{\lambda_0}[1\{\vec X\in W\}T(\vec X)]=\alpha E_{\lambda_0}[T(\vec X)].$$
Let $f(x;n)$ be the density of $\chi^2(n)$, that is 
$$f(x;n)=\frac{1}{2^{n/2}\Gamma(n/2)}x^{n/2-1}e^{-x/2}1\{x>0\}.$$
If $\lambda=\lambda_0$, $T(\vec X)\sim \chi^2(2n)$. We thus have
$$\int_{C_1}^{C_2}f(x;2n) d x=1-\alpha,\quad(1)$$
$$\int_{C_1}^{C_2} x f(x;2n)dx = 2n(1-\alpha).$$
The later equality can be expressed as
$$\int_{C_1}^{C_2} \frac{x}{2n} f(x;2n)dx=\int_{C_1}^{C_2} \frac{x}{2n} \frac{1}{2^{n}\Gamma(n)}x^{n-1}e^{-x/2}dx=\int_{C_1}^{C_2} f(x;2n+2)dx=1-\alpha.\quad(2)$$

It is hard to solve the equations (1) and (2). In practice, we may take
$C_1=\chi_{\alpha/2}^2(2n)$ and $C_2=\chi_{1-\alpha/2}^2(2n)$ so that the significance level of the test is $\alpha$. BUT, it is not the exact UMPU test since (2) is not satisfied. If $n$ is large enough, $f(x;2n+2)\approx f(x;2n)$ (see figure below). This implies the resulting rejection region is almost UMPU when $n$ is large.

```{r,echo = FALSE}
n = 20
x = seq(0,50,by=0.001)
y1 = dchisq(x,n)
y2  = dchisq(x,n+2)
par(mar=c(4,4,2,1),mfcol=c(2,1))
plot(x,y1,type="l",ylab="y")
lines(x,y2,col="red")
legend(40,0.06,legend=c("n=20","n=22"),lty=c(1,1),col=c("black","red"))
n = 100
x = seq(50,150,by=0.001)
y1 = dchisq(x,n)
y2  = dchisq(x,n+2)
plot(x,y1,type="l",ylab="y") 
lines(x,y2,col="red")
legend(130,0.025,legend=c("n=100","n=102"),lty=c(1,1),col=c("black","red"))
```

Of course, you can solve the equations (1) and (2) by numerical algorithms, such as bisection and Newton's methods. Let $F(x;n)$ be the CDF of $\chi^2(n)$ and $F^{-1}$ denote its inverse. By (1), we have $C_2=F^{-1}(F(C_1;2n)+1-\alpha;2n)$. Substituting  it into (2), we arrive at an equation:
$$F(F^{-1}(F(C_1;2n)+1-\alpha;2n);2n+2)-F(C_1;2n+2)=1-\alpha.$$

We can slove the equation using R function `uniroot`. The code is given below.

```{r}
myfun <- function(c,n,alpha)
  pchisq(qchisq(pchisq(c,2*n)+1-alpha,2*n),2*n+2)-pchisq(c,2*n+2)-1+alpha

mysolver <- function(n,alpha){
  a = qchisq(alpha/2,2*n)
  b = qchisq(alpha/2,2*n+2)
  ## solve the equation by using the root finding algorithm
  r = uniroot(myfun,n=n,alpha=alpha,interval = c(a,b))
  c1 = r$root
  c2 = qchisq(pchisq(c1,2*n)+1-alpha,2*n)
  err1 = pchisq(c2,2*n+2)-pchisq(c1,2*n+2)-1+alpha #check the error for eq. (2)
  ## the approximate method
  c11 = qchisq(alpha/2,2*n)
  c22 = qchisq(1-alpha/2,2*n)
  err2 = pchisq(c22,2*n+2)-pchisq(c11,2*n+2)-1+alpha #check the error for eq. (2)
  output = data.frame(exact=c(c1,c2,abs(err1)),rough=c(c11,c22,abs(err2)),
                      row.names = c("C1","C2","error"))
  return(output)
}
alpha = 0.5
n = 10
output = mysolver(n,alpha)
knitr::kable(output,"html",caption = "n=10, alpha=0.05")
```

For large $n=100$, we have the following results.

```{r}
n = 100
output = mysolver(n,alpha)
knitr::kable(output,"html",caption = "n=100, alpha=0.05")
```

As expected, the error for the rough estimates $C_1=\chi_{\alpha/2}^2(2n)$ and $C_2=\chi_{1-\alpha/2}^2(2n)$ decreases as $n$ goes up. 


---

Let $X_1,\dots,X_n$ be a sample from $U[0,\theta]$. Given a  significance level $\alpha$, derive a UMP test of 

$$H_0:\theta=\theta_0\ vs.\ H_1:\theta>\theta_0.$$


`Solution`: Firstly, consider the simple alternative:
$$H_0:\theta=\theta_0\ vs.\ H_1:\theta=\theta_1>\theta_0.$$

The likelihood function is $L(\theta)=\theta^{-n}1\{x_{(n)}\le \theta\}$.
The likelihood ratio for the simple test is 
$$\lambda(\vec x) = \frac{\theta_1^{-n}1\{x_{(n)}\le \theta_1\}}{\theta_0^{-n}1\{x_{(n)}\le \theta_0\}}
=\begin{cases}
(\theta_0/\theta_1)^n,\ &x_{(n)}\le \theta_0\\
\infty,\ &x_{(n)}> \theta_0
\end{cases}$$

We therefore cannot find a $\lambda_0$ such that $P_{\theta_0}(\lambda(\vec X)>\lambda_0)=\alpha$. This implies that the N-P lemma cannot be applied. As we can see, the likelihood ratio is a function of $x_{(n)}$. We thus can use $X_{(n)}$ as the test statistic. A resonable rejection region would be
$W = \{x_{(n)}>C\}$, where $C$ satisfies
$$P_{\theta_0}(X_{(n)}>C)=\alpha.$$

When $\theta=\theta_0$, the order statistic $X_{(n)}/\theta_0$ has a CDF $F(x)=x^n$ (see [Exercise 1](https://hezhijian.netlify.com/course/homework5/)). So we have $C=(1-\alpha)^{1/n}\theta_0$. The rejection region is
$$W = \{\vec x:x_{(n)}>(1-\alpha)^{1/n}\theta_0\}.$$


We next prove that $W$ is UMP. Suppose that there exists a rejection region $W'$ satisfying $P_{\theta_0}(\vec X\in W')\le \alpha$. Let $A=[0,\theta_0]^n$ be the sample space when $\theta=\theta_0$, and let $B=[0,\theta_1]^n$ be the sample space  when $\theta=\theta_1$. It is clear that $A\subseteq B$ since $\theta_1>\theta_0$. This implies 
$$P_{\theta_0}(\vec X\in W') = P_{\theta_0}(\vec X\in W'\cap A)=\frac{1}{\theta_0^n}\int_{W'\cap A} 1 d x_1\dots d x_n\le \alpha.$$
Similarly, 
$$P_{\theta_0}(\vec X\in W) = P_{\theta_0}(\vec X\in W\cap A)=\frac{1}{\theta_0^n}\int_{W\cap A} 1 d x_1\dots d x_n= \alpha.$$
Define $\mu(E) = \int_E 1 d x_1\dots d x_n$. So we have $\mu(W\cap A)\ge \mu(W'\cap A)$. 


On the other hand, noticing that $W\cap B=W\cap A+\bar A\cap B$, we thus have

$$
\begin{align}
P_{\theta_1}(\vec X\in W) &=\frac{1}{\theta_1^n}\int_{W\cap B} 1 d x_1\dots d x_n\\&=\frac{1}{\theta_1^n}\int_{W\cap A}1 d x_1\dots d x_n+\frac{1}{\theta_1^n}\int_{\bar A\cap B}1 d x_1\dots d x_n\\
&=\theta_1^{-n}[\mu(W\cap A)+\mu(\bar A\cap B)]\\
&\ge \theta_1^{-n}[\mu(W'\cap A)+\mu(W'\cap\bar A\cap B)\\
&=\theta_1^{-n}\mu(W'\cap B)=P_{\theta_1}(\bar X\in W').
\end{align}
$$

Therefore, $W$ is UMP rejection region. Since $W$ does not depend on $\theta_1$, it is also the UMP rejection region for the alternative $H_1:\theta>\theta_0$.

For this example, the UMP rejection region is not unique. Following the same procedure above, one can  easily prove that for any
set $W_0\subset A$ with $\mu(W_0)=\alpha\theta_0^n$, $W=W_0\cup \bar A$ is UMP.



---

Let $X_1,X_2,X_3,X_4$ be a sample from $N(\theta,1)$. Given a  significance level $\alpha=0.1$, derive a UMP test of 

$$H_0:\theta\ge 10\ vs.\ H_1:\theta<10.$$
Calculate the power of the test when $\theta=9$.



`Solution`: The test statistics is $T(\vec x)=\frac{\bar x-10}{1/\sqrt{n}}=\sqrt{n}(\bar x-10)=2(\bar x-10)$, where $n=4$. The UMP rejection region has the form $W=\{T(\vec x)<C\}$, where $C$ satisfies
$$P(T(\vec X)<C|\theta=10)=\alpha=0.1$$
This gives $C= u_{0.1}=-u_{0.9}=-1.28$. So $$W=\{\vec x|2(\bar x-10)<-1.28\}=\{\vec x|\bar x<9.36\}.$$

The power of the test is 
$$P(\bar X<9.36|\theta=9)=P(2(\bar X-9)<0.72|\theta=9)=\Phi(0.72)=0.76.$$

