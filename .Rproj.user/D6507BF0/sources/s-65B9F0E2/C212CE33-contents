---
title: 第十一次作业

date: 2018-12-18 
lastmod: 2018-12-18 

draft: false
# toc: true
type: docs

linktitle: 第十一次作业
menu:
  course: 
    parent: 数理统计
    weight: 16
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Consider the simple linear model

$$y_i= \beta_0+\beta_1x_i+\epsilon_i,\ \epsilon_i\stackrel{iid}{\sim} N(0,\sigma^2).$$

Use the F-test method derived in the multiple linear model to test the hypothesis $H_0:\beta_1=0\ vs.\ H_1:\beta_1\neq 0$, and see whether the F-test agrees with the earlier t-test derived in the simple linear models.

`Solution`: The F test statistic is given by

$$F = \frac{S_R^2/(p-1)}{S_e^2/(n-p)}=\frac{S_R^2}{S_e^2/(n-p)},$$

where 

$$S_R^2=\sum_{i=1}^n(\hat y_i-\bar y)^2=\sum_{i=1}^n(\hat\beta_0-\hat\beta_1x_i-\bar y) = \sum_{i=1}^n(\bar y-\hat\beta_1\bar x-\hat\beta_1x_i-\bar y)^2=\hat\beta_1^2\sum_{i=1}^n(x_i-\bar x)^2=\hat\beta_1^2\ell_{xx}.$$

The t test statistic is given by

$$T=\frac{\hat\beta_1}{\sqrt{\frac{S_e^2}{(n-p)\ell_{xx}}}}.$$

As a result, $T^2=F$. Under $H_0$, $T\sim t(n-p)$ and $F\sim F(1,n-p)$. The rejection region for F-test is $W_1=\{F>F_{1-\alpha}(1,n-p)\}$, and the rejection region for t-test is $W_2=\{|T|>t_{1-\alpha/2}(n-p)\}$. Note that $P(|T|>t_{1-\alpha/2}(n-p)|H_0) = P(T^2>t_{1-\alpha/2}(n-p)^2|H_0) =1-\alpha$. Since $T^2\sim F(1,n-p)$ under $H_0$, we have $t_{1-\alpha/2}(n-p)^2=F_{1-\alpha}(1,n-p)$. This implies $W_1=W_2$, i.e., the two tests are the same.



---


The following table shows the monthly returns of stock in Disney, MacDonalds,
Schlumberger, and Haliburton for January through May 1998. Fit a multiple regression
to predict Disney returns from those of the other stocks. What is the
standard deviation of the residuals? What is $R^2$?

Disney | MacDonalds | Schlumberger | Haliburton |
-|-|-|-|
0.08088  | -0.01309  | -0.08463  | -0.13373 | 
0.04737  | 0.15958  | 0.02884  | 0.03616 | 
-0.04634  | 0.09966  | 0.00165  | 0.07919 | 
0.16834  | 0.03125  | 0.09571  | 0.09227 | 
-0.09082  | 0.06206  | -0.05723  | -0.13242 | 

Next, using the regression equation you have just found, carry out the predictions
for January through May of 1999 and compare to the actual data listed
below. What is the standard deviation of the prediction error? How can the comparison
with the results from 1998 be explained? Is a reasonable explanation that
the fundamental nature of the relationships changed in the one year period? (最后一问选做)

Disney | MacDonalds | Schlumberger | Haliburton | 
-|-|-|-|
0.1  | 0.02604  | 0.02695 |  0.00211 | 
0.06629  | 0.07851  | 0.02362 |  -0.04 | 
-0.11545  | 0.06732  | 0.23938  | 0.35526 | 
0.02008  | -0.06483  | 0.06127  | 0.10714 | 
-0.08268  | -0.09029 |  -0.05773 |  -0.02933 | 

`Solution`: 


```{r}
stock=data.frame(Mac=c(-0.01309,0.15958,0.09966,0.03125,0.06206),
                 Sch=c(-0.08463,0.02884,0.00165,0.09571,-0.05723),
                 Hali=c(-0.13373,0.03616,0.07919,0.09227,-0.13242),
                Disney=c(0.08088,0.04737,-0.04634,0.16834,-0.09082))
lm.stock = lm(Disney~Mac+Sch+Hali,data=stock)
summary(lm.stock)
knitr::kable(summary(lm.stock)$coef,"html",caption = "summary table")
```


The regression function is 

$$Disney = 0.0938-0.8812\times MacDonalds	+1.3151\times Schlumberger-0.1717\times Haliburton$$


The $R^2= 0.6298$, and the standard deviation of the residuals is $\hat\sigma=0.1253$.


```{r}
newdata = data.frame(
  Mac=c(0.02604,0.07851,0.06732,-0.06483,-0.09029),
 Sch=c(0.02695,0.02362,0.23938,0.06127,-0.05773),
 Hali=c(0.00211,-0.04,0.35526,0.10714,-0.02933))
truevalue = c(0.1,0.06629,-0.11545,0.02008,-0.08268)
pre = predict(lm.stock,newdata,interval = "prediction")
knitr::kable(pre,"html",caption = "predicted values and CI")
pre_error = sd(pre[,1]-truevalue)
cat("The standard deviation of the prediction error is ", pre_error,".")
```


{{% alert warning %}}
对于这道题来讲，多元线性模型非常不显著，所以预测就没有太多意义了。这时，我们应该改进我们模型。比如，去掉不显著的项、添加高阶项或者交叉项。但注意，由于这个问题数据量为5，所以未知参数的个数不应该超过4，否则出现完全拟合的情况了。例如，下面的回归模型比之前的模型显著多了：
{{% /alert %}}


```{r}
lm.stock2 = lm(Disney~Sch+Mac+I(Sch*Mac),data=stock)##添加交叉项用I(Sch*Mac)表示
summary(lm.stock2)
knitr::kable(summary(lm.stock2)$coef,"html",caption = "improved model")
```

{{% alert warning %}}
在实际使用多元线性回归过程中，如何确定自变量和因变量之前的关系尤为重要。因为不是所有的自变量都可能用得上，而且可能出现非线性项（高阶项、交叉项）。这属于变量选择问题，也是线性回归中非常重要的主题。感兴趣的同学可以查阅课本208页。
{{% /alert %}}
