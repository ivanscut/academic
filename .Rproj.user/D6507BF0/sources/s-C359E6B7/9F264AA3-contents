---
title: "第四章：线性回归分析(Linear Regression Analysis)"
output:
  powerpoint_presentation:
    reference_doc: mystyles.pptx
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

## Contents

### 1. 引言(Introduction)

### 2. 一元线性回归(Simple Linear Regression)

### 3. 多元线性回归(General Linear Regression)


## Case study 1

A manufacturer of air conditioning units is having assembly problems due to
the failure of a connecting rod (连接杆) to meet finished-weight specifications. Too many
rods are being completely tooled, then rejected as overweight. To reduce that
cost, the company’s quality-control department wants to quantify the relationship
between the weight of the **finished rod**, $y$, and that of the **rough casting** (毛坯铸件), $x$. Castings likely to produce rods that are too heavy can then be discarded
before undergoing the final (and costly) tooling process.

DATA: $(x_i,y_i), i=1,\dots,25$

## Graphed data

```{r}
data = read.table("rod.txt",col.names = c("id","rough_weight","finished_weight"))
attach(data)
par(mar=c(4,4,1,0.5))
plot(rough_weight,finished_weight,type="p",pch=16,xlab = "Rough Weight",ylab = "Finished Weight")
lm.out = lm(finished_weight~rough_weight)
abline(coef(lm.out),col="blue")
```

## Case study 2

Crickets (蟋蟀) make their chirping sound (鸣叫) by sliding one
wing cover very rapidly back and forth over the other.
Biologists have long been aware that there is a linear
relationship between **temperature** and the **frequency** with which a cricket chirps.

## Data

![](figs/cricket.png)


## Displayed data

```{r}
data = read.table("cricket.txt",col.names = c("id","chirps","temperature"))
attach(data)
par(mar=c(4,4,1,0.5))
plot(chirps,temperature,type="p",pch=16,xlab = "Chirps per Second",ylab = "Temperature (F)")
lm.out = lm(temperature~chirps)
abline(coef(lm.out),col="blue")
```

## Linear models

$$y = a+bx+\epsilon$$

- $x$: 自变量(independent variable), 预测变量(predictor variable)

- $y$: 因变量(dependent variable), 响应变量(response variable)

- $\epsilon$: 误差/随机项

模型：

$$y_i=a+bx_i+\epsilon_i,\ i=1,\dots,n$$

注意：$x_i$看成固定的量，$y_i$是随机变量

如何估计$a,b$?

## Least squares

**思想**：最小化误差平方和(sum of squared error):

$$Q(a,b)=\sum_{i=1}^n(y_i-a-bx_i)^2$$

估计量为:


$$\hat a = \bar y-\hat b\bar x,\ \hat b = \frac{\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{\sum_{i=1}^n(x-\bar x)^2}=\frac{s_{xy}}{s_{xx}}$$

有用的记号：

- $s_{xx} = \frac 1n\sum_{i=1}^n(x_i-\bar x)^2$ (基本假设：$s_{xx}>0$)
- $s_{yy}=\frac 1 n\sum_{i=1}^n(y_i-\bar y)^2$
- $s_{xy}=\frac 1n\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)$

## Remarks

- 回归方程(regression function): $\hat y = \hat a+\hat bx$

- 截距(intercept)$a$的估计量：$\hat a$

- 斜率(slope)$b$的估计量：$\hat b$

注意到
$$s_{xy}=\frac 1n\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)=\frac 1n\sum_{i=1}^n(x_i-\bar x)y_i$$
则$$\hat b=\frac{s_{xy}}{s_{xx}}=\frac 1{n}\sum_{i=1}^n\frac{(x_i-\bar x)y_i}{s_{xx}}$$

## Expected values

模型：$y_i=a+bx_i+\epsilon_i,\ i=1,\dots,n$


**假设A**：$E[\epsilon_i]=0$

$$
E[\hat b] = E\left[\frac 1{n}\sum_{i=1}^n\frac{(x_i-\bar x)y_i}{s_{xx}}\right] = \frac 1{ns_{xx}}\sum_{i=1}^n(x_i-\bar x)E[y_i]
=\frac 1{ns_{xx}}\sum_{i=1}^n(x_i-\bar x)(a+bx_i)=\frac b{ns_{xx}}\sum_{i=1}^n(x_i-\bar x)x_i
=\frac b{ns_{xx}}\sum_{i=1}^n(x_i-\bar x)(x_i-\bar x)=b
$$

$$
E[\hat a]=E[\bar y-\hat b \bar x]=E[\bar y]-b\bar x=a+b\bar x-b\bar x=a
$$

## Variances

**假设B**: $\epsilon_i$独立，$Var[\epsilon_i]=\sigma^2,i=1,\dots,n$

$$Var[\hat b]= Var\left[\frac 1{n}\sum_{i=1}^n\frac{(x_i-\bar x)y_i}{s_{xx}}\right]=\frac 1{n^2s_{xx}^2}\sum_{i=1}^n(x_i-\bar x)^2Var[y_i]=\frac {\sigma^2}{n^2s_{xx}^2}\sum_{i=1}^{n}(x_i-\bar x)^2=\frac{1}{s_{xx}}\frac{\sigma^2}{n}$$

注意到：$Cov(\bar y,\hat b)=0$

$$Var[\hat a] = Var[\bar y-\hat b \bar x]=Var[\bar y]+(\bar x)^2Var[\hat b]=\left(1+\frac{\bar x^2}{s_{xx}}\right)\frac{\sigma^2}{n}$$



## Variances

$$Cov(\hat a,\hat b)=Cov(\bar y-\hat b \bar x,\hat b)=-\bar xVar[\hat b]=\frac{-\bar x}{s_{xx}}\frac{\sigma^2}{n}$$


结论：$\sigma^2$越小，$s_{xx}$越大，估计量的方差越小。

## Normal distribution

模型：$y_i=a+bx_i+\epsilon_i,\ i=1,\dots,n$

**假设C**: $\epsilon_i\stackrel{iid}{\sim} N(0,\sigma^2)$

$$\hat b\sim N(b,\frac{\sigma^2}{ns_{xx}}),\ \frac{\hat b-b}{\sigma/\sqrt{ns_{xx}}}\sim N(0,1)$$
 

