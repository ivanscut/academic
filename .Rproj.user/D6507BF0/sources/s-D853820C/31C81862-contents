---
title: "第十次作业"
date: "2018-12-04"
categories: ["作业"]
Summary: "截止日期：2018-12-09 23:00"
tags: ["作业", "数理统计"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Let us consider fitting a straight line, $y = \beta_0+\beta_1x$, to points $(x_i,y_i)$, where $i=1,\dots,n$. 

1. Write down the normal equations for the simple linear model via the matrix formalism.

2. Solve the normal equations by tha matrix approach and see whether the solutions agree with the earlier calculation derived in the simple linear models.



---

Prove that the projection matrix $P=X(X^\top X)^{-1} X^\top$ has an eigenvalue 1, and 
$(1,\dots,1)^\top$ is one of the associated eigenvectors.


---

(The QR Method) This problem outlines the basic ideas of an alternative method,
the QR method, of finding the least squares estimate $\hat \beta$. An advantage of the
method is that it does not include forming the matrix $X^\top X$, a process that tends
to increase rounding error. The essential ingredient of the method is that if $X_{n\times p}$
has $p$ linearly independent columns, it may be factored in the form

$$
\begin{align}
X\quad &=\quad Q\quad \quad R\\
n\times p &\quad  n\times p\quad p\times p
\end{align}
$$

where the columns of $Q$ are orthogonal ($Q^\top Q = I_p$) and $R$ is upper-triangular
($r_{ij} = 0$, for $i > j$) and nonsingular. For a discussion of this decomposition and
its relationship to the Gram-Schmidt process, see [https://en.wikipedia.org/wiki/QR_decomposition](https://en.wikipedia.org/wiki/QR_decomposition).

Show that $\hat \beta = (X^\top X)^{-1}X^\top Y$ may also be expressed as $\hat \beta = R^{-1}Q^\top Y$,
or $R\hat \beta  = Q^\top Y$. Indicate how this last equation may be solved for $\hat \beta$ by back-substitution, using that $R$ is upper-triangular, and show that it is thus unnecessary
to invert $R$.


---


Consider fitting the curve $y = \beta_0x+\beta_1x^2$ to points ($x_i,y_i$), where $i = 1,\dots,n$.

1. Use the matrix formalism to find expressions for the least squares estimates
of $\beta_0$ and $\beta_1$.

2. Find an expression for the covariance matrix of the estimates.
